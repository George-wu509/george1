
## **AWS SageMaker vs Azure MLï¼šå…¨é¢æ¯”è¼ƒ**

åœ¨ **AI è¨“ç·´ã€éƒ¨ç½²èˆ‡ç›£æ§** æ–¹é¢ï¼Œ**AWS SageMaker** å’Œ **Azure Machine Learning (Azure ML)** æ˜¯å…©å¤§ä¸»æµé›²ç«¯ AI å¹³å°ã€‚ä»¥ä¸‹æ˜¯å®ƒå€‘åœ¨ **æ ¸å¿ƒåŠŸèƒ½ã€æ€§èƒ½ã€åƒ¹æ ¼ã€æ˜“ç”¨æ€§ã€ç›£æ§èˆ‡æ“´å±•æ€§** æ–¹é¢çš„è©³ç´°æ¯”è¼ƒã€‚

---

## **1. ç¸½è¦½æ¯”è¼ƒ**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Azure Machine Learning (Azure ML)**|
|---|---|---|
|**æœ€ä½³ç”¨é€”**|**é–‹ç™¼ AI/ML æ‡‰ç”¨ä¸¦å¤§è¦æ¨¡éƒ¨ç½²**|**èˆ‡ Microsoft ç”Ÿæ…‹ç³»ï¼ˆå¦‚ Power BI, Officeï¼‰æ•´åˆ**|
|**æ”¯æ´çš„ AI æ¡†æ¶**|PyTorch, TensorFlow, Scikit-learn, XGBoost, ONNX|PyTorch, TensorFlow, Scikit-learn, ONNX, LightGBM|
|**è‡ªå‹• MLï¼ˆAutoMLï¼‰**|æœ‰ AutoPilotï¼Œå¯è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹|**Azure AutoML æ›´æˆç†Ÿï¼Œå¯ç„¡ä»£ç¢¼å®Œæˆ AutoML**|
|**æ•¸æ“šå­˜å„²**|S3, DynamoDB, RDS|Azure Blob Storage, Azure SQL|
|**æ¨¡å‹è¨“ç·´**|æ”¯æŒ **åˆ†æ•£å¼è¨“ç·´**ï¼ˆHorovod, DeepSpeedï¼‰|å…§å»º **Azure ML Pipelines** ä¾¿æ–¼ DataOps|
|**æ¨¡å‹éƒ¨ç½²**|**SageMaker Endpoint**ï¼Œæ”¯æ´ GPU/CPU éƒ¨ç½²|**Azure ML Endpoint**ï¼Œå¯èˆ‡ Kubernetes AKS æ•´åˆ|
|**æˆæœ¬**|**æŒ‰ç§’è¨ˆè²»**ï¼ˆå¯éš¨æ™‚åœæ­¢ï¼‰|**é ä»˜è¨ˆç•«è¼ƒåˆ’ç®—**ï¼ˆå¦‚ Azure Reserved VMï¼‰|
|**ç›£æ§èˆ‡ A/B æ¸¬è©¦**|**SageMaker Model Monitor**ï¼Œæ”¯æ´ drift detection|**Azure ML Model Monitor**ï¼Œå…§å»º Fairness & Explainability|
|**æ•´åˆç”Ÿæ…‹ç³»**|AWS Lambda, Step Functions, CloudWatch|Azure IoT, Power BI, Synapse Analytics|

---

## **2. æ•¸æ“šç®¡ç†**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Azure Machine Learning (Azure ML)**|
|---|---|---|
|**æ•¸æ“šå­˜å„²**|Amazon S3|Azure Blob Storage|
|**æ”¯æ´æ•¸æ“šæ ¼å¼**|CSV, Parquet, JSON, TFRecord|CSV, Parquet, JSON|
|**æ•¸æ“šé è™•ç†**|SageMaker Processing Jobs|Azure ML Data Wrangler|
|**è³‡æ–™æ¨™è¨»**|SageMaker Ground Truth|Azure ML Data Labeling|

### **åˆ†æ**

- **AWS SageMaker**ï¼šGround Truth å¯é€²è¡Œ **åŠè‡ªå‹•æ•¸æ“šæ¨™è¨»**ï¼Œé©åˆ **å¤§è¦æ¨¡æ•¸æ“šæ¨™è¨»**ã€‚
- **Azure ML**ï¼šData Wrangler å…§å»º **æ•¸æ“šæ¸…ç†**ï¼Œèˆ‡ **Power BI, Azure Data Factory æ•´åˆ**ã€‚

ğŸ”¹ **é¸æ“‡å»ºè­°**ï¼š

- è‹¥ **å·²æœ‰ AWS S3 å„²å­˜** â†’ **AWS æ›´åˆé©**ã€‚
- è‹¥ **åœ¨ Azure ä¸Šå·²æœ‰ Blob Storage** â†’ **Azure æ›´åˆé©**ã€‚

---

## **3. è¨“ç·´èƒ½åŠ›**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Azure Machine Learning (Azure ML)**|
|---|---|---|
|**åˆ†æ•£å¼è¨“ç·´**|æ”¯æŒ **Horovod, DeepSpeed, PyTorch DDP**|**Azure ML Pipelines** æ”¯æŒ MLOps|
|**AutoML**|SageMaker AutoPilot|**Azure AutoML**ï¼ˆåŠŸèƒ½æ›´å¼·ï¼‰|
|**GPU/TPU æ”¯æŒ**|**A100, V100, Inferentia, Habana Gaudi**|**A100, V100, AMD MI200**|
|**è¨ˆç®—è³‡æºç®¡ç†**|**Spot Instanceï¼ˆä½æˆæœ¬é¸æ“‡ï¼‰**|**Azure Reserved VMï¼ˆé•·æœŸä½¿ç”¨æ›´çœéŒ¢ï¼‰**|

### **åˆ†æ**

- **AWS SageMaker** æä¾› **Spot Training**ï¼ˆæˆæœ¬å¯æ¸›å°‘ 70%ï¼‰ã€‚
- **Azure ML** æä¾› **AutoML æ”¯æ´å¤šç¨®è¶…åƒæ•¸æœç´¢æ–¹æ³•**ï¼ˆå¦‚ Bayesian Optimizationï¼‰ã€‚
- **åˆ†æ•£å¼è¨“ç·´**ï¼š
    - **AWS SageMaker**ï¼šé©åˆ **å¤§è¦æ¨¡æ·±åº¦å­¸ç¿’**ï¼ˆæ”¯æ´ **DeepSpeed, Horovod, PyTorch DDP**ï¼‰ã€‚
    - **Azure ML**ï¼šé©åˆ **MLOps æ•´åˆ**ï¼ˆå¯é…åˆ Data Factory é€²è¡Œ DataOpsï¼‰ã€‚

ğŸ”¹ **é¸æ“‡å»ºè­°**ï¼š

- éœ€è¦ **è¶…å¤§è¦æ¨¡ AI è¨“ç·´** â†’ **AWS SageMaker**ã€‚
- éœ€è¦ **å…¨è‡ªå‹• AutoML ç®¡ç·š** â†’ **Azure ML**ã€‚

---

## **4. æ¨¡å‹éƒ¨ç½²**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Azure Machine Learning (Azure ML)**|
|---|---|---|
|**éƒ¨ç½²æ–¹å¼**|SageMaker Endpoints|Azure ML Endpoints|
|**æ”¯æ´æ ¼å¼**|PyTorch, TensorFlow, ONNX|PyTorch, TensorFlow, ONNX|
|**å®¹å™¨åŒ–æ”¯æ´**|æ”¯æ´ AWS Lambda, Kubernetes|æ”¯æ´ Azure AKS, Kubernetes|
|**Edge AI**|æ”¯æŒ AWS IoT Greengrass|æ”¯æ´ Azure IoT Edge|

### **åˆ†æ**

- **AWS SageMaker** éƒ¨ç½² **æ¨ç†æˆæœ¬ä½ï¼ˆæŒ‰ç§’è¨ˆè²»ï¼‰**ï¼Œé©åˆ **Serverless æ‡‰ç”¨ï¼ˆAWS Lambdaï¼‰**ã€‚
- **Azure ML** å¯ **ç›´æ¥èˆ‡ AKSï¼ˆAzure Kubernetes Serviceï¼‰ æ•´åˆ**ï¼Œé©åˆ **ä¼æ¥­ç´š AI éƒ¨ç½²**ã€‚

ğŸ”¹ **é¸æ“‡å»ºè­°**ï¼š

- **ç„¡ä¼ºæœå™¨ AIï¼ˆServerless Inferenceï¼‰** â†’ **AWS SageMaker æ›´å¼·**ã€‚
- **ä¼æ¥­ç´š Kubernetes éƒ¨ç½²** â†’ **Azure ML æ›´é©åˆ**ã€‚

---

## **5. ç›£æ§èˆ‡ MLOps**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Azure Machine Learning (Azure ML)**|
|---|---|---|
|**æ¨¡å‹ç›£æ§**|SageMaker Model Monitor|Azure ML Model Monitor|
|**ç•°å¸¸åµæ¸¬**|æ”¯æ´ Drift Detection|**æ”¯æ´ Bias & Fairness Detection**|
|**MLOps**|**SageMaker Pipelinesï¼ˆCI/CDï¼‰**|**Azure DevOps / ML Pipelines**|
|**ç›£æ§å·¥å…·**|AWS CloudWatch|Azure Application Insights|

### **åˆ†æ**

- **AWS SageMaker Model Monitor**ï¼šä¸»è¦ç”¨æ–¼ **ç›£æ§æ•¸æ“šåˆ†ä½ˆæ¼‚ç§»**ï¼ˆDrift Detectionï¼‰ã€‚
- **Azure ML Model Monitor**ï¼šå…§å»º **Bias & Fairness** ç›£æ§ï¼Œé©åˆ **é‡‘èã€é†«ç™‚æ‡‰ç”¨**ã€‚

ğŸ”¹ **é¸æ“‡å»ºè­°**ï¼š

- **åªéœ€è¦ Drift Detection** â†’ **AWS æ›´ç°¡å–®**ã€‚
- **éœ€è¦ AI Fairness & Bias Analysis** â†’ **Azure ML æ›´é©åˆ**ã€‚

---

## **6. æˆæœ¬æ¯”è¼ƒ**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Azure Machine Learning (Azure ML)**|
|---|---|---|
|**è¨ˆåƒ¹æ–¹å¼**|**æŒ‰ç§’è¨ˆè²»ï¼ˆå¯é—œé–‰ç¯€çœæˆæœ¬ï¼‰**|**æŒ‰å°æ™‚è¨ˆè²»ï¼ˆå¯é ç•™ VM ç¯€çœæˆæœ¬ï¼‰**|
|**Spot Instance**|ä¾¿å®œ 70%|ç„¡|
|**å…è²»é¡åº¦**|250 å°æ™‚/ml.t3.medium|30 å¤©å…è²»è©¦ç”¨|

### **åˆ†æ**

- **AWS SageMaker** æŒ‰ **ç§’è¨ˆè²»**ï¼ŒçŸ­æ™‚é–“ä½¿ç”¨ä¾¿å®œã€‚
- **Azure ML** å¯é ä»˜ **Reserved VMï¼ˆé•·æœŸæˆæœ¬ä½ï¼‰**ã€‚

ğŸ”¹ **é¸æ“‡å»ºè­°**ï¼š

- **çŸ­æœŸè©¦é©—** â†’ **AWS SageMaker** ä¾¿å®œã€‚
- **é•·æœŸä¼æ¥­ç´šæ‡‰ç”¨** â†’ **Azure ML** æ›´çœéŒ¢ã€‚

---

## **7. ç¸½çµèˆ‡é¸æ“‡å»ºè­°**

|**ä½¿ç”¨å ´æ™¯**|**æœ€ä½³é¸æ“‡**|
|---|---|
|**éœ€è¦ AutoMLã€è‡ªå‹•æ¨¡å‹é¸æ“‡**|**Azure ML**|
|**è¶…å¤§è¦æ¨¡æ·±åº¦å­¸ç¿’è¨“ç·´**|**AWS SageMaker**|
|**éœ€è¦ Kubernetes + ä¼æ¥­ç´š AI éƒ¨ç½²**|**Azure ML**|
|**éœ€è¦ä½æˆæœ¬ AI è¨“ç·´ï¼ˆSpot Instanceï¼‰**|**AWS SageMaker**|
|**AI èˆ‡ Microsoft Power BI æ•´åˆ**|**Azure ML**|
|**Serverless AI æ¨ç†ï¼ˆç„¡ä¼ºæœå™¨æ¨ç†ï¼‰**|**AWS SageMaker**|

ç¸½çµä¾†èªªï¼š

- **AWS SageMaker** é©åˆ **å¤§è¦æ¨¡ AI è¨“ç·´èˆ‡ä½æˆæœ¬æ¨ç†**ã€‚
- **Azure ML** é©åˆ **AutoMLã€ä¼æ¥­ç´š MLOps èˆ‡ DevOps æ•´åˆ**ã€‚

ä½ ç›®å‰çš„ AI è¨ˆç•«éœ€è¦ **AutoMLã€MLOps é‚„æ˜¯åˆ†æ•£å¼è¨“ç·´ï¼Ÿ**




## **AWS SageMaker å’Œ Amazon S3 è©³ç´°ä»‹ç´¹**

AWS æä¾›è¨±å¤š AI/ML ç›¸é—œæœå‹™ï¼Œå…¶ä¸­ **AWS SageMaker** æ˜¯å°ˆé–€ç‚ºæ©Ÿå™¨å­¸ç¿’ï¼ˆMLï¼‰é–‹ç™¼ã€è¨“ç·´ã€éƒ¨ç½²å’Œç›£æ§æä¾›çš„ç«¯åˆ°ç«¯é›²ç«¯å¹³å°ï¼Œè€Œ **Amazon S3** å‰‡æ˜¯ AWS çš„é›²ç«¯ç‰©ä»¶å­˜å„²æœå‹™ï¼Œå¸¸è¢«ç”¨ä¾†å­˜æ”¾ ML è¨“ç·´æ•¸æ“šã€æ¨¡å‹æª”æ¡ˆå’Œæ¨ç†çµæœã€‚

---

# **1. ä»€éº¼æ˜¯ AWS SageMaker?**

**AWS SageMaker** æ˜¯ä¸€å€‹ **å®Œå…¨è¨—ç®¡ï¼ˆFully Managedï¼‰** çš„ **æ©Ÿå™¨å­¸ç¿’å¹³å°**ï¼Œæä¾› **è¨“ç·´ï¼ˆTrainingï¼‰ã€éƒ¨ç½²ï¼ˆDeploymentï¼‰ã€ç›£æ§ï¼ˆMonitoringï¼‰** å’Œ **MLOps** æ”¯æ´ï¼Œå¹«åŠ©é–‹ç™¼è€…å’Œä¼æ¥­åœ¨ AWS ä¸Šæ§‹å»º AI æ‡‰ç”¨ã€‚

### **1.1 AWS SageMaker çš„æ ¸å¿ƒåŠŸèƒ½**

|**åŠŸèƒ½**|**èªªæ˜**|
|---|---|
|**SageMaker Studio**|**Web ç•Œé¢** æä¾›å®Œæ•´ **ML ç”Ÿå‘½é€±æœŸç®¡ç†**ï¼ˆé–‹ç™¼ã€è¨“ç·´ã€èª¿è©¦ã€éƒ¨ç½²ï¼‰|
|**SageMaker Training**|**å¯æ“´å±• GPU/TPU è¨“ç·´**ï¼ˆæ”¯æ´ Spot Instanceï¼Œé™ä½è¨“ç·´æˆæœ¬ï¼‰|
|**SageMaker Processing**|ç”¨æ–¼æ•¸æ“šé è™•ç†ï¼ˆETLï¼‰ã€ç‰¹å¾µå·¥ç¨‹|
|**SageMaker AutoPilot**|**AutoML è‡ªå‹•åŒ–æ¨¡å‹é¸æ“‡èˆ‡èª¿åƒ**|
|**SageMaker JumpStart**|**å…§å»ºé è¨“ç·´æ¨¡å‹**ï¼ˆResNet, BERT, GPT-2, YOLO, XGBoostï¼‰|
|**SageMaker Experiments**|**ç®¡ç†è¶…åƒæ•¸èª¿æ•´èˆ‡ç‰ˆæœ¬æ§åˆ¶**|
|**SageMaker Debugger**|**ç›£æ§ GPU ä½¿ç”¨ç‡ã€Lossã€Gradient Vanishing**|
|**SageMaker Model Monitor**|**ç›£æ§æ•¸æ“šåˆ†ä½ˆæ¼‚ç§»ï¼ˆData Driftï¼‰**|
|**SageMaker Pipelines**|**MLOps æ•´åˆï¼ˆCI/CD è‡ªå‹•åŒ– AI ç”Ÿå‘½é€±æœŸï¼‰**|
|**SageMaker Deployment**|**å³æ™‚æ¨ç†ï¼ˆReal-time Inferenceï¼‰å’Œæ‰¹é‡æ¨ç†ï¼ˆBatch Transformï¼‰**|
|**SageMaker Edge**|**æ”¯æ´ Edge AIï¼ˆIoT Edgeï¼‰éƒ¨å±¬æ¨¡å‹**|

---

### **1.2 AWS SageMaker æ¶æ§‹**

AWS SageMaker ä¸»è¦ç”±ä»¥ä¸‹éƒ¨åˆ†çµ„æˆï¼š

- **æ•¸æ“šå„²å­˜ï¼šAmazon S3, AWS FSx**
- **æ¨¡å‹é–‹ç™¼ï¼šJupyter Notebook + SageMaker Studio**
- **è¨“ç·´ï¼šGPU/TPU åˆ†æ•£å¼è¨“ç·´**
- **éƒ¨ç½²ï¼šSageMaker Endpoint**
- **ç›£æ§ï¼šCloudWatch + Model Monitor**

---

### **1.3 SageMaker ä½¿ç”¨å ´æ™¯**

AWS SageMaker é©ç”¨æ–¼ï¼š

1. **è¨“ç·´å¤§è¦æ¨¡æ·±åº¦å­¸ç¿’æ¨¡å‹**
    - ä¾‹å¦‚ï¼šYOLO, ResNet, DINOv2, ViT, GPT-3
    - **æ”¯æ´ Spot Instanceï¼ˆæœ€å¤šå¯ç¯€çœ 70% è¨“ç·´æˆæœ¬ï¼‰**
2. **AutoML æ‡‰ç”¨**
    - ç„¡éœ€æ‰‹å‹•é¸æ“‡æ¨¡å‹ï¼ŒSageMaker AutoPilot æœƒè‡ªå‹• **é¸æ“‡æœ€ä½³æ¼”ç®—æ³•**
3. **å¤§è¦æ¨¡ MLOps**
    - é€é SageMaker Pipelines å»ºç«‹ CI/CDï¼Œè‡ªå‹•åŒ– AI è¨“ç·´èˆ‡éƒ¨ç½²
4. **å³æ™‚æ¨ç†**
    - éƒ¨ç½²è‡³ **SageMaker Endpoint**ï¼Œæ”¯æ´ GPU / CPU é«˜æ•ˆæ¨ç†
5. **é‚Šç·£ AI éƒ¨ç½²**
    - **SageMaker Edge Manager** å¯å°‡æ¨¡å‹éƒ¨å±¬åˆ° **IoT è£ç½®ï¼ˆå¦‚æ™ºæ…§ç›¸æ©Ÿï¼‰**

---

### **1.4 SageMaker å¯¦ä½œç¯„ä¾‹**

#### **(1) è¨“ç·´ AI æ¨¡å‹**
```python
import sagemaker
from sagemaker.pytorch import PyTorch

s3_bucket = "my-bucket"
s3_train_data = f"s3://{s3_bucket}/data/train/"

estimator = PyTorch(
    entry_point="train.py",  # è¨“ç·´è…³æœ¬
    source_dir="code",  # åŸå§‹ç¢¼è·¯å¾‘
    role="arn:aws:iam::123456789012:role/SageMakerExecutionRole",
    framework_version="1.13",
    py_version="py39",
    instance_count=1,
    instance_type="ml.p3.2xlarge",
    hyperparameters={"epochs": 10, "batch_size": 32},
)

estimator.fit({"train": s3_train_data})
```

#### **(2) éƒ¨ç½²æ¨¡å‹**
```python
from sagemaker.pytorch.model import PyTorchModel

model = PyTorchModel(
    model_data=estimator.model_data,
    role="arn:aws:iam::123456789012:role/SageMakerExecutionRole",
    entry_point="inference.py",
    framework_version="1.13",
    py_version="py39",
)

predictor = model.deploy(instance_type="ml.m5.large", initial_instance_count=1)
```


# **2. ä»€éº¼æ˜¯ Amazon S3ï¼Ÿ**

Amazon S3 (**Simple Storage Service**) æ˜¯ AWS æä¾›çš„ **é›²ç«¯ç‰©ä»¶å­˜å„²æœå‹™**ï¼Œæ”¯æ´ **æ©Ÿå™¨å­¸ç¿’è¨“ç·´æ•¸æ“šå­˜å„²ã€æ¨¡å‹å„²å­˜ã€æ¨ç†çµæœå­˜å„²**ã€‚

---

## **2.1 Amazon S3 ä¸»è¦ç‰¹é»**

|**ç‰¹æ€§**|**èªªæ˜**|
|---|---|
|**é«˜å¯ç”¨æ€§**|99.99% å¯é æ€§ï¼ŒS3 è³‡æ–™å¯å­˜æ”¾åœ¨å¤šå€‹å¯ç”¨å€|
|**ç„¡é™æ“´å±•**|å¯å„²å­˜ **PB ç´šæ•¸æ“š**ï¼Œé©ç”¨æ–¼ AI è¨“ç·´|
|**ä½æˆæœ¬å­˜å„²**|æä¾› **S3 Standard, S3 Glacierï¼ˆå†·å­˜å„²ï¼‰**|
|**å®‰å…¨æ€§**|æ”¯æ´ **IAM è§’è‰²ã€åŠ å¯†ã€å­˜å–æ§åˆ¶ï¼ˆACLï¼‰**|
|**èˆ‡ SageMaker æ•´åˆ**|SageMaker å¯ç›´æ¥å¾ S3 è¼‰å…¥æ•¸æ“š|

---

## **2.2 S3 å­˜å„²é¡å‹**

|**å­˜å„²é¡å‹**|**ç”¨é€”**|
|---|---|
|**S3 Standard**|é«˜é »å­˜å–æ•¸æ“šï¼Œé©åˆ **AI è¨“ç·´æ•¸æ“š**|
|**S3 Infrequent Access (IA)**|ä½é »å­˜å–æ•¸æ“šï¼Œå¦‚ **å·²è¨“ç·´çš„æ¨¡å‹**|
|**S3 Glacier**|æ­·å²æ•¸æ“šæ­¸æª”ï¼Œå¦‚ **èˆŠç‰ˆ AI æ¨¡å‹**|

---

## **2.3 ä½¿ç”¨ S3 ä¸Šå‚³æ•¸æ“š**

```python
import boto3

s3 = boto3.client("s3")
s3.upload_file("data/train.csv", "my-s3-bucket", "data/train.csv")
print("æ•¸æ“šå·²ä¸Šå‚³åˆ° S3")
```

---

## **2.4 SageMaker è®€å– S3 è¨“ç·´æ•¸æ“š**

```python
import sagemaker

s3_bucket = "my-bucket"
s3_prefix = "data/train"

train_data_s3_path = f"s3://{s3_bucket}/{s3_prefix}/"

estimator.fit({"train": train_data_s3_path})
```

---

## **3. AWS SageMaker vs Amazon S3**

|**æ¯”è¼ƒé …ç›®**|**AWS SageMaker**|**Amazon S3**|
|---|---|---|
|**ç”¨é€”**|è¨“ç·´ã€éƒ¨ç½² AI æ¨¡å‹|å­˜å„²æ•¸æ“š|
|**å¯ç”¨æ€§**|éœ€è¦ EC2 è¨ˆç®—è³‡æº|99.99% SLA|
|**ä¸»è¦åŠŸèƒ½**|GPU è¨“ç·´ã€AutoMLã€éƒ¨ç½²|ä½æˆæœ¬å­˜å„²|

---

## **çµè«–**

1. **Amazon S3** æ˜¯æ©Ÿå™¨å­¸ç¿’æ•¸æ“šå­˜å„²çš„æ ¸å¿ƒï¼Œå¯èˆ‡ **SageMaker æ•´åˆ** ç”¨æ–¼ **AI è¨“ç·´èˆ‡éƒ¨ç½²**ã€‚
2. **AWS SageMaker** æä¾›å®Œæ•´ **AI è¨“ç·´ã€éƒ¨ç½²ã€MLOps æ”¯æ´**ï¼Œé©åˆ **å¤§è¦æ¨¡ AI è¨ˆç•«**ã€‚

ğŸš€ **å¦‚æœä½ æ­£åœ¨æ§‹å»º AI ç³»çµ±ï¼Œå»ºè­°ä½¿ç”¨ AWS SageMaker + Amazon S3 æ­é…ï¼**





è«‹å¹«æˆ‘ä»‹ç´¹å¦‚æœè¦ç”¨aws load AI modelè·Ÿ, load training dataset, åštraining, deployment, performance monitorè¦å¦‚ä½•é€²è¡ŒåŠæ€éº¼è¨­å®š, ä¹Ÿè«‹æä¾›python code

###### ChatGPT èªªï¼š

åœ¨ **AWS ä¸Šè¨“ç·´ã€éƒ¨ç½² AI æ¨¡å‹ï¼Œä¸¦ç›£æ§å…¶æ€§èƒ½** çš„å®Œæ•´æµç¨‹åŒ…æ‹¬ï¼š

1. **æº–å‚™ AWS ç’°å¢ƒ**
2. **ä¸Šå‚³æ•¸æ“šé›†åˆ° S3**
3. **ä½¿ç”¨ SageMaker è¨“ç·´ AI æ¨¡å‹**
4. **éƒ¨ç½²æ¨¡å‹**
5. **ç›£æ§ Performance**

ä»¥ä¸‹æ˜¯è©³ç´°æ­¥é©Ÿèˆ‡ Python ç¨‹å¼ç¢¼ç¤ºä¾‹ã€‚

---

## **1. AWS ç’°å¢ƒæº–å‚™**

é¦–å…ˆï¼Œç¢ºä¿ AWS ç’°å¢ƒå·²æº–å‚™å¥½ï¼š

- **AWS CLI** å·²å®‰è£ä¸¦è¨­ç½®å¥½æ†‘è­‰ (`aws configure`)
    
- **boto3** èˆ‡ **SageMaker SDK** å·²å®‰è£ï¼š
```python
pip install boto3 sagemaker
```
    
- ç²å– AWS è§’è‰² ARNï¼š
```python
aws iam get-role --role-name AmazonSageMaker-ExecutionRole
```
- **å®šç¾©å…¨åŸŸè®Šæ•¸**
```python
import boto3
import sagemaker

s3_bucket = "my-s3-bucket-name"
s3_prefix = "my-training-data"
role = "arn:aws:iam::123456789012:role/AmazonSageMaker-ExecutionRole"
region = "us-east-1"
```
---

## **2. ä¸Šå‚³æ•¸æ“šé›†åˆ° S3**

å°‡æ•¸æ“šé›†ä¸Šå‚³åˆ° S3 ä¾› SageMaker ä½¿ç”¨ï¼š
```python
import boto3
from pathlib import Path

s3 = boto3.client("s3")

def upload_to_s3(local_folder, bucket, prefix):
    for file_path in Path(local_folder).rglob("*"):
        if file_path.is_file():
            s3.upload_file(str(file_path), bucket, f"{prefix}/{file_path.name}")

# å‡è¨­æ•¸æ“šå­˜æ”¾æ–¼ 'data/' ç›®éŒ„
upload_to_s3("data/", s3_bucket, s3_prefix)

# è¨“ç·´æ•¸æ“šè·¯å¾‘
train_data_s3_path = f"s3://{s3_bucket}/{s3_prefix}/"
print("Training data uploaded to:", train_data_s3_path)
```


## **3. åœ¨ AWS SageMaker è¨“ç·´æ¨¡å‹**

ä½¿ç”¨ SageMaker è¨“ç·´ä¸€å€‹ **æ·±åº¦å­¸ç¿’ Surface Normal Estimation æ¨¡å‹**ã€‚

### **(1) å®šç¾© SageMaker è¨“ç·´è¨­ç½®

```python
from sagemaker.pytorch import PyTorch

estimator = PyTorch(
    entry_point="train.py",   # è¨“ç·´è…³æœ¬
    source_dir="code",        # åŒ…å« train.py çš„ç›®éŒ„
    role=role,
    framework_version="1.13", # PyTorch ç‰ˆæœ¬
    py_version="py39",
    instance_count=1,
    instance_type="ml.p3.2xlarge",  # é©åˆ GPU è¨“ç·´
    hyperparameters={
        "epochs": 10,
        "batch-size": 32,
        "learning-rate": 0.001
    },
    input_mode="File",
)

# å•Ÿå‹•è¨“ç·´
estimator.fit({"train": train_data_s3_path})

```

é€™æœƒå•Ÿå‹•ä¸€å€‹ SageMaker åŸ·è¡Œå€‹é«”ï¼Œä¸‹è¼‰æ•¸æ“šé›†ä¸¦é‹è¡Œ `train.py`ã€‚

---

### **(2) è¨“ç·´è…³æœ¬ `train.py`**

è©²è…³æœ¬å°‡æœƒåœ¨ SageMaker åŸ·è¡Œå€‹é«”å…§é‹è¡Œï¼Œä¸¦è‡ªå‹•è®€å– S3 æ•¸æ“šã€‚

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import argparse
import boto3
import os

# ä¸‹è¼‰æ•¸æ“š
def download_s3_data(s3_bucket, s3_prefix, local_dir):
    s3 = boto3.client("s3")
    os.makedirs(local_dir, exist_ok=True)
    response = s3.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)
    for obj in response["Contents"]:
        file_name = obj["Key"].split("/")[-1]
        s3.download_file(s3_bucket, obj["Key"], os.path.join(local_dir, file_name))

# è‡ªå®šç¾© Dataset
class SurfaceNormalDataset(Dataset):
    def __init__(self, root):
        self.files = list(Path(root).glob("*.png"))

    def __getitem__(self, index):
        img = transforms.ToTensor()(Image.open(self.files[index]))
        return img  # å‡è¨­æ¨™è¨»æ•¸æ“šå…§åµŒ

    def __len__(self):
        return len(self.files)

# è¨­å®šè¶…åƒæ•¸
parser = argparse.ArgumentParser()
parser.add_argument("--epochs", type=int, default=10)
parser.add_argument("--batch-size", type=int, default=32)
parser.add_argument("--learning-rate", type=float, default=0.001)
args = parser.parse_args()

# ä¸‹è¼‰æ•¸æ“š
download_s3_data("my-s3-bucket-name", "my-training-data", "/opt/ml/input/data/train")

# åŠ è¼‰æ•¸æ“š
dataset = SurfaceNormalDataset("/opt/ml/input/data/train")
dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)

# å®šç¾©æ¨¡å‹
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv = nn.Conv2d(3, 64, 3, padding=1)
        self.fc = nn.Linear(64, 3)  # XYZ Normal

    def forward(self, x):
        x = self.conv(x)
        x = self.fc(x.mean(dim=[2,3]))  # Global Average Pooling
        return torch.nn.functional.normalize(x, dim=1)

model = SimpleCNN()
optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)
criterion = nn.MSELoss()

# è¨“ç·´è¿´åœˆ
for epoch in range(args.epochs):
    for img in dataloader:
        optimizer.zero_grad()
        output = model(img)
        loss = criterion(output, img)  # å‡è¨­æ¨™è¨»å…§åµŒ
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch} - Loss: {loss.item()}")

# å„²å­˜æ¨¡å‹
torch.save(model.state_dict(), "/opt/ml/model/model.pth")

```

---

## **4. éƒ¨ç½²æ¨¡å‹**

ç•¶è¨“ç·´å®Œæˆå¾Œï¼Œå¯ä»¥éƒ¨ç½²æ¨¡å‹ï¼š

```python
from sagemaker.pytorch.model import PyTorchModel

model = PyTorchModel(
    model_data=estimator.model_data,  # ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹
    role=role,
    entry_point="inference.py",
    framework_version="1.13",
    py_version="py39",
)

predictor = model.deploy(instance_type="ml.m5.large", initial_instance_count=1)

```

---

### **5. ç›£æ§æ¨¡å‹æ€§èƒ½**

AWS æä¾› **CloudWatch Logs** ä¾†ç›£æ§æ¨ç†æ€§èƒ½ï¼š
```python
import boto3

logs = boto3.client("logs")
response = logs.describe_log_groups()
print(response)  # ç²å– SageMaker ç›£æ§æ—¥èªŒ

```

å¦‚æœè¦ç›£æ§ GPU ä½¿ç”¨ç‡ï¼Œå¯åœ¨ `inference.py` ä¸­åŠ ï¼š

```python
import GPUtil
print(GPUtil.showUtilization())
```

---

## **ç¸½çµ**

|**æ­¥é©Ÿ**|**æ–¹æ³•**|
|---|---|
|**æ•¸æ“šä¸Šå‚³**|`boto3` å°‡è¨“ç·´æ•¸æ“šä¸Šå‚³åˆ° S3|
|**æ¨¡å‹è¨“ç·´**|ä½¿ç”¨ SageMaker PyTorch Estimator|
|**æ¨¡å‹éƒ¨ç½²**|`PyTorchModel.deploy()`|
|**ç›£æ§**|AWS CloudWatch, GPUtil|

é€™æ¨£å¯ä»¥åœ¨ AWS ä¸Šå®Œæˆ **AI è¨“ç·´ã€éƒ¨ç½²èˆ‡ç›£æ§**ï¼Œé©ç”¨æ–¼ Surface Normal Estimation æˆ–å…¶ä»– AI æ‡‰ç”¨ï¼å¦‚æœéœ€è¦ **è‡ªå‹•åŒ– Pipeline**ï¼ˆå¦‚ CI/CDï¼‰ï¼Œå¯ä»¥å†åŠ  **AWS Step Functions** ä¾†ç®¡ç†æ•´å€‹æµç¨‹