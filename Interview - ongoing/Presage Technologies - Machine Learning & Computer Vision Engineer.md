
[AI] Presage Technologies - Machine Learning & Computer Vision Engineer  
  
Location:   St. Louis, Missouri  
Salary: $13.5k - 25k  
  
2025.04.09 [HR 15min] 1:20pm Katie Emilien  
2025.04.18 [Tech 60min] 1:00pm jim

https://www.linkedin.com/jobs/view/4168103710/?alternateChannel=search&refId=628c8720-e290-4ec2-abc6-40e13c2552ba&trackingId=dJw3CbakTTSr87foc6roLQ%3D%3D

3D CNNs 
time-varying signals

|                                 |     |
| ------------------------------- | --- |
| [[###Presage Technologies公司介紹]] |     |
| [[###非接觸式軟體脈搏血氧儀]]              |     |
|                                 |     |


**WHO WE ARE**

At Presage Technologies, we believe in improving the quality of healthcare while also making it more affordable and accessible. Over 90% of the world’s population has access to a device that can power our software, but less than half have access to basic health services. We are aiming to close that gap by developing cutting-edge artificial intelligence and <mark style="background: #FFF3A3A6;">video analytics to transform consumer electronics and mobile phone consumer apps into sophisticated health sensing platforms. 在 Presage Technologies</mark>，我們致力於提升醫療保健的質量，同時也使其更實惠且便利。世界上超過 90% 的人口可以使用支援我們軟體的設備，但只有不到一半的人口可以使用基本的醫療服務。我們的目標是透過開發尖端人工智慧和視訊分析技術將消費性電子產品和手機消費者應用程式轉變為複雜的健康感測平台，從而縮小這一差距。

Our Machine Learning Engineer will play an integral role in the development and progression of our state-of-the-art technologies. You will come up with solutions to help solve some of the toughest computer vision problems society faces. General tasks may include, but are not limited to: 我們的機器學習工程師將在我們最先進的技術的開發和進步中發揮不可或缺的作用。您將找到解決方案來幫助解決社會面臨的一些最棘手的電腦視覺問題。一般任務可能包括但不限於：

- Design, build, deploy, and improve machine learning, deep learning, and computer vision algorithms to analyze <mark style="background: #FFF3A3A6;">video and biosignal data and generate functional metrics</mark>. 設計、建構、部署和改進機器學習、深度學習和電腦視覺演算法，以分析視訊和生物訊號數據並產生功能指標。
- Train, validate, and optimize models using large data sets, ensuring high performance and generalization. 使用大型資料集訓練、驗證和最佳化模型，確保高效能和泛化。
- Guide project directions and research and development efforts. 指導專案方向和研發力道。
- Contribute to high impact publications and patents. 為高影響力的出版物和專利做出貢獻。


- MS/PhD in Computer Science, Statistics, Applied Mathematics or a closely related field. 計算機科學、統計學、應用數學或密切相關領域的碩士/博士學位。
- 5+ years of demonstrated experience developing/implementing Machine Learning and/or Artificial Intelligence algorithms in computer vision 擁有 5 年以上在電腦視覺解決方案中開發/實施機器學習和/或人工智慧演算法的經驗。 
- solutions.- Expert in Python. Python 專家
- Experience analyzing <mark style="background: #ABF7F7A6;">time-varying signals</mark>, including <mark style="background: #ABF7F7A6;">robust feature extraction and classification</mark>. 具有分析時變訊號的經驗，包括穩健的特徵提取和分類。
- Experience building custom deep learning architectures for inference from video with<mark style="background: #FFF3A3A6;"> 3D CNNs and/or RNNs</mark>. 擁有使用 3D CNN 和/或 RNN 從影片中進行推理的自訂深度學習架構的經驗。
- Experience building custom deep learning architectures for inference from multiple time-varying signals. 擁有建立自訂深度學習架構以從多個時變訊號進行推理的經驗。
- Ability to dynamically collaborate in a small team setting. 能夠在小團隊環境中動態協作。
- Ability to brief and report results to peers as well as stakeholders. 能夠向同事和利害關係人簡要介紹和報告結果。
- Expert in using Tensorflow or PyTorch. 精通使用 Tensorflow 或 PyTorch。
- Experience with other Machine Learning models including decision trees (XGBoost, LightGBM, etc.). 具有其他機器學習模型（包括決策樹（XGBoost、LightGBM 等））的經驗。


Highly Desirable

- Deploying models at the edge/mobile in C++, Java, Javascript, Objective C. 使用 C++、Java、Javascript、Objective C 在邊緣/行動裝置部署模型。
- Experience with hyperspectral imaging and/or time-varying video analysis. 具有高光譜成像和/或時變視訊分析經驗。
- Experience combining <mark style="background: #BBFABBA6;">multimodal imaging signals</mark>. 結合多模態成像訊號的經驗。- Strong background in statistics. 具有深厚的統計學背景。
- Rapid code prototyping skills. 快速程式碼原型設計技能。
- Relevant work experience in computer vision and machine learning for applications to health care 具備電腦視覺和機器學習在醫療保健領域的應用相關工作經驗

INTERVIEW PROCESS

- Phase 1: Submit a Resume
- Phase 2: Downselection for Introductory Interview with Operations Leadership with Q&A
- Phase 3: Downselection for Machine Learning Background Interview
- Phase 4: Downselection for Machine Learning Performance Task- 
- Phase 5: Negotiations and Offer

**Timeline**: The entire process can occur in less than two weeks for the right candidate.



### Presage Technologies公司介紹

Presage Technologies 是一家位於美國的公司，專注於**醫療保健技術**領域，特別是**利用機器學習和先進的數學處理來分析影片影像**。他們的技術旨在將基於硬體的醫療設備和耗時的流程轉化為軟體，從而實現醫療保健的自動化。

https://presagetechnologies.com/

根據公開資訊，Presage Technologies 的產品之一是一款**非接觸式的軟體脈搏血氧儀**，可以透過現代手機、平板電腦或帶有鏡頭的個人電腦運作。這項技術已於 2023 年獲得 FDA 的初步批准，旨在為需要脈搏血氧監測的患者提供低成本、無摩擦的遠程患者監測 (RPM) 體驗。

**關於 Machine Learning & Computer Vision Engineer 這個職缺，我們可以從一般的職位描述來推斷其職責和所需的技能：**

**主要負責的產品和任務可能包括：**

- **開發和優化電腦視覺演算法：** 針對各種應用，例如影像處理、物件偵測、人臉追蹤、身體追蹤、關鍵點估計、場景重建與理解、影像分割等。
- **設計和實作機器學習模型：** 特別是深度學習模型，用於電腦視覺相關任務。
- **研究和原型設計先進的電腦視覺和深度學習方法：** 開發滿足產品需求的解決方案。
- **設計演算法評估框架：** 定期安排和報告演算法的效能評估。
- **制定選擇合適感測器的流程：** 例如相機，並開發相應的影像處理演算法，重點在於傳統電腦視覺、3D 幾何和深度學習。
- **將電腦視覺解決方案整合到生產系統中：** 並根據回饋和效能指標持續改進。
- **與跨職能團隊合作：** 理解專案需求並交付符合業務目標的解決方案。
- **撰寫可重複使用、可擴展、經過測試且有良好註解的程式碼。**
- **撰寫和展示演算法設計、開發和評估的進度文件。**
- **領導專案/系統的程式碼審查。**

**應該具備的技能：**

- **電腦科學、人工智慧或相關領域的學士或碩士學位。**
- **2 年以上電腦視覺技術和機器學習演算法的工作經驗。**
- **精通 Python 和相關框架：** 例如 OpenCV, TensorFlow, PyTorch, Keras 等。
- **熟悉影像處理技術：** 例如濾波、轉換、增強等。
- **熟悉深度學習模型在物件偵測、影像分割和模式識別等任務中的開發和部署。**
- **有相機校準、立體視覺、追蹤、3D 點雲、配準和相關演算法開發的經驗。**
- **具備設計、訓練和部署生產級電腦視覺應用深度學習架構的經驗，並對最新的電腦視覺/深度學習方法和文獻有廣泛的理解。**
- **熟悉 3D 視覺和投影幾何。**
- **具備在雲端環境中部署 AI 模型的經驗（例如 AWS、Google Cloud、Azure）。**
- **良好的問題解決和分析思維能力。**
- **注重細節，尤其是在處理大型數據集和複雜演算法時。**
- **優秀的溝通能力，能夠向非技術團隊成員傳達技術概念。**
- **研究能力，能夠跟上人工智慧和電腦視覺領域的最新進展。**
- **熟悉資料標註和擴增工具。**
- **熟悉容器化技術，如 Docker。**
- **有在知名電腦視覺或機器學習會議/期刊上發表論文的經驗（可能為加分項）。**

**關於面試流程 (interview process) 和是否有程式碼考試 (coding exam)：**

由於 Presage Technologies 是一家相對較小的私營公司，並且沒有公開詳細的面試流程資訊，以下是一些基於一般科技公司和類似職位的推測：

**面試流程可能包括：**

1. **初步篩選 (HR Screening):** 人力資源部門可能會先審閱您的履歷和求職信，以確認您的基本資格和經驗是否符合職位要求。
2. **技術面試 (Technical Interview):** 這通常是面試的核心部分，您可能會與團隊成員或技術主管進行面談，討論您的技術背景、相關專案經驗以及解決問題的能力。可能會深入詢問您在機器學習和電腦視覺方面的知識，例如演算法原理、模型選擇、訓練技巧、效能優化等。
3. **程式碼考試 (Coding Exam) 或實作練習 (Practical Exercise):** 許多機器學習和電腦視覺工程師的職位都會包含程式碼考試或實作練習，以評估您的編程技能和實際解決問題的能力。這可能包括：
    - **線上程式碼測試平台：** 例如 LeetCode、HackerRank 等，測試您的演算法和資料結構知識。
    - **現場編程：** 在面試過程中，面試官可能會要求您編寫程式碼來解決特定的電腦視覺或機器學習問題。
    - **專案展示或討論：** 您可能會被要求展示您過去的相關專案，並深入討論您的設計思路、實作細節和遇到的挑戰。
4. **行為面試 (Behavioral Interview):** 面試官可能會詢問您關於團隊合作、溝通能力、解決衝突、適應能力等方面的問題，以評估您的軟技能和工作態度是否適合公司的文化。
5. **最終面試 (Final Interview):** 如果您通過了前幾輪面試，可能會與更高階的主管或領導層進行最終面談。

**是否有程式碼考試 (coding exam)：**

**很有可能會有程式碼考試或某種形式的程式設計評估。** 對於機器學習和電腦視覺工程師這樣的職位，編程能力至關重要。公司需要確保候選人具備紮實的程式設計基礎，能夠有效地實作和調試相關的演算法和模型。

**要為面試做準備，您可以：**

- **仔細研究 Presage Technologies 及其產品。** 了解他們在醫療保健領域的應用和技術方向。
- **複習機器學習和電腦視覺的基礎知識和常用演算法。**
- **準備好討論您過去的相關專案，並能深入解釋您所做的貢獻和遇到的挑戰。**
- **練習使用 Python 和相關的函式庫（OpenCV, TensorFlow, PyTorch 等）解決常見的電腦視覺和機器學習問題。**
- **準備好回答關於您的編程技能、專案經驗、問題解決方法和團隊合作能力的問題。**

由於 Presage Technologies 的資訊相對有限，建議您在收到面試機會時，直接向招聘人員詢問關於面試流程和是否有程式碼考試的具體安排。祝您面試順利！


### 非接觸式軟體脈搏血氧儀

Presage Technologies 的非接觸式軟體脈搏血氧儀，主要基於以下原理和技術細節：

- **光體積描記術 (Photoplethysmography, PPG):** 這種技術利用數位攝影機記錄特定區域 (例如前額) 的影像，分析皮膚顏色隨心跳產生的微小變化。心臟脈搏會引起血液容積的變化，進而導致光吸收的變化。透過分析這些變化，可以提取出脈搏訊號。
- **電腦視覺 (Computer Vision):**
    - **影像擷取與處理：** 使用智慧型手機或其他裝置上的攝影機擷取影像或影片。
    - **區域偵測 (Region of Interest, ROI):** 電腦視覺演算法用於自動偵測臉部或身體的特定區域，例如前額，以進行分析。
    - **訊號提取：** 從影像的紅色和綠色通道中提取 PPG 訊號。
- **時變訊號 (Time-Varying Signals) 分析:**
    - **訊號分解：** 使用訊號分解技術 (例如 EEMD) 將 PPG 訊號分解成不同頻率的訊號。
    - **獨立成分分析 (Independent Component Analysis, ICA):** 用於分離和提取有意義的脈搏訊號成分。
    - **血氧飽和度 (SpO2) 估算：** 分析提取的脈搏訊號，估算血氧飽和度。這通常涉及分析訊號中交流 (AC) 和直流 (DC) 成分的比率。

總結來說，Presage Technologies 的技術利用電腦視覺從影像中提取脈搏訊號 (PPG)，然後分析 PPG 訊號中的時變特性，以非接觸方式估算血氧飽和度。



詳細解釋 Presage Technologies 非接觸式軟體脈搏血氧儀產品中使用的 3D CNN 模型和時變訊號處理，特別是強健特徵提取和分類，需要基於已公開的資訊進行推測和合理的假設，因為該公司的具體技術細節並未完全公開。

以下是一個基於常見的時序訊號分析和 3D CNN 應用於影片分析的框架，來推測其可能的技術細節，並提供一個簡化的 PyTorch 程式碼範例。

**推測的技術細節：**

1. **影像擷取與預處理 (Image Acquisition and Preprocessing):**
    
    - **輸入：** 透過智慧型手機、平板電腦或電腦的 RGB 鏡頭獲取連續的影片幀序列。通常會聚焦於臉部或特定的身體區域（例如前額、臉頰），因為這些區域的皮膚血管較為豐富。
    - **臉部/區域偵測與追蹤 (Face/Region Detection and Tracking):** 使用電腦視覺演算法（例如基於深度學習的目標偵測模型如 YOLO 或 Faster R-CNN，或傳統方法如 Haar 特徵）自動偵測並追蹤感興趣的區域。這確保了後續分析的區域穩定。
    - **對齊與歸一化 (Alignment and Normalization):** 為了減少頭部運動和光照變化的影響，可能會對追蹤到的區域進行對齊（例如基於關鍵點）和像素值歸一化（例如縮放到 [0, 1] 或進行 Z-score 標準化）。
2. **時變訊號提取 (Time-Varying Signal Extraction):**
    
    - **平均像素強度時間序列 (Temporal Sequence of Average Pixel Intensities):** 在每個影片幀的感興趣區域內，提取特定顏色通道（通常是紅色和綠色通道，因為血液對這些波長的吸收率不同）的平均像素強度。隨著心臟搏動，血液容積會週期性變化，導致這些顏色通道的強度發生微小的、時間相關的變化。這樣就形成了每個顏色通道的時間序列訊號。
    - **其他時域特徵 (Other Temporal Features):** 除了平均像素強度，可能還會提取其他基於時間的統計特徵，例如方差、標準差、自相關性等，以捕捉更豐富的皮膚顏色變化資訊。
3. **3D CNN 模型用於強健特徵提取 (3D CNN Model for Robust Feature Extraction):**
    
    - **輸入資料 (Input Data):** 3D CNN 的輸入不再是單張靜態影像，而是一個短時間內的連續幀序列（例如連續 32 幀或 64 幀），每個幀包含感興趣區域的多個顏色通道（例如 RGB）。因此，輸入的維度可能是 `(批次大小, 時間步長, 通道數, 高度, 寬度)`。
    - **3D 卷積層 (3D Convolutional Layers):** 3D 卷積核不僅在空間維度（高度和寬度）上滑動，也在時間維度上滑動，從而能夠同時捕捉影像的空間特徵以及這些特徵在時間上的演變。這對於理解皮膚顏色隨時間的微小變化至關重要。不同的 3D 卷積核可以學習提取不同的時空特徵，例如局部運動模式、顏色變化的時間模式等。
    - **池化層 (Pooling Layers):** 3D 池化層（例如 3D 最大池化或平均池化）用於降低特徵圖的維度，並提高模型對微小時間或空間變化的魯棒性。
    - **非線性激活函數 (Non-linear Activation Functions):** 例如 ReLU，引入非線性，使模型能夠學習更複雜的時空關係。
    - **批次歸一化 (Batch Normalization):** 提高訓練的穩定性和速度。
    - **輸出特徵 (Output Features):** 經過多個 3D 卷積和池化層後，模型會提取出一組高階的時空特徵圖。這些特徵圖捕捉了與脈搏和血氧相關的皮膚顏色變化的時空模式。
4. **分類 (Classification) 或回歸 (Regression):**
    
    - **展平 (Flatten):** 將最後的 3D 特徵圖展平成一個一維向量。
    - **全連接層 (Fully Connected Layers):** 一個或多個全連接層用於將提取到的高階特徵映射到最終的輸出。
    - **輸出層 (Output Layer):**
        - **分類：** 如果目標是將血氧飽和度劃分為不同的範圍（例如正常、低），則輸出層可能使用 Softmax 激活函數，輸出每個類別的機率。
        - **回歸：** 如果目標是直接預測血氧飽和度的具體數值，則輸出層可能是一個具有線性激活函數的單個輸出單元。
5. **損失函數與優化器 (Loss Function and Optimizer):**
    
    - **分類：** 常用的損失函數包括交叉熵損失 (Cross-Entropy Loss)。
    - **回歸：** 常用的損失函數包括均方誤差 (Mean Squared Error, MSE) 或平均絕對誤差 (Mean Absolute Error, MAE)。
    - **優化器：** 常用的優化器包括 Adam、SGD 等。

**Time-Varying Signals 的作用：**

- **核心資訊載體：** 皮膚顏色隨心跳產生的微小變化是血氧估算的基礎。這些變化是典型的時變訊號，其頻率和幅度與心率和血液容積相關。
- **特徵提取的基礎：** 3D CNN 模型通過分析連續幀中的這些時變訊號，學習提取與血氧相關的強健特徵。模型能夠捕捉到這些訊號在時間上的模式和變化趨勢，而僅僅分析單張靜態影像是無法獲得這些資訊的。
- **運動魯棒性：** 透過分析短時間內的連續幀，3D CNN 有望學習到對輕微運動不敏感的特徵。時間上的冗餘資訊可以幫助模型從雜訊中提取出真實的脈搏訊號。

**PyTorch 程式碼範例 (簡化版):**

Python

```
import torch
import torch.nn as nn
import torch.nn.functional as F

class TemporalBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        super(TemporalBlock, self).__init__()
        self.conv3d = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)
        self.bn = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv3d(x)
        x = self.bn(x)
        x = self.relu(x)
        return x

class SpatioTemporalCNN(nn.Module):
    def __init__(self, in_channels, num_classes):
        super(SpatioTemporalCNN, self).__init__()
        self.temporal_block1 = TemporalBlock(in_channels, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))
        self.temporal_block2 = TemporalBlock(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))
        self.temporal_block3 = TemporalBlock(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(128 * 8 * 8, 256) # 假設經過池化後的時間維度為 8，空間維度為 8x8
        self.relu_fc = nn.ReLU(inplace=True)
        self.fc2 = nn.Linear(256, num_classes)

    def forward(self, x):
        # x 的 shape: (batch_size, time_steps, channels, height, width)
        x = self.temporal_block1(x)
        x = self.pool1(x)
        x = self.temporal_block2(x)
        x = self.pool2(x)
        x = self.temporal_block3(x)
        x = self.pool3(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu_fc(x)
        x = self.fc2(x)
        return x

# 假設輸入是連續 32 幀的 RGB 影像，目標是二分類（例如：低血氧 vs. 正常血氧）
batch_size = 32
time_steps = 32
channels = 3
height = 64
width = 64
num_classes = 2

# 創建一個範例輸入張量
input_tensor = torch.randn(batch_size, time_steps, channels, height, width)

# 創建模型實例
model = SpatioTemporalCNN(in_channels=channels, num_classes=num_classes)

# 前向傳播
output = model(input_tensor)
print(output.shape) # 輸出 shape: (batch_size, num_classes)
```

**請注意：**

- 這是一個非常簡化的 3D CNN 模型範例，實際應用中模型的架構可能會更複雜，包含更多的卷積層、池化層、殘差連接 (Residual Connections) 或其他先進的網路結構。
- 程式碼中的超參數（例如卷積核大小、步長、通道數、全連接層的維度等）需要根據具體的資料集和任務進行調整和優化。
- 實際的血氧估算可能不僅僅依賴分類，更可能是回歸到一個連續的血氧飽和度數值。
- 強健的特徵提取還可能涉及到更複雜的訊號處理技術，例如頻域分析、小波變換等，這些技術可能會與 3D CNN 模型結合使用。

總之，Presage Technologies 的非接觸式血氧儀很可能利用電腦視覺技術從影片中提取皮膚顏色隨時間變化的資訊，並使用 3D CNN 模型來學習這些時空訊號中的複雜模式，從而實現對血氧飽和度的準確估計。時變訊號是核心的輸入，而 3D CNN 則是一個強大的工具，用於從這些訊號中提取強健且具有判別性的特徵，最終用於分類或回歸任務。