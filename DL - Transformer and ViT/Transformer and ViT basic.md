

Ref1: [逐步解析Vision Transformer各细节，附带源码与微调讲解](https://zhuanlan.zhihu.com/p/690406548)

Ref2: [[論文導讀] Vision Transformer (ViT) 附程式碼實作](https://medium.com/@andy6804tw/%E8%AB%96%E6%96%87%E5%B0%8E%E8%AE%80-vision-transformer-vit-%E9%99%84%E7%A8%8B%E5%BC%8F%E7%A2%BC%E5%AF%A6%E4%BD%9C-379306ea2fb)

Ref3: [Vision Transformer 必读系列之图像分类综述(一): 概述](https://developer.aliyun.com/article/912274)

Ref4: [[Transformer_CV] Vision Transformer(ViT)重點筆記](https://hackmd.io/@YungHuiHsu/ByDHdxBS5)

Ref5: [Vision Transformer（ViT）PyTorch代码全解析（附图解）](https://blog.csdn.net/weixin_44966641/article/details/118733341)

Ref6: [ViT — Vision Transformer : Convolution is dead, long live Transformers!](https://applehank.medium.com/vit-vision-transformer-convolution-is-dead-long-live-the-self-attention-bbced72a8487)


**Multi-head self attention**
Ref6: [[AI學習筆記] 李宏毅課程 Transformer 機制解說 (上)](https://andy6804tw.github.io/2021/07/30/ntu-transformer(1)/#encoder)

Ref7: [Multi-headed Self-attention（多头自注意力）机制介绍](https://zhuanlan.zhihu.com/p/365386753)

Ref8: [Attention注意力机制综述（二）--多头自注意力机制（含代码）](https://zhuanlan.zhihu.com/p/669330242)

Ref9: [transformer中QKV的通俗理解(渣男与备胎的故事)](https://blog.csdn.net/Weary_PJ/article/details/123531732)

**Decoder**
Ref5: [Transformer Decoder详解](https://zhuanlan.zhihu.com/p/502249065)

Ref6: 