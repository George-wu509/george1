
转眼间，自DETR被提出已经过去了2年了，如今又迎来了2023年（截至本章初稿完成之际），可以说，这是Transformer框架在CV领域发力的第3个年头了。时至今日，对Transformer的质疑声越来越小了，它的强大得到了越来越多、越来越广泛的认可。可以说，如今的CV领域，Transformer已经和CNN是各分半壁江山了。

现如今，目标检测技术继DETR的高潮后，又进入到了一个相对平稳的发展期，短时间内可能也看不到重要的突破了，更多的是在进一步挖掘现有工作的性能和可能性，比如近期爆火的Segment Anything（SAM），其网络结构就是常见的[ViT结构](https://zhida.zhihu.com/search?content_id=227388868&content_type=Article&match_order=1&q=ViT%E7%BB%93%E6%9E%84&zhida_source=entity)搭配上Prompt技术等，没有花里胡哨的东西，但表现出的性能是极其不俗的。

继DETR被提出后，[Deformable DETR](https://zhida.zhihu.com/search?content_id=227388868&content_type=Article&match_order=1&q=Deformable+DETR&zhida_source=entity)、Conditional DETR、DINO等一系列工作相继被提出，不断地去解决原始的DETR所暴露出来的诸多，不断将这一框架的性能逼近最优。DETR的问世为广大的研究者揭示了一条新的研究路线，随后，大量的基于DETR框架的新工作问世，渐进式地解决DETR框架的诸多问题。比如：

- **Deformable DETR**提出了Deformable Attention解决标准Transformer中的Attention的 O(N2) 的问题，加快模型的收敛速度和降低算法的复杂度，同时又引入了多尺度特征解决小目标检测性能不足的问题；
- **Group DETR**引入多个object queries，既能保留DETR的end-to-end推理的优势，同时还能利用训练中的one-to-many优势来提升性能，加快模型的收敛速度；
- **DAB-DETR**通过引入“去噪学习”的思想来加快DETR的收敛速度，而随后的DINO则彻底完善这套框架，实现了DETR在COCO数据集上的“霸榜”……

可以说，在这些“量变”的工作基础上，如今的DETR已经发生了“质变”，已经成为了目标检测领域中的新的“巨头”，但是，这个“巨头”的缺陷也是十分明显的，那就是**“实用性”差**。

整体来看，现有的目标检测框架大致可以分为**CNN based**以及**Transformer based**。对于前者，通常又可以划分为以Faster RCNN和RetinaNet为代表的“**学术派**”和以[YOLO系列](https://zhida.zhihu.com/search?content_id=227388868&content_type=Article&match_order=1&q=YOLO%E7%B3%BB%E5%88%97&zhida_source=entity)为代表的“**工业派**”（这两个派别是笔者擅自划分的，如有异议，还请指出）。

所谓的“学术派”，主要是指那些常被用在学术论文里的Baseline工作，典型的如RetinaNet、Faster RCNN以及Mask RCNN等，每当有新的ViT结构被提出，这些工作总是会被用作COCO experiments的Baseline，去验证那些新提出的ViT的有效性。这些工作的特点就是结构简洁，训练技巧少，可优化的空间很大。通常，这些工作都侧重在学术研究上，被用于验证一些新的想法的“可行性”，因而相对不太重视对检测速度的影响，即“实时性”，因为从长远的目光来看，当前被认为“不实用”的技术都可以在未来的某个时刻由发达的硬件技术所解决，这也是学术研究与工业研究的差别之一；

所谓的“工业派”，主要研究以面向工业部署为主要应用点的算法框架。不同于学术研究所侧重的“可行性”验证，“工业派”的研究更加注重算法的“实用性”，其中最重要的验证指标之一就是“实时性”，因为工业场景中往往很少会有大量的V100显卡供我们使用。这类工作旨在以较低的FLOPs和模型参数量的条件下，尽可能达到较为可观的检测性能，解决实际场景下的一些具体问题。很多时候，这类工作的性能往往会和“学术派”的工作有着较大的性能差距，而为了尽可能弥补这些差距，往往会在诸多“后验”层面上下功夫，比如YOLO系列常用的“马赛克增强”、“混合增强”以及大epoch训练时长等策略，这些策略往往不会伤害到模型的推理性能，但会大幅度提升模型的性能，充分挖掘出在此种严格条件限制下的算法性能。

|学术派|工业派|
|---|---|
|Faster RCNN|YOLOv3~v8|
|RetinaNet|CenterNet|
|Mask RCNN|SSD|
|……|……|

不论是哪一派，在CNN这套框架下，相关技术都已经发展得格外成熟了——写论文就用Faster RCNN和RetinaNet做Baseline，搞实时性研究就上YOLO系列。但作为检测领域的另一个巨头——DETR系列，相关研究很少会涉及到“实用性”，大多数都还是在验证新模块、新改进和新优化的“可行性”。

尽管DETR系列已经在短短两年的时间里就打破了CNN的垄断地位，但就“实用性”而言，DETR仍旧无法取代、甚至是媲美于YOLO系列，后者依旧是工业领域中的“翘楚”，仍旧有着不可被取代的优势。YOLO的强势不仅仅是得益于诸多训练技巧的加持，更重要的是当前硬件发展对CNN的友好，这是Transformer**暂时**所不具备的，也正因此，一些Transformer-based的工作也大量吸收了CNN的优势，尽可能达到面向部署端的友好。

但是，事物总是要发展的，问题总是要被发现和解决的，既然DETR不具备较好的“实用性”，那么提高它的“实用性”就是一个很重要的研究点。YOLO系列固然稳定又可靠，但也存在着诸多问题，只不过这些问题暂时被其光芒所遮蔽，但总会有人穿过那片光芒，窥探到其下的斑驳甚至污槽。既然DETR的有效性已经在学术上得到了广泛的验证，那么研究一款可以实时运行的、具有良好实用性的DETR检测器是很有意义的。

对于这个问题，百度近期提交了一份“答案”：**RT-DETR（Real-time DETR）**。

![[Pasted image 20250325222318.png]]

相较于最新的YOLOv8，RT-DETR以**较短的训练轮次**（75~80 epoch）和**较少的数据增强**（没有马赛克增强）的策略，在**同等测试条件下**（640x640）展现出了更强的性能和更好的平衡，且检测速度也与YOLO系列相媲美，正如图2所展示的对比结果。
![[Pasted image 20250325223023.png]]就实时性而言，RT-DETR出色地完成了它的任务，实现了完全可以与YOLO系列所媲美的平衡性。当然，这只是纸面上的数据，而YOLO系列是久经工业界的考验的，且得益于当前的硬件对CNN的友好支持，YOLO系列的实用性是毋庸置疑的，而DETR在这一块还需要接受大量的来自工业界的测试。

另一方面，尽管RT-DETR的训练时长为72epoch左右，但这并不代表RT-DETR的训练周期就一定快于YOLO系列，因为“72 epoch的耗时 < 300 epoch的好使”显然不是一个严格不等式，就笔者的经验而言，以RT-DETR-R50和YOLOv5-L为例，前者一个epoch所消耗的时间远大于后者的一个epoch时间，致使RT-DETR的70多epoch的总耗时要比YOLOv5的300epoch大很多，这一差距主要还是归结于RT-DETR所采用的Deformable attention的计算量和计算速度在现有的硬件设备上尚不具备可媲美与卷积操作的性能，不过，这无疑是阶段性的问题，从发展的眼光来看，未来的硬件技术也会很好地支持DETR框架，不过，也许到了那一天，如今气势汹汹的DETR框架恐怕也会成为了昨日黄花，被不断迭代出来的新技术淘汰掉了吧。

## 二、RT-DETR研究动机

在序言中，我们已经提到了，百度之所以做这么一件事，其目的是**希望为工业界提供一款实用性较高的DETR系列的实时检测器**，因为当下的DETR框架无疑是通用目标检测领域中最受瞩目的、最具潜力的新框架，而同赛道的主打实时检测的YOLO系列则已趋近于完善，不论是YOLOv5还是YOLOv8，都只是在已经成熟的框架上继续修修补补，拔高性能，但不涉及框架性的变动，也是因为当下的DETR系列虽强大但滞缓，推理速度对实用性有严格要求的工业界尚不友好，因此，总该要有人来解决这两个问题。就论文的纸面数据来说，RT-DETR无疑是这件事是做成了的，性能够高，速度也够快。

另一方面，除了从实时性的角度出发来做这次研究，RT-DETR的另一个研究动机则是解决“**两套阈值**”的麻烦。

熟悉YOLO系列的读者应该知道，当我们在COCO验证集（或测试集）上去测试mAP时，我们总是要先完成**阈值筛选（Confidence threshold）**和**非极大值抑制（NMS）**处理两个关键步骤，前者的目的是滤除低得分的检测框（通常这些低得分的框就是背景），后者的目的是滤除那些对同一物体的冗余响应（一个物体可能被多个框检测到）。在完成了这两个步骤后，剩下的检测框就将参与到mAP的计算中去，正如图3所示。

但是，在计算mAP时，阈值筛选环节往往会使用**十分低的阈值**，以YOLOv5为例，用于筛选前景和背景的预测框的得分阈值为0.001，NMS中的iou阈值为0.6，换言之，只要得分高于0.001，就会被保留，只要iou不超过0.6，就不会被认为是冗余框。但是，当一个框的得分为0.001的时候，我们真的能认为这是个“好框”吗？很多时候，一个预测框的得分为0.1，0.3，甚至是0.5的时候，我们也不免会觉得这个框的精确性还是不够，更何况是0.001这么低的值呢？但是，我们若是拉高得分阈值，比如将0.001提升至0.3，不论是mAP还是recall，都会下降，从纸面数据来说，这种“下降”是无法被接受的。

然而，在实际运行的时候，比如跑一个实际场景的demo，不论是阈值还是NMS中的iou阈值，我们都可以适当调高一些，比如，得分阈值提高到0.3，NMS的iou阈值提升到0.45，之所以可以这么做，是因为在实际运行的时候，我们都会下意识地认为**那些低得分的框往往都是背景，或者低质量的前景预测，没有保留下来的必要**，还能减少后处理的运算压力，而NMS的iou阈值提到高0.45，可以更好地去冗余框。

为了更直观地理解以上两点的区别，我们使用由笔者实现的42.9 AP的YOLOv3在COCO数据集上做一次测试对比，对比的可视化结果如下方的图4所示。

![[Pasted image 20250325230522.png]]其中，在第一行所展示的结果中，我们设置得分阈值为0.001，NMS的iou阈值为0.65，在第二行所展示的结果中，我们设置得分阈值为0.3，NMS的iou阈值为0.45。从图中可以很明显的看到，在第一套阈值的处理下，存在大量低质量的得分框，远不及第二套阈值的设置，而这些低质量得分框都是会参与到mAP的计算中去，直观上会觉得应该是第二套阈值所算出来的mAP值要更高，但是，使用第一套阈值所计算出来的AP为42.9%，而第二套阈值的AP只有39.2%，如下方的表格1所示。试问，在写论文的时候，你会选择哪个结果呢？我们是不是有理由地怀疑当前的AP指标是存在一些“空子”可钻呢？

|CT|NT|AP|AP50|
|---|---|---|---|
|0.001|0.65|42.9|63.5|
|0.3|0.45|39.2|57.1|

对于这一问题，RT-DETR作者团队在文章的一开头就做了分析，如下方的图5所示，作者团队是以YOLOv5和YOLOv8为例，可以看到，在不同的得分阈值的设置下，“有效的”预测框的数量是完全不同的，尤其是使用anchor box的YOLOv5，变化更为显著，再一次证明了anchor box的冗余性。

因此，“**两套阈值**”的设置显然是一种矛盾，就如同老话说的，见人说人话，见鬼说鬼话。从某种意义上来讲，这两套阈值完全就是多余的超参数，而很多论文中都不会提到这两个对性能有直接影响的超参数的设置。事实上，这样的问题也不仅存在于YOLO中，对于绝大多数的Dense detection的检测器，如RetinaNet和SSD等，都有着这样不一致的矛盾。从发展的眼光来看，这种“两套阈值”设置绝对是当前的目标检测框架的一个弊病。

DETR的一个创新就是将检测问题转换为无序的序列输出问题，将原本的“**密集检测**”变成了“**稀疏检测**”，再配合一些其他的设置，DETR系列的检测器往往是**不需要后处理**的，即不需要做阈值筛选和NMS，只需对最终的预测结果做一次topk操作即可。

以Deformable DETR为例，假定object queries的维度被设置为300，那么最终就会输出300个预测框，然后依据得分的高低保留前100个预测框，去参与mAP的计算。而在实际运行时，也是只可视化这100个预测框，当然，这当中还会设置一个可视化阈值，毕竟这100个预测框总是要有一些低得分的“背景框”。但相较于YOLO，DETR的后处理不仅仅是干净整洁，而且不需要“两套阈值”，不论是计算mAP还是运行demo，都只需要做一次topk操作即可。而DETR检测器之所以可以做到如此简洁，正是因为DETR更贴契合“End-to-end”的理念，很大程度地摒弃了以往包含得分阈值筛选&非极大值抑制在内的后处理环节。

因此，在认识到了这一个“矛盾”后，设计一款基于DETR框架的实时通用目标检测器也是十分必要的，不仅仅是要提高DETR系列的实用性，也是为了解决YOLO系列等工作中的“两套阈值”的麻烦。

至此，我们就说清楚了RT-DETR的研究动机，简单来说，它的目的就是希望在解决以往的高效检测器的“两套阈值”的麻烦的同时设计一款全新的端到端的实时通用目标检测器，而RT-DETR就是他们所找寻到的“答案”。

## 三、RT-DETR检测框架

接下来，我们来介绍一下RT-DETR的结构。截至本文完成之际，当前开源社区只有百度放出来的基于PaddlePaddle框架的RT-DETR的实现，已经支持训练和测试了，尽管还不是最完整版的，但结合已有的代码和论文，足以让我们来充分了解这一全新的实时检测器。

从结构上来看，RT-DETR可以分为三大块：**主干网络**、**颈部网络**以及**解码器**。我们分别来说一下这三大块。

### 3.1 主干网络

对于主干网络，RT-DETR采用CNN网络，如流行的[ResNet系列](https://zhida.zhihu.com/search?content_id=227388868&content_type=Article&match_order=1&q=ResNet%E7%B3%BB%E5%88%97&zhida_source=entity)，或者百度自家研发的HGNet。当然，使用ViT系列的主干网络如SwinTransformer及其后续诸多变体也是可以的，因为就特征提取而言，虽然研究初期ViT系列来势汹汹，颇有山雨欲来风满楼的大变动之驾驶，但后来的诸多CNN工作如[ConvNeXt](https://zhida.zhihu.com/search?content_id=227388868&content_type=Article&match_order=1&q=ConvNeXt&zhida_source=entity)等工作则证明了“ViT的训练trick可能是关键之处”，由此抹平了CNN架构和ViT架构在视觉表征学习上的性能差距。但毋庸置疑，**就当下的硬件而言，CNN架构无疑是快于ViT架构的**，因此，从实时性的角度出发，选择CNN架构来做特征提取还是有助于提高DETR系列的实时性，进而提升实用性——毫无疑问，这是阶段性的措施，不难想象，未来一定会有新架构全面——不论是性能还是推理速度——取代CNN架构。

![[Pasted image 20250326030411.png]]

和以往的检测器一样，RT-DETR也是从主干网络中抽取三个尺度的输出，其输出步长分别为8、16和32，以往我们使用 C3 、 C4 以及 C5 来标记他们的，在RT-DETR论文中，则使用 S3 、 S4 和 S5 来标记他们，这并没有什么本质的不同，仅仅是原先将原先用习惯的“小黄猫”称呼换成了“小橘猫”。

### 3.2 颈部网络

对于颈部网络，RT-DETR采用了**一层Transformer的Encoder，只处理主干网络输出的 S5 特征**，即图6中所展示的**AIFI**（Attention-based Intra-scale Feature Interaction）模块。尽管这个模块的名字起得很是那么一回事，但其实他就是一个很普通的Transformer的Encoder层，包含标准的MSAH（或者Deformable Attention）和FFN，如图7所展示的公式，注意，图7中省略了FFN的处理。

首先，我们将二维的S5 特征拉成向量，然后交给AIFI模块处理，其数学过程就是多头自注意力与FFN，随后，我们再将输出调整回二维，记作 F5 ，以便去完成后续的所谓的“跨尺度特征融合”。之所以RT-DETR的AIFI只处理最后的S5 特征，是出于两点考虑：

1. 一方面，以往的DETR，如Deformable DETR是将多尺度的特征展平成序列（ RB×C×H×W→RB×N×C ），然后拼接到一起，构成一个序列很长的向量，随后再交给核心为self attention技术的Transformer encoder去做多尺度之间的特征交互，但这无疑会造成巨大的计算资源的消耗，毕竟self attention技术的平方计算复杂度一直是其广受诟病的缺陷之一；
2. 另一方面，RT-DETR认为相较于较浅的S3 特征和S4 特征，S5 特征拥有更深、更高级、更丰富的语义特征，而self attention机制可能更关注特征的语义性，而非空间局部细节等，因此，作者团队认为不必让多尺度特征都放到一个篮子中去。

综上，作者团队认为只需将Encoder作用在空间尺寸不太大，信息语义程度有很高的S5 特征上即可，以此来平衡性能和速度——既可以大幅度地减小计算量、提高计算速度，又不会损伤到模型的性能。为了验证这一点，作者团队设计了若干对照组，如图8所示。


《目标检测大杂烩》-第14章-浅析RT-DETR - Kissrabbit的文章 - 知乎
https://zhuanlan.zhihu.com/p/626659049