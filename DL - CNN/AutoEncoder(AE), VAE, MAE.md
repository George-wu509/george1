
![[Pasted image 20250909100823.png]]【全】一文带你了解自编码器（AutoEncoder） - NLP自然语言处理的文章 - 知乎
https://zhuanlan.zhihu.com/p/80377698

AutoEncoder (AE) 和 Variational AutoEncoder (VAE) 的详细介绍和对比 - deephub的文章 - 知乎
https://zhuanlan.zhihu.com/p/429686815

自编码器(AutoEncoder)介绍及pytorch代码实现 - Qzz528的文章 - 知乎
https://zhuanlan.zhihu.com/p/625085766

### 自编码器（Autoencoder）介绍

### 自编码简单模型介绍

自编码器可以理解为一个试图去还原其原始输入的系统。自编码器模型如下图所示。从上图可以看出，自编码器模型主要由编码器（Encoder）和解码器（Decoder）组成，其主要目的是将输入x转换成中间变量y，然后再将y转换成  ，然后对比输入x和输出  使得他们两个无限接近。

那么此时可能会有人问了，好端端的图片为什么要压缩呢?其主要原因是：有时神经网络要接受大量的输入信息, 比如输入信息是高清图片时, 输入信息量可能达到上千万, 让神经网络直接从上千万个信息源中学习是一件很吃力的工作. 所以, 何不压缩一下, 提取出原图片中的最具代表性的信息, 缩减输入信息量, 再把缩减过后的信息放进神经网络学习. 这样学习起来就简单轻松了. 所以, 自编码就能在这时发挥作用. 通过将原数据白色的X 压缩, 解压 成黑色的X, 然后通过对比黑白 X ,求出预测误差, 进行反向传递, 逐步提升自编码的准确性. 训练好的自编码中间这一部分就是能总结原数据的精髓. 可以看出, 从头到尾, 我们只用到了输入数据 X, 并没有用到 X 对应的数据标签, 所以也可以说自编码是一种非监督学习. 到了真正使用自编码的时候. 通常只会用到自编码前半部分。


Autoencoder (AE), Variational Autoencoder (VAE), 和 Masked Autoencoder (MAE) 雖然名字相似，都採用了「編碼器-解碼器」架構，但它們的核心思想、目標、架構和應用場景有著天壤之別。

我將為您提供一個非常詳細的中文解釋，涵蓋從核心思想到模型架構的每一個層面。

---

### **概覽：三者的核心區別**

- **Autoencoder (AE):** 最基礎的形式，像一個「有損壓縮」工具。主要目標是**學習數據的有效表示 (Representation Learning)** 或**降維 (Dimensionality Reduction)**，同時盡可能地重建原始輸入。
    
- **Variational Autoencoder (VAE):** AE的生成式進階版，像一個「數據生成器」。主要目標是學習一個**平滑、連續的潛在空間 (Latent Space)**，從而能夠**生成全新的、看起來真實的數據**。
    
- **Masked Autoencoder (MAE):** 為「表徵學習」而生的現代自監督模型，像一個「拼圖大師」。主要目標是透過讓模型「腦補」被遮蓋的圖像部分，來**預訓練一個極其強大的視覺特徵提取器 (Encoder)**，用於其他下游任務。
    

---

### **1. Autoencoder (AE) - 自編碼器**

#### **核心思想**

AE的核心思想非常直觀：將輸入數據 `X` 透過一個**編碼器 (Encoder)** 壓縮成一個低維度的**潛在表示 `z` (latent representation)**，然後再透過一個**解碼器 (Decoder)** 將這個 `z` 解碼，嘗試重建出原始數據 `X'`。如果模型能夠在壓縮後依然完美重建，就說明中間的壓縮表示 `z` 成功地捕捉了數據最重要的特徵。

#### **模型架構 (Model Architecture)**

AE的架構是對稱的，解碼器通常是編碼器的「鏡像」。對於圖像處理，通常使用卷積神經網絡 (CNN)。
- **編碼器 (Encoder):**
    - **目標：** 降維，提取特徵。
    - **組成：**
        - **卷積層 (CNN Layer):** 通常由多個 `Conv2d` 層組成。每一層使用濾波器 (filter) 從圖像中提取特徵（如邊緣、角點、紋理）。隨著層數加深，濾波器數量通常會增加（例如 32 -> 64 -> 128），以學習更複雜的特徵。
        - **激活函數 (Activation Layers):** 每個卷積層後通常跟著一個非線性激活函數，最常用的是 **`ReLU`** (`Rectified Linear Unit`) 或其變體 (`LeakyReLU`)，以增加模型的表達能力。
        - **池化層 (Pooling Layers):** 通常使用 **`MaxPooling2D`**。在卷積和激活之後，池化層會對特徵圖進行**下採樣 (Downsampling)**，例如將 `2x2` 的區域縮減為一個點（取最大值）。這有助於減小數據的空間尺寸、增加感受野 (receptive field)，並保留最重要的特徵。
    - **輸出：** 經過多層 `Conv -> ReLU -> Pool` 的堆疊後，最後的特徵圖會被**展平 (Flatten)**，並可能通過一個全連接層 (Dense Layer) 得到最終的、一維的潛在向量 `z`。
        
- **解碼器 (Decoder):**
    - **目標：** 從潛在向量 `z` 中重建原始圖像。
    - **組成：**
        - **反卷積層 (Deconvolution) 或 上採樣層 (Upsampling):** 這是與編碼器相反的操作。通常使用 **`Conv2DTranspose`** 層或 **`UpSampling2D`** 層來放大特徵圖的空間尺寸。
        - **卷積層 (CNN Layer):** 在上採樣之後，通常會接 `Conv2d` 層來細化特徵和填充細節。
        - **激活函數 (Activation Layers):** 同樣使用 `ReLU` 等激活函數。
    - **輸出：** 解碼器的最後一層是一個 `Conv2d` 層，其輸出通道數與原始圖像相同（彩色為3，灰階為1），並使用一個適合的激活函數（如 **`Sigmoid`** 將像素值壓縮到0-1之間）來生成最終的重建圖像 `X'`
#### **運作原理與目標**

AE的目標是最小化**重建損失 (Reconstruction Loss)**，即原始輸入 `X` 和重建輸出 `X'` 之間的差異。常用的損失函數是**均方誤差 (Mean Squared Error, MSE)**。
LossAE​=∣∣X−X′∣∣2=∣∣X−Decoder(Encoder(X))∣∣2

#### **主要應用**
1. **數據降噪 (Denoising):** 訓練時給輸入加入噪聲，但要求模型重建出乾淨的原始圖像。
2. **降維與可視化:** 將高維數據壓縮到2維或3維的 `z` 向量，用於可視化數據分佈。
3. **異常檢測 (Anomaly Detection):** 如前述，只用正常數據訓練AE。當輸入異常數據時，由於模型沒學過其模式，重建誤差會顯著增大，從而檢測出異常。

---

### **2. Variational Autoencoder (VAE) - 變分自編碼器**

#### **核心思想**

VAE的目標遠不止於重建，它希望**學習整個數據的分佈**，從而能夠**生成新的數據**。它將AE中確定的潛在向量 `z` 升級為一個**機率分佈**。編碼器不再輸出一個點，而是輸出一簇點的統計參數（平均值和標準差）。解碼器則從這個分佈中**隨機採樣**一個點 `z` 來進行重建。

這使得潛在空間變得**平滑且連續**。在AE的潛在空間中，兩個點之間可能沒有意義；但在VAE的潛在空間中，任意兩個點之間的點都對應一個有意義的、平滑過渡的生成結果。

#### **模型架構 (Model Architecture)**

VAE的架構在AE的基礎上做了關鍵修改，主要在編碼器的輸出和潛在向量的生成上。

- **編碼器 (Inference Network):**
    - **結構：** 前半部分與AE的編碼器完全相同（`Conv -> ReLU -> Pool`...）。
    - **關鍵區別：** 最後的全連接層**不輸出單一的潛在向量 `z`**。而是輸出**兩個**向量：
        1. **平均值向量 (mean vector) `μ`**
        2. **對數方差向量 (log-variance vector) `log(σ²)`**
    - 這兩個向量共同定義了一個高斯分佈 `N(μ, σ²)`，這就是潛在空間的機率分佈。
        
- **重參數化技巧 (Reparameterization Trick):**
    - 我們不能直接從 `N(μ, σ²)` 中進行採樣，因為採樣這個動作是隨機的，會導致梯度無法反向傳播。
    - 於是，我們採用一個技巧：先從一個標準正態分佈 `ε ~ N(0, I)` 中採樣一個隨機噪聲 `ε`，然後透過以下公式計算 `z`：
    - 這樣，`z` 依然服從 `N(μ, σ²)` 分佈，但隨機性被轉移到了 `ε` 上，使得 `μ` 和 `σ` 可以透過梯度下降進行學習。
        
- **解碼器 (Generative Network):**
    - **結構與AE的解碼器完全相同**。它接收經過重參數化技巧採樣得到的向量 `z`，然後透過 `Conv2DTranspose` 等層來重建圖像。

#### **運作原理與目標**

VAE的損失函數比AE複雜，由兩部分組成：
**1. 重建損失 (Reconstruction Loss):** 與AE相同，用於確保生成圖像的保真度
**2. KL散度 (Kullback-Leibler Divergence):** 這是VAE的精華。它是一個正則化項，用來衡量編碼器產生的分佈
**總損失 = 重建損失 + KL散度損失**
#### **主要應用**
1. **圖像生成:** 從潛在空間中隨機採樣一個 `z`，輸入解碼器，即可生成一張全新的、從未見過的圖像。
2. **數據編輯與插值:** 找到代表「戴眼鏡」和「不戴眼鏡」的兩個潛在向量 `z1` 和 `z2`，在它們之間進行插值，可以生成從不戴眼鏡到戴眼鏡的平滑過渡動畫。
3. **半監督學習:** 利用潛在空間的結構來提升少量標籤數據的分類效果。

### **3. Masked Autoencoder (MAE) - 遮蔽自編碼器**

#### **核心思想**

MAE是為**預訓練 (Pre-training)** 大型視覺模型而設計的。它的思想源於NLP領域的BERT模型：**通過預測被遮蔽的部分來學習通用的表示**。

MAE的核心假設是：如果一個模型能僅憑一小部分可見的圖像塊，就成功「腦補」出大部分被遮蔽的內容，那它一定已經學會了圖像中物體的結構、紋理和語義等深層次的知識。這個學到知識的編碼器將會非常強大。

#### **模型架構 (Model Architecture)**

MAE的架構非常不對稱，並且通常使用 **Vision Transformer (ViT)** 作為骨幹，而不是CNN。

- **預處理 - 隨機遮蔽 (Random Masking):**
    - 將輸入圖像分割成一系列不重疊的patch（例如 `16x16`）。
    - 隨機**丟棄**其中一大部分的patch（例如75%）。
        
- **編碼器 (Encoder):**
    
    - **目標：** 從極少數可見的patch中學習深層表示。
    - **組成：** 通常是一個標準的 **Vision Transformer (ViT)**。
    - **關鍵設計：** 編碼器**只處理可見的patch**（例如只處理剩下的25%）。這使得MAE的預訓練過程計算效率極高，因為大部分計算都被節省了。
        
- **解碼器 (Decoder):**
    
    - **目標：** 從可見patch的表示中，重建出被遮蔽patch的像素值。
    - **組成：** 通常是一個**更輕量、更淺**的ViT。
    - **輸入：**
        1. 由編碼器輸出的可見patch的表示。
        2. 為每一個被遮蔽的patch引入一個共享的、可學習的**「遮蔽標記」(`[MASK]` token)**。
    - **輸出：** 為每一個被遮蔽的patch預測其原始的像素值。

#### **運作原理與目標**

MAE的目標也是最小化重建損失，但有兩個關鍵不同：

1. **非對稱設計：** 編碼器輕量（只看部分patch），解碼器負責重建。
2. **損失計算範圍：** 損失函數（通常是MSE）**只在被遮蔽的patch上計算**。模型不需要重建它已經看到的部分。
 #### **主要應用**

 **自監督預訓練 (Self-Supervised Pre-training):** MAE的主要用途。在海量的無標籤圖像上進行預訓練後，**解碼器會被完全丟棄**。
    
**下游任務微調 (Fine-tuning):** 將預訓練好的、強大的**編碼器**作為一個固定的或可微調的骨幹網路，應用於各種視覺任務，如：
    - **圖像分類 (Image Classification)**
    - **物件偵測 (Object Detection)**
    - **語義分割 (Semantic Segmentation)**
    - MAE預訓練的ViT在這些任務上都達到了頂級(State-of-the-Art)的性能。

### **總結對比表**

|特性|Autoencoder (AE)|Variational Autoencoder (VAE)|Masked Autoencoder (MAE)|
|---|---|---|---|
|**核心目標**|數據壓縮、降噪、降維|**生成新數據**、學習數據分佈|**預訓練強大的視覺表徵**|
|**潛在空間 `z`**|確定的、可能是離散/不規則的|**機率分佈**、平滑、連續|**上下文相關的特徵表示**（不直接用於生成）|
|**損失函數**|僅重建損失|重建損失 + **KL散度**|僅在**被遮蔽部分**的重建損失|
|**編碼器輸入**|完整的圖像|完整的圖像|**部分可見的圖像塊 (Patches)**|
|**解碼器目標**|重建完整的圖像|重建完整的圖像|**僅重建被遮蔽的圖像塊**|
|**常用骨幹**|CNN|CNN|**Vision Transformer (ViT)**|
|**架構對稱性**|對稱（Encoder ≈ Decoder的鏡像）|對稱|**非對稱**（Encoder重，Decoder輕）|
|**主要應用**|異常檢測、降噪|**圖像生成**、數據編輯|**為下游任務（分類、檢測）預訓練模型**|