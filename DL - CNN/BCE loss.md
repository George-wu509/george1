
| 信度損失 <mark style="background: #FFF3A3A6;">Confidence</mark> Loss |          |
| ---------------------------------------------------------------- | -------- |
|                                                                  | BCE Loss |

|          | positive anchor(有任何物體 y=1) 將不同的物體的condifence取最大值=Pconf, 譬如 [0.1, 0.4, 0.7,0.85] ->  PConf=0.85.  negative anchor(無任何物體 y=0) 將不同的物體的condifence取最大值=Pconf, 譬如 [0.8, 0.02, 0.1,0.04] ->  PConf=0.1                                                                                                                                                                                                                                                                                                                                               |
| -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| BCE Loss | positive anchor LBCE  ([0,1]->[0.15,0.85]) =<br> (1,0.85)=−[1log(0.85)+(1−1)log(1−0.85)]=−log(0.85)≈0.163<br><br>negative anchor LBCE  ([1,0]->[0.9,0.1]) =<br> (0,0.1)=−[0log(0.1)+(1−0)log(1−0.1)]=−log(0.9)≈0.105<br><br>>>>  **LBCE(pt​)=<mark style="background: #BBFABBA6;">-(ylog(pt​)+(1-y)log(1-pt))</mark>**<br>>>>  ** 所有LBCE相加(正負) / 正負樣本anchor數量  **<br>(anchor/proposal based objection detection/instance segmentation)<br><br>>>>  ** 所有LBCE相加(正負) / 正負樣本邊界框數量  **<br>(anchor free objection detection/instance segmentation) |
|          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |

**4. Binary Cross-Entropy Loss (BCE Loss) for Confidence Scores**

BCE Loss 通常用於二分類問題，例如判斷一個 anchor box 是否包含目標（目標性/置信度損失）。假設模型輸出的 confidence scores 為 [P(背景),P(汽車),P(行人)]，我們需要將其與目標性標籤進行比較。

對於一個正樣本 anchor (與真實目標重疊)，目標性標籤 y=1。對於一個負樣本 anchor (背景)，目標性標籤 y=0。模型的置信度輸出需要轉換為一個單一的目標性預測值，例如，可以取前景類別的最大概率作為目標性置信度，或者模型可能直接輸出一個獨立的目標性置信度。

假設模型輸出的目標性置信度為 pconf​，真實標籤為 y∈{0,1}。

LBCE​(y,pconf​)=−[ylog(pconf​)+(1−y)log(1−pconf​)]

**具體範例:**

- **正樣本 anchor:** 真實標籤 y=1，模型預測 P(汽車)=0.85 (假設以此作為目標性置信度)。 LBCE​(1,0.85)=−[1log(0.85)+(1−1)log(1−0.85)]=−log(0.85)≈0.163
    
- **負樣本 anchor:** 真實標籤 y=0，模型預測 P(背景)=0.9 (假設 1 - P(背景) 作為目標性置信度，即 1−0.9=0.1)。 LBCE​(0,0.1)=−[0log(0.1)+(1−0)log(1−0.1)]=−log(0.9)≈0.105





具體舉例說明在一個目標檢測模型中如何使用二元交叉熵損失 (BCE Loss) 計算 confidence loss。

**情景設定：**

- **圖像:** 一張包含兩個物體的圖片：一輛汽車和一個人。
- **物體類別:** background (0), car (1), people (2)。
- **Anchor 數量:** 模型生成了 100 個 anchor boxes。
- **目標性標籤 (Ground Truth Objectness Labels):** 對於每個 anchor，我們需要確定其是否與任何真實物體 (car 或 people) 的邊界框充分重疊。
    - 如果一個 anchor 與任何真實物體的 IoU 大於某個閾值（例如 0.5），則該 anchor 的目標性標籤為 1 (包含目標)。
    - 如果一個 anchor 與所有真實物體的 IoU 都小於某個閾值（例如 0.3），則該 anchor 的目標性標籤為 0 (不包含目標/背景)。
    - IoU 在這兩個閾值之間的 anchor 通常在訓練中被忽略，不參與 confidence loss 的計算。

**模型輸出 (Confidence Scores):**

對於每個 anchor i (從 1 到 100)，模型會預測其屬於每個類別的概率。假設模型輸出的概率向量是 [Pi​(background),Pi​(car),Pi​(people)]。

**計算 Confidence Loss (使用 BCE Loss):**

Confidence loss 的目標是訓練模型預測每個 anchor 是否包含任何前景目標。因此，我們需要一個目標性預測值和一個目標性真實標籤。

**步驟 1: 確定每個 Anchor 的目標性真實標籤 (yi​)**

假設經過與真實邊界框的匹配，我們得到以下目標性真實標籤：

- Anchor 1-10: yi​=1 (與汽車或人重疊)
- Anchor 11-20: yi​=1 (與汽車或人重疊)
- Anchor 21-80: yi​=0 (與任何真實物體重疊較小，視為背景)
- Anchor 81-100: 被忽略，不參與損失計算。

**步驟 2: 從模型輸出中提取或計算目標性預測 (pi​)**

有多種方法可以從模型的類別概率輸出中得到每個 anchor 的目標性預測 pi​：

- **方法 1: 取前景類別的最大概率:** 可以將一個 anchor 包含任何前景目標的置信度定義為其屬於任何前景類別的最大概率。
    
    - pi​=max(Pi​(car),Pi​(people))
- **方法 2: 使用一個獨立的目標性預測分支 (更常見於某些模型):** 模型可能直接為每個 anchor 輸出一個額外的置信度分數，表示其包含任何目標的概率。假設這個輸出是 Ci​∈[0,1]，則 pi​=Ci​。
    

**我們這裡使用方法 1 進行舉例。**

**步驟 3: 計算每個 Anchor 的 BCE Loss**

BCE Loss 的公式是：

LBCE​(yi​,pi​)=−[yi​log(pi​)+(1−yi​)log(1−pi​)]

**具體範例計算：**

- **Anchor 5 (正樣本):** 假設模型輸出 [P5​(background)=0.2,P5​(car)=0.7,P5​(people)=0.1]。
    
    - 目標性真實標籤 y5​=1。
    - 目標性預測 p5​=max(0.7,0.1)=0.7。
    - LBCE​(1,0.7)=−[1log(0.7)+(1−1)log(1−0.7)]=−log(0.7)≈0.357
- **Anchor 15 (正樣本):** 假設模型輸出 [P15​(background)=0.1,P15​(car)=0.3,P15​(people)=0.6]。
    
    - 目標性真實標籤 y15​=1。
    - 目標性預測 p15​=max(0.3,0.6)=0.6。
    - LBCE​(1,0.6)=−[1log(0.6)+(1−1)log(1−0.6)]=−log(0.6)≈0.511
- **Anchor 50 (負樣本):** 假設模型輸出 [P50​(background)=0.9,P50​(car)=0.05,P50​(people)=0.05]。
    
    - 目標性真實標籤 y50​=0。
    - 目標性預測 p50​=max(0.05,0.05)=0.05。
    - LBCE​(0,0.05)=−[0log(0.05)+(1−0)log(1−0.05)]=−log(0.95)≈0.051
- **Anchor 70 (負樣本):** 假設模型輸出 [P70​(background)=0.7,P70​(car)=0.2,P70​(people)=0.1]。
    
    - 目標性真實標籤 y70​=0。
    - 目標性預測 p70​=max(0.2,0.1)=0.2。
    - LBCE​(0,0.2)=−[0log(0.2)+(1−0)log(1−0.2)]=−log(0.8)≈0.223

**步驟 4: 計算總的 Confidence Loss**

總的 confidence loss 是所有參與計算的 anchor 的 BCE loss 的平均值：

Lconf​=正負樣本 anchor 的數量∑i∈{正負樣本anchor}​LBCE​(yi​,pi​)​

在我們的例子中，共有 10 + 10 + 60 = 80 個參與計算的 anchor。

**總結：**

使用 BCE loss 計算 confidence loss 的關鍵步驟是：

1. 為每個 anchor 確定其目標性真實標籤 (是否包含目標)。
2. 從模型的類別概率輸出中提取或計算每個 anchor 的目標性預測值。
3. 使用 BCE loss 公式比較每個 anchor 的目標性預測和真實標籤。
4. 將所有參與計算的 anchor 的 BCE loss 平均起來得到最終的 confidence loss。

不同的目標檢測模型可能會採用不同的方法來定義和計算目標性預測，但使用 BCE loss 作為衡量預測置信度與真實標籤之間差異的函數是很常見的。