

|                         |     |
| ----------------------- | --- |
| [[###FCN 和 CNN 的介紹與比較]] |     |
| [[###SimpleCNN 具體舉例]]   |     |
| [[###SimpleFCN 具體舉例]]   |     |
|                         |     |
|                         |     |

### FCN 和 CNN 的介紹與比較

#### 什麼是 FCN？

FCN（Fully Convolutional Network，全卷積網絡）是一種專為圖像分割（Image Segmentation）任務設計的深度學習模型。與傳統的卷積神經網絡（CNN）不同，FCN 完全由卷積層組成，沒有全連接層（Fully Connected Layers），並且能夠處理任意大小的輸入圖像，輸出與輸入圖像空間尺寸相關的預測（如像素級分類）。FCN 是語義分割的開創性架構，它將 CNN 的全連接層FC（Fully Connected layers）替換成卷積層，實現端到端的 pixel-wise 預測。

FCN 的核心思想是：

- 通過卷積和池化操作提取特徵。
- 使用上採樣（Upsampling，例如轉置卷積）將特徵圖恢復到原始輸入圖像的大小。
- 最終每個像素都會有一個類別預測，實現端到端的像素級分割。

#### FCN 與 CNN 的差別

|特性|CNN（卷積神經網絡）|FCN（全卷積網絡）|
|---|---|---|
|**輸出**|通常是單一向量（如類別概率）|空間映射（如像素級分類）|
|**結構**|包含卷積層 + 全連接層|僅包含卷積層（無全連接層）|
|**輸入大小**|通常固定（如 224×224）|可變（因無全連接層限制）|
|**應用**|圖像分類、目標檢測|圖像分割|
|**上採樣**|不需要|需要（如轉置卷積或插值）|

簡單來說，CNN 適合全局分類任務（如這張圖是貓還是狗），而 FCN 適合空間細粒度的任務（如分割出圖像中的貓的每個像素）。

---

![[Pasted image 20250323180612.png]]


![[Pasted image 20250323180026.png]]

![[Pasted image 20250323180644.png]]

### PyTorch 代碼示例

#### 1. CNN 示例（簡單圖像分類）

以下是一個簡單的 CNN，用於圖像分類任務：

```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # 輸入 3 通道 (RGB)
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 56 * 56, 128),  # 假設輸入圖像大小為 224×224
            nn.ReLU(),
            nn.Linear(128, num_classes),   # 輸出類別數
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# 初始化模型
cnn_model = SimpleCNN(num_classes=10)
print(cnn_model)

# 測試
input_tensor = torch.randn(1, 3, 224, 224)  # batch_size=1, 3通道, 224×224
output = cnn_model(input_tensor)
print("CNN Output Shape:", output.shape)  # torch.Size([1, 10])，10個類別的概率
```

#### 2. FCN 示例（簡單圖像分割）

以下是一個簡單的 FCN，用於圖像分割任務：

```python
import torch
import torch.nn as nn

class SimpleFCN(nn.Module):
    def __init__(self, num_classes=2):  # 假設分割成 2 類（如前景和背景）
        super(SimpleFCN, self).__init__()
        # 下採樣（特徵提取）
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣 2x
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣 2x
        )
        # 上採樣（恢復分辨率）
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # 上採樣 2x
            nn.ReLU(),
            nn.ConvTranspose2d(16, num_classes, kernel_size=2, stride=2),  # 上採樣 2x
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# 初始化模型
fcn_model = SimpleFCN(num_classes=2)
print(fcn_model)

# 測試
input_tensor = torch.randn(1, 3, 224, 224)  # batch_size=1, 3通道, 224×224
output = fcn_model(input_tensor)
print("FCN Output Shape:", output.shape)  # torch.Size([1, 2, 224, 224])，每個像素 2 類概率
```

---

### 代碼比較

1. **結構**：
    - **CNN**：有全連接層（nn.Linear），將特徵壓縮成單一向量輸出。
    - **FCN**：無全連接層，使用轉置卷積（nn.ConvTranspose2d）恢復空間維度。
2. **輸出**：
    - **CNN**：輸出為 [batch_size, num_classes]，表示圖像級別的類別概率。
    - **FCN**：輸出為 [batch_size, num_classes, height, width]，表示像素級別的類別概率。
3. **用途**：
    - **CNN**：用於分類，適合回答「這張圖是什麼？」。
    - **FCN**：用於分割，適合回答「圖中哪些像素屬於某類？」。
4. **輸入靈活性**：
    - **CNN**：由於全連接層的存在，輸入大小通常固定（這裡假設 224×224）。
    - **FCN**：全卷積結構允許任意大小的輸入，輸出尺寸與輸入成比例。

---

### 總結

- **CNN** 是傳統分類模型，通過卷積提取特徵後用全連接層輸出全局預測。
- **FCN** 是分割模型，通過全卷積結構保留空間信息並生成像素級預測。
- 在 PyTorch 實現中，FCN 的關鍵是去掉全連接層並加入上採樣層，這是它與 CNN 的根本區別。




### SimpleCNN 具體舉例

假設 SimpleCNN 的結構如下（根據你的要求調整）：

```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=0),  # 3 輸入通道，16 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
            nn.Conv2d(16, 32, kernel_size=3, padding=0),  # 16 輸入通道，32 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 1 * 1, 128),  # 調整全連接層輸入大小，後面會計算
            nn.ReLU(),
            nn.Linear(128, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
```

輸入條件：

- **輸入圖像**：7×7，3 通道（RGB），即形狀為 [1, 3, 7, 7]（batch_size=1）。
- **卷積核大小**：3×3。
- **無 padding**（padding=0）。
- **目標**：輸出為 10 個類別的得分。

---

### 步驟-by-步驟計算與解釋

#### 步驟 1：第一次卷積 (Conv2d: 3 -> 16, 3×3)

- **輸入**：[1, 3, 7, 7]（batch_size=1, 通道=3, 高=7, 寬=7）。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：3。
    - 輸出通道：16。
    - Stride：1（預設）。
    - Padding：0。
- **輸出尺寸計算**：
    - 公式：output_size = (input_size - kernel_size + 2 * padding) / stride + 1
    - 高：(7 - 3 + 0) / 1 + 1 = 4 + 1 = 5
    - 寬：(7 - 3 + 0) / 1 + 1 = 4 + 1 = 5
    - 輸出形狀：[1, 16, 5, 5]（16 個 5×5 特徵圖）。
- **計算過程**：
    - 每個 3×3 卷積核在輸入圖像上滑動，計算 3 個通道的點積並加偏置。
    - 假設輸入數據（僅展示通道 1）：
        
```python
[[1, 2, 3, 4, 5, 6, 7],
 [8, 9, 10, 11, 12, 13, 14],
 [15, 16, 17, 18, 19, 20, 21],
 [22, 23, 24, 25, 26, 27, 28],
 [29, 30, 31, 32, 33, 34, 35],
 [36, 37, 38, 39, 40, 41, 42],
 [43, 44, 45, 46, 47, 48, 49]]
```
        
    - 假設第一個卷積核權重（通道 1）：[[1, 0, -1], [2, 0, -2], [1, 0, -1]]，偏置為 0。
    - 左上角 3×3 區域：
        - 輸入：[[1, 2, 3], [8, 9, 10], [15, 16, 17]]
        - 點積：1*1 + 2*0 + 3*-1 + 8*2 + 9*0 + 10*-2 + 15*1 + 16*0 + 17*-1 = 1 - 3 + 16 - 20 + 15 - 17 = -8
        - 假設其他通道計算後總和為 -10。
    - 滑動 5×5 次，生成特徵圖：
        
```python
特徵圖 1: [[-10, 5, -2, 3, 1],
            [4, -3, 6, -1, 2],
            [-5, 7, -4, 8, -6],
            [9, -7, 10, -8, 11],
            [-9, 12, -11, 13, -12]]
```
        

#### 步驟 2：ReLU 激活

- **輸入**：[1, 16, 5, 5]。
- **操作**：將負值設為 0。
- **輸出形狀**：[1, 16, 5, 5]。
- **計算過程**：
    - 示例：
```python
輸入: [[-10, 5, -2, 3, 1], ...]
輸出: [[0, 5, 0, 3, 1], ...]
```
        

#### 步驟 3：第一次池化 (MaxPool2d: 2×2)

- **輸入**：[1, 16, 5, 5]。
- **池化參數**：
    - 窗口：2×2。
    - Stride：2。
- **輸出尺寸計算**：
    - 高：floor((5 - 2) / 2) + 1 = floor(1.5) + 1 = 2
    - 寬：floor((5 - 2) / 2) + 1 = 2
    - 輸出形狀：[1, 16, 2, 2]（5×5 被縮減為 2×2）。
- **計算過程**：
    - 在每個 2×2 區域取最大值。
    - 示例：
        
```python
輸入: [[0, 5, 0, 3, 1],
       [4, -3, 6, -1, 2],
       [-5, 7, -4, 8, -6],
       [9, -7, 10, -8, 11],
       [-9, 12, -11, 13, -12]]
輸出: [[5, 6], [12, 13]]（分區域取最大值）
```
        

#### 步驟 4：第二次卷積 (Conv2d: 16 -> 32, 3×3)

- **輸入**：[1, 16, 2, 2]。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：16。
    - 輸出通道：32。
    - Padding：0。
- **輸出尺寸計算**：
    - 高：(2 - 3 + 0) / 1 + 1 = -1 + 1 = 0（無效）。
- **問題**：
    - 輸入 2×2 小於 3×3 卷積核，無法進行卷積。
- **解決方法**：
    - 為適應 7×7 輸入，我們調整結構，移除第二次卷積和池化，直接進入分類器。修改後結構如下：
```python
self.features = nn.Sequential(
    nn.Conv2d(3, 16, kernel_size=3, padding=0),
    nn.ReLU(),
    nn.MaxPool2d(2, 2),
)
self.classifier = nn.Sequential(
    nn.Flatten(),
    nn.Linear(16 * 2 * 2, 128),  # 調整為 16×2×2
    nn.ReLU(),
    nn.Linear(128, num_classes),
)
```

        
    - 從步驟 3 輸出 [1, 16, 2, 2] 繼續。

#### 步驟 5：展平 (Flatten)

- **輸入**：[1, 16, 2, 2]。
- **操作**：展平為一維向量。
- **輸出形狀**：[1, 64]（16×2×2 = 64）。
- **計算過程**：
    - 示例：
```python
輸入: [[[5, 6], [12, 13]], ...]（16 個 2×2）
輸出: [5, 6, 12, 13, ...]（長度 64）
```

#### 步驟 6：第一次全連接層 (Linear: 64 -> 128)

- **輸入**：[1, 64]。
- **參數**：權重 [64, 128]，偏置 [128]。
- **輸出形狀**：[1, 128]。
- **計算過程**：
    - output = input @ weight + bias。
    - 示例（假設權重和偏置隨機）：
```python
輸入: [5, 6, 12, 13, ...]
輸出: [x1, x2, ..., x128]
```
        

#### 步驟 7：ReLU 激活

- **輸入**：[1, 128]。
- **操作**：max(0, x)。
- **輸出形狀**：[1, 128]。

#### 步驟 8：第二次全連接層 (Linear: 128 -> 10)

- **輸入**：[1, 128]。
- **參數**：權重 [128, 10]，偏置 [10]。
- **輸出形狀**：[1, 10]（10 個類別得分）。
- **計算過程**：
    - 生成最終分類得分。

---

### 總結與數據流（調整後結構）

|步驟|形狀|解釋|
|---|---|---|
|輸入|[1, 3, 7, 7]|7×7 RGB 圖像|
|Conv1|[1, 16, 5, 5]|3×3 卷積提取特徵|
|ReLU1|[1, 16, 5, 5]|非線性激活|
|MaxPool1|[1, 16, 2, 2]|2×2 池化縮減尺寸|
|Flatten|[1, 64]|展平為向量|
|Linear1|[1, 128]|全連接層|
|ReLU2|[1, 128]|非線性激活|
|Linear2|[1, 10]|最終分類輸出|

### 注意

- **尺寸問題**：原始結構中第二次卷積因輸入 2×2 過小無法執行，我移除第二次卷積和池化，確保流程可行。
- **輸出**：最終輸出 [1, 10] 表示 10 個類別的得分，符合 CNN 分類目標。
- **假設數據**：這裡使用簡化值展示，實際權重由訓練決定。



### SimpleFCN 具體舉例

以下以一個簡化的 SimpleFCN 為例，針對你的條件（輸入為 7×7 圖像，卷積核大小為 3×3，通道數為 3），只考慮一層 Conv2d + ReLU + MaxPool2d 的編碼器結構，然後通過解碼器恢復到原始尺寸。我會逐步計算並解釋從輸入到輸出的每個步驟。

---

### SimpleFCN 結構

假設簡化的 SimpleFCN 結構如下：

```python
import torch
import torch.nn as nn

class SimpleFCN(nn.Module):
    def __init__(self, num_classes=2):  # 分割成 2 類（如前景和背景）
        super(SimpleFCN, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=0),  # 3 輸入通道，16 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(16, num_classes, kernel_size=3, stride=2, padding=1, output_padding=1),  # 上採樣到 7×7
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x
```

輸入條件：

- **輸入圖像**：7×7，3 通道（RGB），即形狀為 [1, 3, 7, 7]（batch_size=1）。
- **卷積核大小**：3×3。
- **無 padding**（padding=0）。
- **目標**：輸出為像素級分類（每個像素 2 個類別的得分），形狀為 [1, 2, 7, 7]。

---

### 步驟-by-步驟計算與解釋

#### 步驟 1：卷積層 (Conv2d: 3 -> 16, 3×3)

- **輸入**：[1, 3, 7, 7]（batch_size=1, 通道=3, 高=7, 寬=7）。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：3。
    - 輸出通道：16。
    - Stride：1（預設）。
    - Padding：0。
- **輸出尺寸計算**：
    - 公式：output_size = (input_size - kernel_size + 2 * padding) / stride + 1
    - 高：(7 - 3 + 0) / 1 + 1 = 4 + 1 = 5
    - 寬：(7 - 3 + 0) / 1 + 1 = 4 + 1 = 5
    - 輸出形狀：[1, 16, 5, 5]（16 個 5×5 特徵圖）。
- **計算過程**：
    - 每個 3×3 卷積核在輸入圖像上滑動，計算 3 個通道的點積並加偏置。
    - 假設輸入數據（僅展示通道 1）：
        
```
[[1, 2, 3, 4, 5, 6, 7],
 [8, 9, 10, 11, 12, 13, 14],
 [15, 16, 17, 18, 19, 20, 21],
 [22, 23, 24, 25, 26, 27, 28],
 [29, 30, 31, 32, 33, 34, 35],
 [36, 37, 38, 39, 40, 41, 42],
 [43, 44, 45, 46, 47, 48, 49]]
```
        
    - 假設第一個卷積核權重（通道 1）：[[1, 0, -1], [2, 0, -2], [1, 0, -1]]，偏置為 0。
    - 左上角 3×3 區域：
        - 輸入：[[1, 2, 3], [8, 9, 10], [15, 16, 17]]
        - 點積：1*1 + 2*0 + 3*-1 + 8*2 + 9*0 + 10*-2 + 15*1 + 16*0 + 17*-1 = 1 - 3 + 16 - 20 + 15 - 17 = -8
        - 假設其他通道計算後總和為 -10。
    - 輸出特徵圖（假設值）：
        
```
特徵圖 1: [[-10, 5, -2, 3, 1],
            [4, -3, 6, -1, 2],
            [-5, 7, -4, 8, -6],
            [9, -7, 10, -8, 11],
            [-9, 12, -11, 13, -12]]
```
        

#### 步驟 2：ReLU 激活

- **輸入**：[1, 16, 5, 5]。
- **操作**：將負值設為 0。
- **輸出形狀**：[1, 16, 5, 5]。
- **計算過程**：
    - 示例：
        
```
輸入: [[-10, 5, -2, 3, 1],
       [4, -3, 6, -1, 2],
       [-5, 7, -4, 8, -6],
       [9, -7, 10, -8, 11],
       [-9, 12, -11, 13, -12]]
輸出: [[0, 5, 0, 3, 1],
       [4, 0, 6, 0, 2],
       [0, 7, 0, 8, 0],
       [9, 0, 10, 0, 11],
       [0, 12, 0, 13, 0]]
```
        

#### 步驟 3：池化層 (MaxPool2d: 2×2)

- **輸入**：[1, 16, 5, 5]。
- **池化參數**：
    - 窗口：2×2。
    - Stride：2。
- **輸出尺寸計算**：
    - 高：floor((5 - 2) / 2) + 1 = floor(1.5) + 1 = 2
    - 寬：floor((5 - 2) / 2) + 1 = 2
    - 輸出形狀：[1, 16, 2, 2]（16 個 2×2 特徵圖）。
- **計算過程**：
    - 在每個 2×2 區域取最大值。
    - 示例：
        
```
輸入: [[0, 5, 0, 3, 1],
       [4, 0, 6, 0, 2],
       [0, 7, 0, 8, 0],
       [9, 0, 10, 0, 11],
       [0, 12, 0, 13, 0]]
輸出: [[5, 6],
       [12, 13]]
```
        

#### 步驟 4：轉置卷積 (ConvTranspose2d: 16 -> 2, 3×3, stride=2, padding=1, output_padding=1)

Ref:  [转置卷积（Transposed Convolution）](https://blog.csdn.net/qq_37541097/article/details/120709865)

- **輸入**：[1, 16, 2, 2]。
- **參數**：
    - 輸入通道：16。
    - 輸出通道：2（類別數）。
    - 卷積核：3×3。
    - Stride：2。
    - Padding：1。
    - Output_padding：1（調整輸出到 7×7）。
- **輸出尺寸計算**：
    - 公式：output_size = (input_size - 1) * stride - 2 * padding + kernel_size + output_padding
    - 高：(2 - 1) * 2 - 2 * 1 + 3 + 1 = 2 - 2 + 3 + 1 = 4 - 2 + 1 = 3 + 1 = 4 + 1 = 5 + 1 = 6 + 1 = 7
    - 寬：同上 = 7
    - 輸出形狀：[1, 2, 7, 7]。
- **計算過程**：
    - 將 2×2 擴展為 7×7。
    - 假設輸入：[[5, 6], [12, 13]]，權重（簡化為某通道）：[[1, 0, -1], [0, 0, 0], [-1, 0, 1]]。
    - 輸出（假設值，僅展示通道 1）：
        
```
[[5, 0, -6, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0],
 [-12, 0, 13, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0]]
```
        
    - 通道 2 同理生成另一個 7×7 特徵圖。

---

### 總結與數據流

|步驟|形狀|解釋|
|---|---|---|
|輸入|[1, 3, 7, 7]|7×7 RGB 圖像|
|Conv2d|[1, 16, 5, 5]|3×3 卷積提取特徵|
|ReLU|[1, 16, 5, 5]|非線性激活|
|MaxPool2d|[1, 16, 2, 2]|2×2 池化縮減尺寸|
|ConvTranspose2d|[1, 2, 7, 7]|3×3 轉置卷積，恢復到 7×7|

### 解釋每個步驟

1. **卷積層 (Conv2d)**：
    - 將 7×7 輸入轉換為 5×5 特徵圖，提取空間特徵，輸出 16 個通道。
2. **ReLU**：
    - 引入非線性，將負值設為 0，提升模型表達能力。
3. **池化層 (MaxPool2d)**：
    - 縮減空間尺寸至 2×2，保留主要特徵，減少計算量。
4. **轉置卷積 (ConvTranspose2d)**：
    - 將 2×2 上採樣到 7×7，生成像素級預測，輸出 2 個通道（每個像素的類別得分）。

### 注意

- **輸出**：最終輸出 [1, 2, 7, 7] 表示每個像素有 2 個類別的得分，符合 FCN 分割目標。
- **假設數據**：這裡使用簡化值展示，實際權重由訓練決定。
- **參數調整**：轉置卷積的 output_padding=1 確保輸出精確匹配輸入尺寸 7×7。