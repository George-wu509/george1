
|                                       |     |
| ------------------------------------- | --- |
| [[###**1. MobileNet**]]               |     |
| [[###**2. EfficientNet**]]            |     |
| [[###- **YOLOv5-Lite/YOLOv8-Nano:**]] |     |
| [[###SSD-MobileNet]]                  |     |






**輕量化 CNN 的核心概念：**

輕量化 CNN 的設計目標是在保持模型準確度的前提下，大幅降低模型的計算複雜度和參數數量，使其能夠在資源有限的裝置（例如手機、嵌入式系統）上高效運行。

### **1. MobileNet**

- **核心特點：**
    - **深度可分離卷積（Depthwise Separable Convolution）：** 這是 MobileNet 的核心創新。它將標準卷積分解為兩個步驟：
        - **深度卷積（Depthwise Convolution）：** 對每個輸入通道獨立進行卷積。
        - **逐點卷積（Pointwise Convolution）：** 使用 1x1 卷積組合深度卷積的輸出。
    - 這種分解方式大幅減少了計算量和參數數量。
    - 引入 Width Multiplier 與 Resolution Multiplier，讓使用者可以更彈性的去調整模型的大小與準確度。
- **與傳統 CNN 的差異：**
    - 傳統 CNN 使用標準卷積，同時進行空間和通道的卷積，計算量較大。
    - MobileNet 的深度可分離卷積大大降低了計算成本。
- **應用場景：**
    - 行動裝置上的圖像分類、物件偵測、人臉辨識等任務。


### **2. EfficientNet**

- **核心特點：**
    - **複合縮放（Compound Scaling）：** EfficientNet 提出了一種統一的縮放方法，同時調整模型的深度（depth）、寬度（width）和解析度（resolution），以達到最佳的效能。
    - 使用 AutoML 自動搜尋最佳模型結構。
    - 使用 MobileNetV2 所使用的反向殘差結構(Inverted residuals)與壓縮激活(Squeeze-and-Excitation Networks)。
- **與傳統 CNN 的差異：**
    - 傳統 CNN 通常只單獨調整模型的某個維度（例如深度）。
    - EfficientNet 的複合縮放方法能夠更有效地平衡模型的各個維度，提高效能。
- **應用場景：**
    - 需要高精度和高效率的圖像分類任務。

好的，針對您關於 EfficientNet 調整模型深度、寬度、解析度的問題，詳細解釋如下：

**1. EfficientNet 如何調整深度 (Depth)、寬度 (Width) 和解析度 (Resolution)？是 AutoML 嗎？**

EfficientNet 的調整方法是一個巧妙的兩階段過程，**不完全是**直接用 AutoML 同時調整您提到的所有參數來得到每個版本的模型 (EfficientNet-B1, B2, ...)。

- **階段一：使用神經架構搜索 (NAS) 找到優秀的基線模型 (Baseline Model - EfficientNet-B0)**
    
    - EfficientNet 的作者首先使用了一種神經架構搜索（NAS，這是一種 AutoML 技術）來找到一個在準確率和計算效率（以 FLOPS 衡量）之間取得良好平衡的**基礎網路架構**，命名為 EfficientNet-B0。
    - 這個 NAS 過程會探索不同的架構選擇，例如卷積塊的類型（主要是 MBConv 結構）、擴展比例、**卷積核大小 (kernel size)**、激活函數、連接方式等等，以自動發現一個高效的基礎骨幹網路。
- **階段二：提出並應用複合縮放方法 (Compound Scaling Method) 放大基線模型**
    
    - 在得到 EfficientNet-B0 這個優秀的基線後，作者提出了一個核心觀點：單獨放大網路的深度、寬度或解析度中任何一個維度都會遇到瓶頸，**同時、均衡地**放大這三個維度效果最好。
    - 他們定義了三個縮放係數：
        - `d = α^φ` (深度縮放因子)
        - `w = β^φ` (寬度縮放因子)
        - `r = γ^φ` (解析度縮放因子)
    - 這裡的 `φ` 是一個用戶指定的**複合係數 (compound coefficient)**，用來控制總體的放大程度。`α, β, γ` 是常數，代表了如何將資源分配給深度、寬度和解析度這三個維度。
    - 作者通過在**基線模型 EfficientNet-B0** 上進行小範圍的**網格搜索 (Grid Search)**（_而不是_ 再次使用 NAS/AutoML）來確定 `α, β, γ` 的最佳值（大約是 α ≈ 1.2, β ≈ 1.1, γ ≈ 1.15），目標是在稍微增加計算量（約 2 倍 FLOPS）的情況下最大化 B0 的準確率。
    - 對於後續的 EfficientNet-B1 到 B7 模型，他們**並不是**重新運行 NAS 或 AutoML。而是**固定**了通過網格搜索得到的 `α, β, γ` 值，然後**逐步增加**複合係數 `φ` (φ=1, 2, ..., 7)，並根據上述公式計算出 `d, w, r` 的值。
    - 接著，他們將這些縮放因子應用到 EfficientNet-B0 架構上：
        - **深度 (Depth) 縮放：** 增加網路中的**層數 (layer number)**，通常是增加主要模塊（MBConv blocks）的重複次數。
        - **寬度 (Width) 縮放：** 增加每一層的**通道數量 (channel number)**，通常是將 B0 中各層的通道數乘以 `w`。
        - **解析度 (Resolution) 縮放：** 增加輸入圖像的**高度和寬度**，通常是將 B0 的輸入解析度乘以 `r`。
    - **卷積核大小 (Kernel Size)** 通常是在階段一的 NAS 過程中確定的（作為 B0 架構的一部分），在階段二的複合縮放過程中**一般不改變**。縮放主要影響的是層的數量和通道數。

**總結 Q1：** EfficientNet 的方法是 **NAS (AutoML) 用於尋找基線架構 (B0) + 公式化的複合縮放 (Compound Scaling) 用於從 B0 放大到 B1-B7**。複合縮放本身不是 AutoML，而是一種基於固定比例、系統性地同時增加模型深度（層數）、寬度（通道數）和輸入解析度的方法。它不直接在縮放過程中調整卷積核大小。

**2. 最佳的效能 (Optimal Performance) 是指什麼？用什麼 Loss Functions？**

- **最佳效能的含義：**
    
    - 在 EfficientNet 的論文和實踐中，「最佳效能」主要指的是在給定的**計算資源預算 (Computational Budget)**（通常用 FLOPS 或模型參數數量來衡量）下，實現**最高的模型準確率 (Accuracy)**（例如，在 ImageNet 數據集上的 Top-1 準確率）。
    - 複合縮放方法的目標就是找到一種比單獨縮放任一維度更**高效**的策略，即用更少的計算量（FLOPS）或更少的參數來達到相同的準確率，或者在相同的計算量下達到更高的準確率。
- **Loss Functions (損失函數)：**
    
    - 在**訓練**任何特定 EfficientNet 模型（無論是 B0 還是 B1-B7）進行圖像分類任務時（如在 ImageNet 上訓練），所使用的**主要損失函數**是**交叉熵損失 (Cross-Entropy Loss)**。這是多類別分類問題的標準損失函數。
    - 在階段一使用 NAS 尋找 EfficientNet-B0 架構時，其優化的**獎勵函數 (Reward Function)** 可能是一個**複合目標**，不僅僅是準確率，可能還會直接或間接地考慮模型的 FLOPS 或延遲，以鼓勵找到既準確又高效的架構。但這是在架構搜索階段使用的內部評估指標。
    - 對於最終模型的公開訓練和評估，標準的交叉熵損失是用於優化模型權重的。

**總結 Q2：** EfficientNet 追求的「最佳效能」主要是指**在計算成本（FLOPS）約束下達到最高的分類準確率**。其模型在進行圖像分類任務訓練時，使用的標準損失函數是**交叉熵損失 (Cross-Entropy Loss)**。







**3. 常用的輕量物件偵測模型：**

### - **YOLOv5-Lite/YOLOv8-Nano:**
    - YOLO 系列的輕量版本，針對行動裝置和嵌入式系統進行了優化。
    - 使用輕量化的骨幹網路和高效的偵測頭。
    - 輕量化模型在精度上可能稍遜於大型模型，但在速度上具有明顯優勢。
- **SSD-MobileNet:**
    - 結合 SSD（Single Shot MultiBox Detector）物件偵測框架和 MobileNet 骨幹網路。
    - 在速度和準確度之間取得了良好的平衡。

**輕量化 CNN 的共同特點：**

- **更少的參數和計算量：** 適用於資源有限的裝置。
- **更快的推理速度：** 實現即時應用。
- **模型壓縮技術：**
    - 例如模型剪枝(model pruning)與量化(quantization)，常常被應用在輕量化模型上面，更加減少模型的參數與計算。

**與一般 CNN 的差異總結：**

- 一般 CNN 追求更高的準確度，通常具有更深的網路結構和更多的參數。
- 輕量化 CNN 追求更高的效率，通過創新的網路結構和優化方法，在保持一定準確度的前提下，大幅降低計算成本。


### SSD-MobileNet 

理解 SSD-MobileNet 的結構，需要將兩個關鍵組件分開來看，然後理解它們是如何結合的：SSD（Single Shot MultiBox Detector）和 MobileNet。

**1. SSD（Single Shot MultiBox Detector）**

- **核心特點：**
    - SSD 是一種單階段（single-shot）目標偵測器，這意味著它直接從輸入圖像預測目標的邊界框和類別，而不需要像兩階段偵測器（例如 Faster R-CNN）那樣先生成候選區域。
    - **多尺度特徵圖（Multi-scale Feature Maps）：** SSD 的一個關鍵特點是使用來自網路不同層次的多個特徵圖進行預測。這使其能夠檢測不同尺寸的目標。較淺的層次可以檢測較小的目標，而較深的層次可以檢測較大的目標。這某種程度上達到類似Feature Pyramid Network的效果，但是作法上稍有不同。
    - **預設框（Default Boxes）：** SSD 在每個特徵圖單元位置放置一組預設框，這些預設框具有不同的尺寸和長寬比。模型學習調整這些預設框，以更好地匹配真實目標。
- **與 Feature Pyramid Network (FPN) 的關係：**
    - 雖然 SSD 通過使用多個特徵圖實現了多尺度檢測，但它與 FPN 的方法有所不同。FPN 通過自上而下的方式構建特徵金字塔，增強了低層次特徵的語義資訊。
    - SSD 直接利用網絡前向運算的各層Feature map, FPN則是將高層的語意特徵向底層傳遞。
    - 因此，可以說 SSD 具有類似 FPN 的多尺度檢測能力，但實現方式不同。

**2. MobileNet**

- **核心特點：**
    - MobileNet 是一種輕量級的 CNN 架構，專為行動和嵌入式裝置設計。
    - 它使用深度可分離卷積，顯著減少了計算成本和參數數量。

**3. SSD-MobileNet 的結合**

- **結構：**
    - SSD-MobileNet 將 MobileNet 作為其骨幹網路（backbone network）。這意味著 MobileNet 負責從輸入圖像中提取特徵。
    - 然後，SSD 的多尺度預測層被添加到 MobileNet 的不同層次的特徵圖上。
    - 具體來說，在 MobileNet 的幾個關鍵層次之後，添加了額外的卷積層，這些層輸出的特徵圖用於預測目標的邊界框和類別。
    - 因此MobileNet負責輕量化的特徵提取，SSD負責多尺度的目標檢測。
- **優勢：**
    - 這種結合使得 SSD-MobileNet 能夠在資源有限的裝置上實現實時目標檢測。
    - MobileNet 提供了輕量級的特徵提取，而 SSD 提供了高效的多尺度目標檢測能力。

**總結：**

- SSD-MobileNet 是一種高效的目標檢測模型，通過結合 MobileNet 的輕量級特徵提取和 SSD 的多尺度預測能力，實現了在資源有限的裝置上的實時目標檢測。
- SSD 本身透過利用深淺不同的feature map 來達到多尺度檢測的效果，因此，跟FPN的作用類似，但是實作方式不同。