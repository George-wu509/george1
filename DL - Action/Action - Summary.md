

|                                        |                                                                                                                                                                                                                                                                                                   |                                             |
| -------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------- |
| 動作識別<br>（Action Recognition）           | 這是視頻動作分析的核心領域，旨在從整個視頻序列中識別出發生的動作類型。它通常將視頻視為一個整體或分段，提取時空特徵（時間序列和空間圖像），並分類為預定義的動作類別（如「跑步」或「揮手」）。重點在於分類準確性，而非精確定位動作的起始時間或空間位置。常使用深度學習模型處理視頻幀序列，捕捉運動模式。<br><br>類別: **針對整個影片輸出一個結果**<br>模型將整個視頻視為單一單位，輸出一個動作類別（如「跑步」），重點在全局分類，而非細分片段或定位。適合快速判斷視頻主題，但忽略時間細節。<br><br>                                    | 在醫療監控中，識別老人「跌倒」動作，觸發警報                      |
| 動作檢測<br>（Action Detection）             | 這是動作識別的進階版，不僅識別動作類型，還需檢測動作在視頻中的時間範圍（起始和結束幀）和空間位置（e.g., 邊界框）。分為時間動作檢測（Temporal Action Detection，只考慮時間）和時空動作檢測（Spatio-Temporal Action Detection，考慮時間+空間）。它處理未修剪的長視頻，需處理背景噪音和多動作重疊。<br><br>類別: **針對影片中的各片段輸出結果以及開始結束時間**<br>模型檢測視頻中動作發生的片段，輸出類別並標記起始/結束時間（如「偷竊」從第10秒到20秒），強調時空定位，適用於監控或事件追蹤。<br><br> | 在監控視頻中，檢測小偷「偷竊」的起始時間和位置，生成警報並標記嫌疑人邊界框       |
| 關鍵點檢測（Keypoint Detection）              | 聚焦於檢測視頻中物件（通常是人類身體）的關鍵點位置，如關節（手肘、膝蓋、肩膀）。在視頻中，它需追蹤這些點的時間序列，形成姿勢估計。分為 2D（平面坐標）和 3D（帶深度）。這不是直接分類動作，而是提供低層級特徵，用於更高層分析。<br><br><br>類別: **針對影片內特定區域或追蹤點輸出結果**<br>模型追蹤視頻中特定點位（如人體關節），輸出坐標或軌跡（如膝蓋位置），聚焦空間精準，不涉及整體動作分類，常用於姿勢分析。<br><br>                                                                    | 在醫療復健中，追蹤患者膝蓋關鍵點，分析走路異常                     |
| 動作分割<br>（Action Segmentation)          | 常稱 Temporal Action Segmentation 聚焦於將長視頻序列分解成連續的細粒度動作片段，每個片段標記起始/結束時間和動作類型。不同於簡單分類，它處理未修剪的長視頻，捕捉動作轉換和持續時間。常使用序列模型（如 RNN 或 Transformer）處理時間依賴<br><br>類別: **針對影片中的各片段輸出結果以及開始結束時間**<br>模型將長視頻分割成連續片段，輸出每個片段的動作類別及時間邊界（如「切菜」從0-5秒），強調時間連續性，適合流程分析如烹飪或生產線。<br><br>                                     | 在廚房烹飪視頻中，將過程分割為「切菜」、「炒菜」、「盛盤」等片段，用於食譜教學 App |
| 動作預測<br>（Action Prediction)            | 在從部分觀察的視頻前綴預測未來即將發生的動作或動作序列。重點在於時間因果推斷，使用因果模型或生成式 AI（如 GAN 或 Diffusion Models）模擬未來幀。處理不確定性和長程依賴，適合實時應用<br><br>類別: **針對影片中的各片段輸出結果**<br>模型基於前段視頻預測未來片段的動作（如預測「即將跌倒」），輸出預測結果，但通常不需精確時間邊界，適用於預防系統如自動駕駛。<br><br>                                                                                      | 在自動駕駛中，從行人當前姿勢預測「即將過馬路」，提前煞車避免事故            |
| 異常動作檢測（Anomaly Action Detection）       | 這專注於識別視頻中偏離正常模式的動作，如意外或異常行為。使用無監督或半監督學習（如 Autoencoder 或 One-Class SVM），重建正常數據並檢測偏差。適合稀有事件，處理長視頻噪音<br><br>類別: **針對影片中的各片段輸出結果以及開始結束時間**<br>模型檢測視頻中異常片段，輸出類別及時間邊界（如「打鬥」從15-25秒），聚焦偏差模式，適合安全監控，類似動作檢測但強調異常。<br><br>                                                                                  | 在公共監控中，檢測人群中「打鬥」或「盜竊」異常，自動通知保安              |
| 動作質量評估（Action Quality Assessment, AQA） | 評估動作執行的質量、熟練度或正確性，而非僅分類。使用回歸模型預測分數（如 0-10 分），基於姿勢、流暢度和標準模板比較。常應用於技能評估，融入多模態數據（如視頻+感測器）<br><br>類別: **針對整個影片輸出一個結果**<br>模型評估整個視頻的動作質量，輸出單一分數（如體操得分8.5），聚焦熟練度或正確性，不需片段分割，適用於體育或醫療評估。<br><br>                                                                                                         | 在體育比賽中，評估體操選手「翻滾」動作的質量分數，用於裁判輔助             |
|                                        |                                                                                                                                                                                                                                                                                                   |                                             |
|                                        |                                                                                                                                                                                                                                                                                                   |                                             |
|                                        |                                                                                                                                                                                                                                                                                                   |                                             |

Reference:
端到端大模型2.0 - VLA (Vision Language Action) 介绍 - 冯泇铖的文章 - 知乎
https://zhuanlan.zhihu.com/p/15468949634

杂七杂八学习笔记（2）(Action recognition) - Hongda Jiang的文章 - 知乎
https://zhuanlan.zhihu.com/p/498264826

基于视频的动作识别终极指南【2024】 - 汇智网的文章 - 知乎
https://zhuanlan.zhihu.com/p/679116978

视频分析入门之 Action Proposal - 赵zhijian的文章 - 知乎
https://zhuanlan.zhihu.com/p/32265681

https://www.zhihu.com/search?type=content&q=Action%20Detection