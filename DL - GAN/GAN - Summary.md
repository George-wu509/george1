
|                                      |     |
| ------------------------------------ | --- |
| [[### GAN、ESRGAN 和 Real-ESRGAN 的架構]] |     |
| [[### GAN、ESRGAN 與 Real-ESRGAN詳細介紹]] |     |
| [[### GAN (DCGAN)的網路架構]]             |     |
| [[### GAN具體舉例]]                      |     |
| [[### QA list]]                      |     |

|             |                                |
| ----------- | ------------------------------ |
| GAN         | 超解析度領域的基礎，提供了生成逼真圖像的能力。        |
| ESRGAN      | 在 GAN 的基礎上進行了改進，提高了圖像重建的品質。    |
| Real-ESRGAN | 專注於處理真實世界圖像的複雜退化，使其在實際應用中更具優勢。 |
**GAN**:  
    生成器(Generator) 生成新的資料: 殘差網路 (Residual Network)
	鑑別器（Discriminator） 判斷樣本是真實的還是生成的: VGG 網路

**ESRGAN**:  
	生成器(Generator) 生成新的資料: RRDB（Residual-in-Residual Dense Block）
	鑑別器（Discriminator） 相對判別器 (Relativistic Discriminator)
	改善 Discriminator跟loss function

**Real-ESRGAN**:  
    生成器(Generator) 生成新的資料: RRDB（Residual-in-Residual Dense Block）
	鑑別器（Discriminator） 改成U-Net結構加上Spectral Normalization(SN)以增強判別器的能力並穩定訓練過程


### GAN、ESRGAN 和 Real-ESRGAN 的架構

GAN、ESRGAN 和 Real-ESRGAN 的架構，以及它們在超解析度（Super Resolution）方面的能力和優缺點：



![[Pasted image 20250327041059.png]]

**1. GAN（生成對抗網路）**

- **架構：**
    - GAN 由兩個主要的神經網路組成：
        - **生成器（Generator）：** 負責生成新的資料樣本（在這裡是高解析度圖像）。
        - **鑑別器（Discriminator）：** 負責判斷一個樣本是真實的還是生成的。
    - 這兩個網路進行對抗式訓練：生成器試圖生成逼真的圖像來欺騙鑑別器，而鑑別器則努力區分真實和生成的圖像。
- **在超解析度中的應用：**
    - GAN 可以用於生成更逼真的高解析度圖像，因為它們能夠捕捉到圖像的細節和紋理。
- **優點：**
    - 能夠生成非常逼真的圖像。
    - 能夠捕捉到圖像的細節和紋理。
- **缺點：**
    - 訓練不穩定，可能出現模式崩潰（mode collapse）等問題。
    - 可能產生不希望的人工痕跡。
    - 
	GAN（[Generative Adversarial Nets (生成对抗网络)](https://blog.csdn.net/qq_42728437/article/details/129829711)）
	


![[Pasted image 20250327035326.png]]

**2. ESRGAN（增強型超解析度生成對抗網路）**

- **架構：**
    - ESRGAN 是在 GAN 的基礎上改進的超解析度模型。
    - 它引入了 RRDB（Residual-in-Residual Dense Block）作為生成器的基本構建塊，這使得網路更深、更複雜，從而提高了圖像重建的品質。
    - 並且改善鑑別器，還有loss function。
- **在超解析度中的能力：**
    - ESRGAN 能夠生成比傳統方法更清晰、更逼真的高解析度圖像。
    - 它能夠更好地恢復圖像的細節和紋理。
- **優點：**
    - 生成更高品質的超解析度圖像。
    - 更好地恢復圖像的細節和紋理。
    - 更穩定的訓練過程。
- **缺點：**
    - 計算量大，需要更強的計算資源。
    - 還是有可能產生不希望的人工痕跡。

![[Pasted image 20250327035409.png]]

**3. Real-ESRGAN（真實世界增強型超解析度生成對抗網路）**

- **架構：**
    - Real-ESRGAN 是專為處理真實世界低解析度圖像而設計的模型。
    - 它採用了更複雜的降解過程，以更真實地模擬真實世界圖像的退化。
    - 其中也使用了Sinc濾波器等等手段。
    - 也對鑑別器加以改善。
- **在超解析度中的能力：**
    - Real-ESRGAN 能夠有效地處理各種真實世界圖像的退化，包括模糊、雜訊和壓縮偽影。
    - 它能夠生成清晰且逼真的高解析度圖像，即使在處理非常模糊或低品質的圖像時也能產生較好成果。
- **優點：**
    - 能夠處理真實世界圖像的複雜退化。
    - 在處理非常低品質的圖像時也能產生較好成果。
    - 更加考慮到真實圖片會遇到的各種問題，讓生成的圖片更真實。
- **缺點：**
    - 模型複雜度高，計算量較大。
    - 針對特殊情況，可能需要調整參數。

**總結比較：**

- GAN 是超解析度領域的基礎，提供了生成逼真圖像的能力。
- ESRGAN 在 GAN 的基礎上進行了改進，提高了圖像重建的品質。
- Real-ESRGAN 則專注於處理真實世界圖像的複雜退化，使其在實際應用中更具優勢。


### GAN、ESRGAN 與 Real-ESRGAN詳細介紹

## GAN、ESRGAN 與 Real-ESRGAN 在超解析度領域的詳細比較

在圖像超解析度（Super Resolution, SR）技術中，生成對抗網路（Generative Adversarial Networks, GANs）及其衍生模型扮演了舉足輕重的角色。這些模型致力於從低解析度（Low-Resolution, LR）圖像生成高解析度（High-Resolution, HR）圖像，並追求更逼真、更清晰的視覺效果。以下將詳細比較 GAN、ESRGAN (Enhanced Super-Resolution Generative Adversarial Network) 以及 Real-ESRGAN 在超解析度方面的能力與優缺點。

### 1. 生成對抗網路 (GAN) 在超解析度的應用

**基本原理：**

GAN 由兩個核心部分組成：生成器（Generator）和判別器（Discriminator）。在超解析度任務中：

- **生成器 (G)：** 負責<mark style="background: #ABF7F7A6;">接收低解析度圖像作為輸入，並試圖生成對應的高解析度圖像</mark>。它的目標是讓生成的圖像盡可能逼真，難以與真實的高解析度圖像區分。
- **判別器 (D)：** 負責<mark style="background: #FFB86CA6;">判斷輸入的圖像是真實的高解析度圖像還是由生成器生成的假圖像</mark>。它的目標是盡可能準確地識別出假圖像。

這兩個網路相互博弈，共同進步。生成器努力欺騙判別器，而判別器則努力識破生成器的偽裝。透過這種對抗性的訓練過程，生成器最終能夠學習到從低解析度圖像到高解析度圖像的複雜映射關係，從而生成視覺上更令人信服的高解析度圖像。

**在超解析度方面的能力：**

- **生成更銳利的邊緣和更豐富的紋理：** 相比於傳統的基於插值或簡單迴歸的超解析度方法（例如 PSNR 導向的方法），GAN 能夠生成包含更多高頻細節的圖像，使得圖像看起來更清晰、紋理更豐富。這是因為 GAN 的目標是視覺上的真實感，而不僅僅是像素級的相似度。
- **感知損失 (Perceptual Loss)：** 許多基於 GAN 的超解析度模型（如 SRGAN）引入了感知損失函數。感知損失通常利用預訓練的深度神經網路（如 VGG 網路）提取圖像的特徵，並計算生成圖像與真實高解析度圖像在特徵空間上的差異。這種損失函數比傳統的均方誤差 (MSE) 損失更能捕捉人類視覺系統對圖像質量的感知，從而引導生成器產生更符合人眼審美的結果。

**優點：**

- **生成結果更逼真：** GAN 的核心優勢在於能夠生成視覺上更自然、更接近真實高解析度圖像的結果。
- **細節恢復能力強：** 能夠在一定程度上恢復圖像中丟失的細節和紋理。

**缺點：**

- **訓練不穩定：** GAN 的訓練過程非常敏感，容易出現模式崩潰 (mode collapse)、梯度消失或梯度爆炸等問題，導致訓練困難且結果不穩定。
- **容易產生偽影 (Artifacts)：** 為了追求視覺上的真實感，GAN 有時會生成一些實際上並不存在的紋理或細節，即偽影。這些偽影可能看起來不自然或令人不悅。
- **生成細節的一致性較差：** 有時生成的細節可能與圖像的整體內容不夠協調。
- **對真實世界複雜降級的處理能力有限：** 傳統的 GAN 模型通常在合成的、簡單降級（如雙三次插值下採樣）的數據集上表現較好，但對於真實世界中複雜且未知的圖像降級（如模糊、噪點、壓縮失真等混合）處理效果不佳。

### 2. 增強型超解析度生成對抗網路 (ESRGAN)

**基本原理：**

ESRGAN 是在 SRGAN 基礎上的重要改進，旨在解決 SRGAN 生成圖像中仍然存在的偽影問題，並進一步提升視覺質量。其主要改進點包括：

- **移除批次歸一化 (Batch Normalization, BN) 層：** 研究發現，在 GAN 的生成器中使用 BN 層，尤其是在較深網路或進行殘差學習時，可能會引入偽影，並限制模型的表達能力。ESRGAN 移除了生成器中的 BN 层，從而提升了模型的性能和穩定性，減少了偽影。
- **引入殘差密集塊 (Residual-in-Residual Dense Block, RRDB)：** ESRGAN 採用了更深、更複雜的生成器網路結構，其核心是 RRDB。這種結構允許網路學習到更深層次的特徵，並通過殘差學習促進了梯度的傳播，使得網路更容易訓練，同時也提升了細節恢復能力。
- **改進的感知損失：** ESRGAN 在感知損失的計算上有所調整，更側重於激活前的特徵，這被認為能提供更銳利且更自然的紋理。
- **相對判別器 (Relativistic Discriminator)：** ESRGAN 引入了相對平均判別器 (Relativistic average Discriminator, RaD)。傳統判別器的目標是判斷輸入圖像的“絕對”真實性（是真的還是假的）。而相對判別器則判斷“真實圖像比生成圖像更真實”的概率，或者反過來。這種相對的判斷方式有助於生成器生成更逼真的圖像，因為它不僅要欺騙判別器，還要讓自己生成的圖像比真實圖像“看起來更真”。

**在超解析度方面的能力：**

- **生成更銳利、更自然的細節：** 由於移除了 BN 層和採用了 RRDB 結構，ESRGAN 能夠生成比 SRGAN 更清晰、細節更豐富且偽影更少的圖像。
- **更好的紋理合成：** 相對判別器和改進的感知損失使得 ESRGAN 在合成逼真紋理方面表現更出色。

**優點：**

- **顯著減少偽影：** 相比於 SRGAN，ESRGAN 生成的圖像偽影更少，視覺效果更佳。
- **細節更豐富銳利：** 能夠生成更清晰、更精細的圖像細節。
- **視覺質量高：** 在多個標準測試集和視覺評估中，ESRGAN 通常能取得領先的結果。

**缺點：**

- **仍然可能產生少量偽影：** 雖然有所改善，但在某些情況下，ESRGAN 仍然可能生成一些不自然的紋理。
- **對真實世界降級的處理仍然不理想：** 與 GAN 類似，ESRGAN 主要還是針對已知的、簡單的圖像降級（如下採樣）進行訓練和優化。對於真實世界中拍攝的、包含複雜混合降級（如模糊、噪點、JPEG 壓縮失真等）的低解析度圖像，其效果會大打折扣，生成的圖像可能仍然不夠自然或出現新的問題。
- **模型複雜度較高：** RRDB 結構使得生成器網路更深，計算量也相應增加。

### 3. 真實世界增強型超解析度生成對抗網路 (Real-ESRGAN)

**基本原理：**

Real-ESRGAN 的核心目標是解決 ESRGAN 在處理真實世界圖像時的不足。真實世界的低解析度圖像通常包含複雜且未知的降級過程，而不僅僅是簡單的雙三次插值下採樣。Real-ESRGAN 的主要創新在於其**更貼近真實世界的降級模型**和相應的訓練策略：

- **更複雜的“真實世界”降級過程建模：** Real-ESRGAN 在訓練過程中，不再僅僅使用簡單的雙三次插值來生成低解析度圖像。它引入了一個更複雜的降級模型，該模型會隨機地組合多種常見的圖像降級操作，例如：
    - **模糊 (Blur)：** 模擬鏡頭失焦、運動模糊等。
    - **噪點 (Noise)：** 模擬感光元件噪點、信號干擾等。
    - **縮放 (Resize)：** 模擬不同程度的下採樣。
    - **JPEG 壓縮 (JPEG Compression)：** 模擬圖像在存儲和傳輸過程中常見的壓縮失真。
    - 這些降級操作的順序和參數都是隨機的，從而生成更接近真實世界低解析度圖像的訓練數據。它還考慮了振鈴效應 (ringing artifacts) 和過沖效應 (overshoot artifacts) 等更細緻的降級現象。
- **高階降級過程 (High-order Degradation Modeling)：** 為了進一步模擬真實世界中多次處理導致的降級疊加，Real-ESRGAN 可能會重複應用上述的降級過程。
- **針對真實世界數據的微調：** 雖然核心是更強大的合成降級數據，但 Real-ESRGAN 也可以利用真實世界的圖像數據進行微調，以進一步提升其泛化能力。
- **與 ESRGAN 相似的生成器和判別器結構：** Real-ESRGAN 通常沿用了 ESRGAN 的生成器 (基於 RRDB) 和判別器 (相對判別器) 結構，其主要創新在於訓練數據的生成方式。

**在超解析度方面的能力：**

- **顯著提升對真實世界圖像的處理效果：** 由於其訓練數據更接近真實世界的複雜降級，Real-ESRGAN 在處理帶有模糊、噪點、壓縮失真等問題的真實低解析度圖像時，能夠生成更自然、更清晰且偽影更少的結果。
- **更強的泛化能力：** 對於未知的、多樣的真實世界降級，Real-ESRGAN 表現出比 ESRGAN 更好的魯棒性和泛化能力。
- **有效去除真實世界的偽影和噪點：** 在提升解析度的同時，Real-ESRGAN 也能在一定程度上修復和去除原始低解析度圖像中的一些降級引入的缺陷。

**優點：**

- **專為真實世界圖像設計：** 其核心優勢在於能夠有效處理帶有複雜、未知降級的真實低解析度圖像。
- **泛化能力強：** 對於各種不同來源和降級程度的真實圖像，都能有較好的表現。
- **生成的圖像更自然、更乾淨：** 相比於在真實圖像上直接應用 ESRGAN，Real-ESRGAN 產生的偽影更少，噪點抑制效果更好。
- **開源且易於使用：** 提供了預訓練模型，方便用戶直接應用於自己的真實圖像。

**缺點：**

- **可能過度平滑：** 為了去除複雜的噪點和偽影，有時 Real-ESRGAN 可能會導致圖像的一些細微紋理被過度平滑掉，使得圖像看起來略微“塑料感”。
- **對極端降級的處理仍有局限：** 對於降級非常嚴重、信息損失過多的圖像，其恢復效果仍然有限。
- **計算量依然較大：** 繼承了 ESRGAN 的複雜網路結構，因此計算資源需求較高。
- **“真實”的定義是相對的：** 雖然其降級模型比以往更複雜，但“真實世界”的降級是無窮無盡的，模型仍然可能無法完美處理所有情況。

### 總結比較

|特性|GAN (通用於 SR)|ESRGAN|Real-ESRGAN|
|:--|:--|:--|:--|
|**核心思想**|生成器與判別器對抗學習|移除 BN 層，引入 RRDB，相對判別器|更複雜的真實世界降級模型，高階降級建模|
|**主要優勢**|生成逼真圖像，恢復紋理|顯著減少偽影，細節更豐富銳利，視覺質量高|專為真實世界圖像設計，泛化能力強，去除真實偽影和噪點|
|**主要劣勢**|訓練不穩定，易產生偽影，對真實降級處理能力有限|仍可能產生少量偽影，對真實降級處理仍不理想|可能過度平滑，對極端降級處理仍有局限|
|**訓練數據降級**|通常為簡單的雙三次插值下採樣|通常為簡單的雙三次插值下採樣|複雜的隨機組合降級（模糊、噪點、壓縮、縮放等）|
|**適用場景**|對圖像質量要求不高，或作為其他模型的基礎|對合成降級數據或質量較好的低解析度圖像進行超分|處理真實拍攝、帶有複雜未知降級的低解析度圖像|
|**偽影情況**|較多，且明顯|較少，但仍可能存在|更少，但可能引入平滑導致的細節損失|
|**細節恢復**|一般，可能產生不真實細節|好，細節銳利|較好，但側重於去除降級引入的失真，可能犧牲部分細微紋理|
|**對真實圖像**|效果差，偽影嚴重|效果一般，可能無法很好處理複雜降級|效果好，能較好適應真實世界的複雜降級|

**中文詳細解釋總結：**

- **GAN (生成對抗網路)** 是超解析度領域的一個基礎框架。它透過讓“生成圖像的畫家”（生成器）和“鑒別真偽的專家”（判別器）互相競爭，來學習如何將模糊的低解析度圖片變清晰。它的好處是能畫出看起來更真實、細節更多的圖片，但缺點是訓練起來不穩定，容易畫出一些奇怪的、不存在的東西（偽影），而且對於現實生活中那些因為各種原因（比如抖動、光線不好、壓縮過）變模糊的圖片，處理效果不太好。
    
- **ESRGAN (增強型超解析度生成對抗網路)** 可以看作是 GAN 在超解析度方面的一個“升級版畫家”。它改進了“畫家”的內部結構（移除了 BN 層，用了更厲害的 RRDB 結構）和“專家”的評判標準（用了相對判別器），這樣畫出來的圖片不僅更清晰、細節更豐富，而且那些奇怪的“偽影”也少了很多。不過，它主要還是針對那些比較“單純”的模糊圖片（比如只是簡單縮小的圖片）比較在行，遇到現實生活中那些“疑難雜症”圖片，還是有點力不從心。
    
- **Real-ESRGAN (真實世界增強型超解析度生成對抗網路)** 則是專門為了應對“現實生活中的疑難雜症圖片”而生的“超級畫家”。它最大的特點是在訓練的時候，就給“畫家”看了大量模擬真實世界各種複雜情況（比如又模糊、又有噪點、還被壓縮過）的圖片。這樣一來，這位“畫家”就練就了一身硬功夫，能夠很好地處理我們日常生活中遇到的各種低質量圖片，讓它們變得更清晰、更乾淨，並且有更強的“抗打擊能力”（泛化能力）。當然，為了把圖片弄乾淨，它有時候可能會把一些非常細小的紋理也一起“磨平”了，而且對於那些爛到幾乎沒救的圖片，它也回天乏術。
    

總而言之，從 GAN 到 ESRGAN 再到 Real-ESRGAN，是超解析度技術不斷向著更真實、更實用方向發展的過程。選擇哪種模型，取決於具體的應用場景以及對圖像質量的要求，特別是原始低解析度圖像的來源和降級特性。對於處理真實世界的模糊舊照片或網絡圖片，Real-ESRGAN 通常是目前更優的選擇。 好的，這就為您詳細比較 GAN、ESRGAN 和 Real-ESRGAN 在超解析度（Super Resolution）方面的能力和優缺點。

**概覽**

在深入探討每個模型的細節之前，我們先對這三者在超解析度領域的發展有一個大致的了解：

- **GAN (Generative Adversarial Network, 生成對抗網路)**：是一個通用的深度學習框架，不僅限於超解析度。SRGAN (Super-Resolution Generative Adversarial Network) 是將 GAN 的思想應用於超解析度任務的早期代表。它開創了利用對抗學習來生成更逼真細節高解析度影像的先河。
- **ESRGAN (Enhanced Super-Resolution Generative Adversarial Network, 增強型超解析度生成對抗網路)**：是 SRGAN 的改進版本。它針對 SRGAN 生成影像中可能出現的偽影和不夠自然的紋理進行了優化，旨在生成更銳利、細節更豐富且更自然的超解析度影像。
- **Real-ESRGAN (Real-World Enhanced Super-Resolution Generative Adversarial Network, 真實世界增強型超解析度生成對抗網路)**：是 ESRGAN 的進一步發展，主要目標是解決真實世界中低解析度影像的超解析度問題。真實世界的影像往往帶有複雜的、未知的退化（如模糊、噪點、壓縮失真等），Real-ESRGAN 致力於處理這些更具挑戰性的場景。

**詳細比較**

接下來，我們將從原理、超解析度能力和優缺點三個方面對它們進行詳細比較：

| 特性         | GAN (以 SRGAN 為例)                                             | ESRGAN                                                                                                                              | Real-ESRGAN                                                                                                                                          |
| :--------- | :----------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- |
| **中文全稱**   | 生成對抗網路 (應用於超解析度的 SRGAN)                                      | 增強型超解析度生成對抗網路                                                                                                                       | 真實世界增強型超解析度生成對抗網路                                                                                                                                    |
| **核心思想**   | 透過生成器和判別器的對抗學習，生成高解析度影像。判別器判斷生成影像的真實性，生成器努力欺騙判別器。            | 在 SRGAN 基礎上進行多方面增強，旨在提升生成影像的視覺品質和細節。                                                                                                | 針對真實世界複雜的影像退化進行建模和訓練，使其能更好地處理實際應用中的低解析度影像。                                                                                                           |
| **網路結構**   |                                                              |                                                                                                                                     |                                                                                                                                                      |
| - 生成器      | 通常基於殘差網路 (Residual Network)。                                 | 引入**殘差密集塊 (Residual-in-Residual Dense Block, RRDB)**，網路更深、更複雜，能學習更豐富的特徵。移除了 Batch Normalization (BN) 層，因其在 GAN 訓練中可能引入偽影並限制模型的泛化能力。 | 沿用了 ESRGAN 的 RRDB 結構作為核心。                                                                                                                            |
| - 判別器      | 傳統的 VGG 網路或類似結構，判斷輸入影像是否為真實的高解析度影像。                          | 引入**相對判別器 (Relativistic Discriminator)**，判斷真實影像比生成影像更真實的概率，反之亦然。這種相對比較能提供更有效的梯度指導生成器。                                               | 採用 **U-Net 結構的判別器，並結合光譜歸一化 (Spectral Normalization, SN)**，以增強判別器的能力並穩定訓練過程，使其能更好地應對複雜退化。                                                             |
| **損失函數**   |                                                              |                                                                                                                                     |                                                                                                                                                      |
| - 感知損失     | 使用 VGG 網路提取特徵，計算生成影像和真實高解析度影像在特徵空間的距離。通常使用 VGG 網路**激活後**的特徵。 | 改進感知損失，使用 VGG 網路**激活前**的特徵。研究發現激活前的特徵更稠密，能提供更強的監督信號，避免亮度不一致和偽影問題。                                                                   | 延續 ESRGAN 的感知損失策略，並可能結合其他損失函數以優化針對真實世界退化的效果。通常包含感知損失、對抗損失和像素損失（如 L1 損失）的組合。                                                                          |
| - 對抗損失     | 標準的 GAN 對抗損失。                                                | 配合相對判別器，使用相對平均對抗損失 (Relativistic average Adversarial Loss)。                                                                         | 配合 U-Net 判別器，使用對抗損失。                                                                                                                                 |
| **訓練數據**   | 通常使用高解析度影像，並通過簡單的下採樣（如雙三次插值）得到低解析度影像進行配對訓練。                  | 與 SRGAN 類似，主要使用合成的低解析度-高解析度影像對進行訓練。                                                                                                 | **核心創新之一是引入更高階的退化模型 (High-order Degradation Model)**。它模擬真實世界中影像可能經歷的多重退化過程（如模糊、下採樣、噪點、JPEG 壓縮等，並且可能是這些過程的多次迭代）。**完全使用合成數據進行訓練**，但這些合成數據更接近真實世界的退化情況。 |
| **超解析度能力** |                                                              |                                                                                                                                     |                                                                                                                                                      |
| - 細節生成     | 能夠生成一些 SRCNN 等傳統方法難以生成的細節，但有時細節可能不夠自然或帶有偽影。                  | 生成的影像在**銳利度和細節豐富度上顯著優於 SRGAN**，紋理更自然，偽影更少。                                                                                          | 在處理真實世界中帶有複雜退化的影像時，能生成更逼真、更自然的細節，並有效去除偽影。                                                                                                            |
| - 真實感      | 相比傳統方法有提升，但有時生成結果看起來仍然有些“假”。                                 | **顯著提升了生成影像的視覺真實感**，更接近人眼觀察到的自然影像。                                                                                                  | 專為真實世界影像設計，因此在處理貼近生活的照片、影片截圖等時，**真實感和自然度非常出色**。                                                                                                      |
| - 泛化能力     | 對於與訓練數據相似退化模式的影像效果較好，但對於未知或複雜退化的真實影像效果可能不佳。                  | 相比 SRGAN 有所提升，但其訓練數據仍主要基於簡單的合成退化，對於真實世界複雜退化的泛化能力有限。                                                                                 | **核心優勢在於其對真實世界複雜退化的強大泛化能力**。由於採用了更逼真的退化模型進行訓練，它能更好地處理各種未知的模糊、噪點和壓縮失真。                                                                                |
| **優點**     |                                                              |                                                                                                                                     |                                                                                                                                                      |
|            | - 開創了使用 GAN 進行超解析度，能生成更逼真細節的先河。                              | - 生成的影像銳利度高，細節豐富。                                                                                                                   | - **處理真實世界影像效果極佳**，能應對複雜、未知的影像退化。                                                                                                                    |
|            | - 相對於傳統的基於插值或簡單 CNN 的方法，視覺效果有顯著提升。                           | - 顯著減少了 SRGAN 中常見的偽影。                                                                                                               | - **泛化能力強**，對不同類型的真實退化都有較好的效果。                                                                                                                       |
|            |                                                              | - 引入 RRDB 網路結構和相對判別器，提升了模型性能和訓練穩定性。                                                                                                 | - 提出的高階退化模型更貼近實際情況。                                                                                                                                  |
|            |                                                              | - 感知損失的改進使得生成的影像亮度和紋理更準確。                                                                                                           | - 使用 U-Net 判別器和光譜歸一化，增強了判別能力並穩定訓練。                                                                                                                   |
|            |                                                              |                                                                                                                                     | - 僅使用合成數據訓練，降低了對大量真實成對數據的需求。                                                                                                                         |
| **缺點**     |                                                              |                                                                                                                                     |                                                                                                                                                      |
|            | - 訓練不穩定，容易出現模式崩潰 (mode collapse)。                            | - 雖然有所改進，但對於非常複雜或未在訓練中充分覆蓋的真實世界退化，效果仍可能打折扣。                                                                                         | - **高階退化模型雖然更複雜，但仍不能完全覆蓋所有真實世界的退化情況。** 對於某些極端的或特定類型的偽影，可能仍無法完美去除，甚至可能放大。                                                                             |
|            | - 生成的影像有時會產生不自然的紋理或偽影 (artifacts)。                           | - 訓練所需的計算資源較大。                                                                                                                      | - **對於一些特定場景（如建築、室內），可能產生輕微的線條扭曲。**                                                                                                                  |
|            | - 對於真實世界中複雜的退化（如噪點、模糊混合）處理能力有限。                              |                                                                                                                                     | - GAN 固有的訓練不穩定性問題雖然有所緩解，但仍可能在某些情況下引入不期望的偽影。                                                                                                          |
|            | - 感知損失的選擇和權重對結果影響較大。                                         |                                                                                                                                     | - 計算複雜度相對較高。                                                                                                                                         |

**總結與中文詳細解釋**

- **GAN (SRGAN) 的超解析度能力與優缺點：**
    
    - **能力**：SRGAN 的主要貢獻在於引入了生成對抗網路來提升超解析度影像的視覺真實感。它不再僅僅追求峰值信噪比 (PSNR) 等傳統指標，而是更注重人眼感知的圖像質量，能夠生成一些此前方法難以恢復的紋理細節。
    - **優點**：
        - **生成更逼真的細節**：相比於傳統的雙三次插值或基於簡單卷積神經網路的方法 (如 SRCNN)，SRGAN 能生成更豐富、更銳利的紋理細節，使得放大後的影像看起來不再那麼模糊和平滑。
        - **提升視覺感知質量**：其目標是讓生成的影像在視覺上更接近真實的高解析度影像。
    - **缺點**：
        - **訓練困難且不穩定**：GAN 的訓練本身就是一個挑戰，容易出現梯度消失、模式崩潰等問題，導致訓練結果不理想或難以復現。
        - **易產生偽影和不自然紋理**：為了“欺騙”判別器，生成器有時可能會產生一些看起來銳利但實際上並不真實存在的紋理，或者引入一些奇怪的偽影。
        - **對真實退化處理不佳**：SRGAN 通常在合成的、退化方式比較單一的數據集上訓練，當應用於真實世界中充滿複雜噪點、模糊和壓縮失真的低解析度影像時，效果往往會大打折扣。
- **ESRGAN 的超解析度能力與優缺點：**
    
    - **能力**：ESRGAN 是對 SRGAN 的一次重大升級。它通過改進網路結構（引入 RRDB 並移除 BN 層）、優化判別器（採用相對判別器）以及改進感知損失（使用激活前的特徵），顯著提升了生成影像的質量。它能生成更銳利、細節更豐富、偽影更少、整體觀感更自然的超解析度影像。
    - **優點**：
        - **顯著提升的銳利度和細節**：ESRGAN 生成的影像在清晰度和細節表現上遠超 SRGAN，能夠恢復出非常精細的紋理。
        - **有效減少偽影**：通過移除 BN 層和改進網路設計，ESRGAN 能更好地避免 SRGAN 中常見的令人不悅的偽影。
        - **更自然的視覺效果**：改進的感知損失和相對判別器使得生成的紋理和亮度更接近真實影像，整體看起來更自然。
        - **更強大的網路結構**：RRDB 塊的引入使得生成器網路更深，學習能力更強。
    - **缺點**：
        - **對真實複雜退化的處理能力仍有限**：儘管 ESRGAN 在合成數據集上表現優異，但其訓練方式仍然主要依賴於簡單的下採樣退化。因此，當面對真實世界中充滿各種未知和混合退化的影像時，其效果仍然可能不夠理想，可能會產生不自然的細節或無法有效去除所有噪點和模糊。
        - **計算資源需求較高**：更深的網路結構意味著需要更多的計算資源進行訓練和推理。
- **Real-ESRGAN 的超解析度能力與優缺點：**
    
    - **能力**：Real-ESRGAN 的核心目標是攻克真實世界影像的超解析度難題。它最大的創新在於提出了一個“高階退化模型”，用以模擬真實世界中影像可能經歷的更複雜、更多樣的退化過程（如多次模糊、下採樣、添加不同類型的噪點、JPEG 壓縮失真等）。通過使用這種更逼真的合成數據進行訓練，並結合改進的判別器網路，Real-ESRGAN 能夠非常有效地處理來自現實生活中的低質量影像。
    - **優點**：
        - **卓越的真實世界影像處理能力**：這是 Real-ESRGAN 最顯著的優勢。無論是老舊照片、低質量網路圖片、還是帶有複雜噪點和模糊的影像，Real-ESRGAN 都能在很大程度上恢復細節，提升清晰度，並生成視覺上令人滿意的結果。
        - **強大的泛化性**：由於其訓練數據模擬了多種真實世界的退化，Real-ESRGAN 對於不同來源、不同退化類型的低解析度影像都具有較好的適應性和處理效果。
        - **更逼真的退化建模**：高階退化模型比以往的方法更能模擬真實影像的複雜性。
        - **有效的偽影去除和細節恢復**：能夠在放大影像的同時，較好地去除真實影像中常見的噪點、模糊和壓縮偽影，並恢復出自然的紋理細節。
        - **僅需合成數據訓練**：這大大降低了對大量成對的真實低解析度-高解析度影像數據的需求，使得模型訓練更具可行性。
    - **缺點**：
        - **退化模型仍非完美**：儘管高階退化模型已經非常先進，但真實世界的影像退化過程極其複雜多樣，現有的模型仍然無法完全涵蓋所有可能的情況。對於某些非常特殊或極端的退化，Real-ESRGAN 的效果可能仍有提升空間，甚至可能放大某些特定偽影。
        - **可能產生新的細微偽影**：在追求更銳利細節的過程中，GAN 模型有時仍可能引入一些微小的、不易察覺的偽影，或者在某些情況下（如建築物的直線）產生輕微的扭曲。
        - **計算開銷**：作為一個先進的深度學習模型，Real-ESRGAN 仍然需要一定的計算資源，尤其是在處理高解析度輸出或批量處理時。

**總而言之：**

- 如果您需要一個基礎的、能夠生成帶有一些逼真細節的超解析度影像的模型，並且可以接受一些潛在的偽影和訓練不穩定性，**SRGAN** 是一個可以了解的起點。
- 如果您追求更高質量的視覺效果，希望生成的影像更銳利、細節更豐富、偽影更少，並且主要處理退化方式相對簡單（或已知）的影像，**ESRGAN** 是一個非常好的選擇。
- 如果您需要處理的是來源多樣、退化複雜且未知的**真實世界低解析度影像**（例如老照片修復、網路圖片放大、監控影像增強等），那麼 **Real-ESRGAN** 無疑是目前最為強大和實用的選擇之一，它在應對這些挑戰性場景時展現出了卓越的性能。




### GAN (DCGAN)的網路架構

典型的 GAN (以 DCGAN - Deep Convolutional Generative Adversarial Network 為例，因為它是圖像生成中非常經典且具代表性的 GAN 架構) 的生成器 (Generator) 和判別器 (Discriminator) 的每一層以及它們的損失函數。

**重要提示：**

- GAN 的具體架構會根據不同的任務和數據集有所變化。這裡提供的是一個通用且經典的 DCGAN 結構示例。
- 層的數量、濾波器的數量、核心大小等超參數會根據具體應用調整。

**DCGAN 生成器 (Generator) 的典型層結構**

生成器的目標是從一個隨機噪聲向量 (latent vector, 通常是 100 維) 生成一張逼真的圖像。它通常由一系列的**轉置卷積層 (Transposed Convolutional Layers)** 或稱為**分數步長卷積層 (Fractionally-strided Convolutional Layers)** 組成，用於將低維的噪聲向量逐步上採樣到目標圖像的尺寸。

![[Pasted image 20250517004124.png]]



一個典型的 DCGAN 生成器結構可能如下 (以生成 64x64x3 的彩色圖像為例)：

1. **輸入層 (Input Layer):**
    
    - 接收一個隨機噪聲向量 (例如，維度為 100 的向量 `z`)。
2. **全連接層 (Fully Connected Layer) (可選，但 DCGAN 論文中建議移除，直接用 reshape):**
    
    - 在一些早期 GAN 中，可能會先用全連接層將噪聲向量映射到一個較高維的空間。
    - DCGAN 論文建議移除全連接隱藏層，直接將噪聲向量 reshape 成一個小的 3D 特徵圖。
    - 例如，將 100 維的 `z` 向量 reshape 成 `4x4x1024` 的特徵圖。
3. **一系列轉置卷積層 (Transposed Convolutional Layers / Conv2DTranspose):**
    
    - **第一層轉置卷積 (Conv2DTranspose):**
        - 輸入: `4x4x1024` (或類似的小尺寸高通道數特徵圖)
        - 操作: 進行轉置卷積，通常步長 (stride) 為 2，填充 (padding) 使得輸出尺寸翻倍。
        - 輸出: 例如 `8x8x512`
        - 激活函數: **ReLU (Rectified Linear Unit)**
        - 歸一化: **批次歸一化 (Batch Normalization, BatchNorm)** (DCGAN 關鍵改進之一，用於穩定訓練)
    - **第二層轉置卷積 (Conv2DTranspose):**
        - 輸入: `8x8x512`
        - 操作: 轉置卷積 (stride=2, padding)
        - 輸出: 例如 `16x16x256`
        - 激活函數: **ReLU**
        - 歸一化: **BatchNorm**
    - **第三層轉置卷積 (Conv2DTranspose):**
        - 輸入: `16x16x256`
        - 操作: 轉置卷積 (stride=2, padding)
        - 輸出: 例如 `32x32x128`
        - 激活函數: **ReLU**
        - 歸一化: **BatchNorm**
    - **第四層轉置卷積 (Conv2DTranspose) / 輸出層:**
        - 輸入: `32x32x128`
        - 操作: 轉置卷積 (stride=2, padding)
        - 輸出: `64x64x3` (3 代表彩色圖像的 RGB 通道)
        - 激活函數: **Tanh** (DCGAN 論文建議在生成器的最後一層使用 Tanh 激活函數，將輸出值縮放到 [-1, 1] 範圍，這通常與輸入圖像的歸一化方式匹配)
        - 歸一化: 通常在輸出層不使用 BatchNorm。

**DCGAN 判別器 (Discriminator) 的典型層結構**

判別器的目標是接收一張圖像 (無論是真實圖像還是生成器生成的假圖像)，並輸一個概率值，表示該圖像為真實圖像的可能性。它通常由一系列的**卷積層 (Convolutional Layers)** 組成，用於提取圖像特徵並進行分類。

![[Pasted image 20250517004307.png]]


一個典型的 DCGAN 判別器結構可能如下 (以判斷 64x64x3 的圖像為例)：

1. **輸入層 (Input Layer):**
    
    - 接收一張圖像 (例如，`64x64x3` 的圖像)。
2. **一系列卷積層 (Convolutional Layers / Conv2D):**
    
    - **第一層卷積 (Conv2D):**
        - 輸入: `64x64x3`
        - 操作: 卷積，通常步長 (stride) 為 2，填充 (padding) 使得輸出尺寸減半。
        - 輸出: 例如 `32x32x64` (通道數增加)
        - 激活函數: **LeakyReLU** (DCGAN 論文建議在判別器的所有層使用 LeakyReLU 激活函數，斜率通常設為 0.2，有助於梯度的反向傳播)
        - 歸一化: **批次歸一化 (BatchNorm)** (通常在判別器的第一層不使用 BatchNorm，但後續層會使用)
    - **第二層卷積 (Conv2D):**
        - 輸入: `32x32x64`
        - 操作: 卷積 (stride=2, padding)
        - 輸出: 例如 `16x16x128`
        - 激活函數: **LeakyReLU**
        - 歸一化: **BatchNorm**
    - **第三層卷積 (Conv2D):**
        - 輸入: `16x16x128`
        - 操作: 卷積 (stride=2, padding)
        - 輸出: 例如 `8x8x256`
        - 激活函數: **LeakyReLU**
        - 歸一化: **BatchNorm**
    - **第四層卷積 (Conv2D):**
        - 輸入: `8x8x256`
        - 操作: 卷積 (stride=2, padding)
        - 輸出: 例如 `4x4x512`
        - 激活函數: **LeakyReLU**
        - 歸一化: **BatchNorm**
3. **扁平化層 (Flatten Layer) (可選，如果最後一層卷積輸出不是單個值):**
    
    - 將最後一層卷積輸出的多維特徵圖展平成一維向量。
    - DCGAN 論文中，最後的卷積層通常設計成輸出一個 `1x1xN` 的特徵圖，可以直接用於全連接層或 Sigmoid。
4. **輸出層 (Output Layer / Fully Connected Layer):**
    
    - 輸入: 展平後的一維向量 (或 `1x1xN` 特徵圖，然後直接進行卷積得到單個輸出)
    - 操作: 通常是一個單個神經元的全連接層 (或者一個卷積核大小與輸入特徵圖大小相同、步長為1、輸出通道為1的卷積層)。
    - 輸出: 一個**標量值 (scalar value)**。
    - 激活函數: **Sigmoid** (將輸出值壓縮到 [0, 1] 之間，表示輸入圖像為真實圖像的概率。0 代表假，1 代表真)。

**GAN 的損失函數 (Loss Functions)**

GAN 的訓練是一個極小極大博弈 (minimax game)，生成器(Generator)和判別器(Discriminator)有各自的損失函數，並且在訓練過程中交替優化。

- D(x)：判別器對於真實數據 x 預測其為真實的概率。
- G(z)：生成器從噪聲 z 生成的假數據。
- D(G(z))：判別器對於生成器生成的假數據 G(z) 預測其為真實的概率。
- pdata​(x)：真實數據的分佈。
- pz​(z)：噪聲的分佈。

1. **判別器損失函數 (LD​)**: 判別器的目標是**最大化**正確分類真實樣本和生成樣本的能力。換句話說，它希望 D(x) 趨近於 1 (真實樣本被判斷為真)，並且 D(G(z)) 趨近於 0 (生成樣本被判斷為假)。 其損失函數通常定義為二元交叉熵損失 (BCE: Binary Cross-Entropy Loss): LD​=−Ex∼pdata​(x)​[logD(x)]−Ez∼pz​(z)​[log(1−D(G(z)))] 在實際訓練中，我們通常最小化這個損失的負值 (或者說最大化這個目標函數)。
    
    - **第一項** Ex∼pdata​(x)​[logD(x)]：當輸入真實數據 x 時，判別器希望 D(x) 接近 1，所以 logD(x) 接近 0。
    - **第二項** Ez∼pz​(z)​[log(1−D(G(z)))]：當輸入生成數據 G(z) 時，判別器希望 D(G(z)) 接近 0，所以 1−D(G(z)) 接近 1，因此 log(1−D(G(z))) 接近 0。
2. **生成器損失函數 (LG​)**: 生成器的目標是**最小化**其生成的樣本被判別器識別為假的概率。換句話說，它希望 D(G(z)) 趨近於 1 (生成的樣本被判斷為真)。 原始 GAN 論文中，生成器的損失函數定義為： LG​=Ez∼pz​(z)​[log(1−D(G(z)))] 生成器試圖最小化這個值。然而，在訓練初期，當判別器很容易區分真假樣本時，D(G(z)) 可能很小，導致 log(1−D(G(z))) 的梯度也很小，造成生成器學習緩慢 (梯度飽和問題)。
    
    因此，在實踐中，通常使用一個修改後的生成器損失函數，即**最大化** D(G(z)) 的對數概率： LG​=−Ez∼pz​(z)​[logD(G(z))] 這個形式在訓練初期能提供更強的梯度信號，有助於生成器的學習。這個損失函數也被稱為 "non-saturating heuristic" 或 "inverted labels" 技巧。
    

**總結一下損失函數的目標：**

- **判別器 (D)**： 試圖**最大化** V(D,G)=Ex∼pdata​(x)​[logD(x)]+Ez∼pz​(z)​[log(1−D(G(z)))]
- **生成器 (G)**： 試圖**最小化** V(D,G) (原始形式)，或者在實踐中，試圖**最小化** LG​=−Ez∼pz​(z)​[logD(G(z))] (non-saturating 形式)。

這就是一個典型 DCGAN 的生成器、判別器的層結構以及它們各自的損失函數。希望這個解釋對您有所幫助！

ref:
史上最全GAN综述2020版：算法、理论及应用
https://zhuanlan.zhihu.com/p/110581201



### GAN具體舉例

具體的例子，一步步詳細說明 GAN 的輸入、生成器（Generator）和判別器（Discriminator）的輸入輸出，以及損失函數是如何計算的。

**假設我們的目標是生成手寫數字的圖像（類似 MNIST 數據集的圖像）。**

- **圖像規格：** 假設我們生成的圖像大小是 28x28 像素，並且是灰度圖像（只有一個顏色通道）。

**A. GAN 的整體輸入**

一個 GAN 系統在訓練時，主要有兩方面的輸入：

1. **隨機噪聲 (Random Noise) - z：**
    
    - **作用：** 這是提供給**生成器**的原始“素材”或“靈感”。生成器會學習如何將這些隨機的數字模式轉換成有意義的圖像。
    - **具體例子：** 通常是一個固定長度的一維向量，向量中的每個值都是從某個簡單的概率分佈（如均勻分佈在 [-1, 1] 之間，或標準正態分佈）中隨機抽樣得到的。
    - **例如：** 一個 100 維的向量，如 `[0.12, -0.5, 0.88, ..., -0.23]`。每一批 (batch) 訓練都會生成一批新的隨機噪聲向量。
2. **真實數據 (Real Data) - xreal​：**
    
    - **作用：** 這是提供給**判別器**用來學習“什麼是真實的”的樣本。判別器需要看到大量的真實圖像，才能學會分辨真偽。
    - **具體例子：** 在我們的例子中，就是 MNIST 數據集中的真實手寫數字圖像。每一張圖像都是一個 28x28x1 的張量（或矩陣）。像素值通常會被歸一化到某個範圍，例如 [-1, 1] 或 [0, 1]。
    - **例如：** 一張真實的數字“7”的圖像，表示為一個 28x28 的像素值矩陣。

**B. 生成器 (Generator, G) 的輸入和輸出**

生成器的角色像一個“畫家”或“偽造者”，它試圖創作出逼真的圖像。

1. **生成器的輸入 (Input to G):**
    
    - **內容：** 上述的**隨機噪聲向量 z**。
    - **維度示例：** 如果我們設定噪聲維度是 100，那麼輸入就是一個形狀為 `(batch_size, 100)` 的張量。`batch_size` 指的是一次處理多少個樣本。
2. **生成器的輸出 (Output from G) - G(z) 或 xfake​：**
    
    - **內容：** 生成器根據輸入的噪聲向量 z，“畫”出來的**偽造圖像**。
    - **維度示例：** 由於我們的目標是生成 28x28 的灰度圖像，所以輸出就是一個形狀為 `(batch_size, 28, 28, 1)` 的張量。
        - `batch_size`：同上。
        - `28, 28`：圖像的高度和寬度。
        - `1`：顏色通道數（灰度圖像為 1）。
    - **像素值範圍：** 生成器最後一層的激活函數（通常是 Tanh）會將輸出圖像的像素值約束在一個特定範圍，例如 [-1, 1]，以匹配真實圖像的歸一化範圍。
    - **例如：** 輸入一個 100 維的噪聲向量 `z_i`，生成器輸出一個 28x28x1 的圖像 G(zi​)，這個圖像看起來可能像一個手寫數字，也可能不像（尤其在訓練初期）。

**C. 判別器 (Discriminator, D) 的輸入和輸出**

判別器的角色像一個“藝術評論家”或“偵探”，它試圖分辨輸入的圖像到底是真實的還是偽造的。

1. **判別器的輸入 (Input to D):**
    
    - **內容：** 判別器的輸入有兩種來源：
        - **真實圖像 xreal​：** 來自真實數據集（例如 MNIST）。
        - **生成圖像 xfake​ (即 G(z))：** 由生成器產生的偽造圖像。
    - **維度示例：** 無論是真實圖像還是生成圖像，它們的維度都是一樣的，即 `(batch_size, 28, 28, 1)`。
2. **判別器的輸出 (Output from D) - D(x)：**
    
    - **內容：** 判別器對輸入圖像 x 給出的一個**概率值**，表示該圖像為“真實圖像”的可能性有多大。
    - **維度示例：** 一個形狀為 `(batch_size, 1)` 的張量，其中每個值都在 [0, 1] 之間。
        - 值越接近 1，表示判別器認為該圖像是真實圖像的概率越高。
        - 值越接近 0，表示判別器認為該圖像是偽造圖像的概率越高。
    - **激活函數：** 判別器的最後一層通常使用 Sigmoid 激活函數，將輸出壓縮到 [0, 1] 區間，使其可以被解釋為概率。
    - **例如：**
        - 如果輸入一張真實圖像 xreal_i​，判別器理想的輸出 D(xreal_i​) 應該接近 1。
        - 如果輸入一張生成圖像 G(zj​)，判別器理想的輸出 D(G(zj​)) 應該接近 0。

**D. 損失函數 (Loss Functions) 如何計算的一步步解說**

GAN 的訓練是一個“二人零和博弈”的過程，我們需要分別定義判別器和生成器的損失函數，然後交替訓練它們。這裡我們使用原始 GAN 論文中提出的 Minimax Loss，並解釋實踐中常用的變體。

**前提：**

- x 代表真實圖像。
- z 代表輸入生成器的隨機噪聲。
- G(z) 代表生成器生成的假圖像。
- D(x) 代表判別器認為圖像 x 是真實圖像的概率。
- Ex∼pdata​(x)​ 表示對所有真實數據取期望（在實踐中，通過一個批次的平均來近似）。
- Ez∼pz​(z)​ 表示對所有可能的噪聲輸入取期望（在實踐中，通過一個批次的平均來近似）。
- log 通常指自然對數。

**1. 判別器 (D) 的訓練階段**

判別器的目標是：

- 對於真實圖像 xreal​，使其輸出 D(xreal​) 盡可能接近 1（即 logD(xreal​) 盡可能接近 0）。
- 對於生成圖像 G(z)，使其輸出 D(G(z)) 盡可能接近 0（即 log(1−D(G(z))) 盡可能接近 0）。

**判別器的損失函數 LD​：** LD​=−Ex∼pdata​(x)​[logD(x)]−Ez∼pz​(z)​[log(1−D(G(z)))] 判別器通過**最小化**這個 LD​（或者說最大化 V(D,G)=Ex∼pdata​(x)​[logD(x)]+Ez∼pz​(z)​[log(1−D(G(z)))]）來更新其參數。

**一步步計算（假設處理一個批次 Batch 的數據）：**

- **a. 準備數據：**
    
    - 從真實數據集（MNIST）中抽取一個批次的真實圖像，例如 `batch_size` 張，記為 {xreal1​​,xreal2​​,...,xrealbatch_size​​}。
    - 生成 `batch_size` 個隨機噪聲向量 {z1​,z2​,...,zbatch_size​}。
    - 將這些噪聲向量輸入生成器 G（此時 G 的參數是固定的，不更新），得到一個批次的生成圖像 $\{G(z_1), G(z_2), ..., G(z_{batch\_size}}\}$。
- **b. 判別器處理真實圖像：**
    
    - 將真實圖像批次 {xreali​​} 輸入判別器 D，得到判別器對每張真實圖像的預測概率 {D(xreal1​​),D(xreal2​​),...,D(xrealbatch_size​​)}。
    - 計算這部分損失（真實圖像被判斷為真實的對數似然）： Lossreal​=−batch_size1​i=1∑batch_size​log(D(xreali​​)) （目標是讓 D(xreali​​) 趨近於 1，這樣 log(D(xreali​​)) 趨近於 0，−log(D(xreali​​)) 也趨近於 0）
- **c. 判別器處理生成圖像：**
    
    - 將生成圖像批次 {G(zi​)} 輸入判別器 D，得到判別器對每張生成圖像的預測概率 $\{D(G(z_1)), D(G(z_2)), ..., D(G(z_{batch\_size}})\}$。
    - 計算這部分損失（生成圖像被判斷為偽造的對數似然，即 1−D(G(zi​)) 表示被判斷為假的概率）： Lossfake​=−batch_size1​i=1∑batch_size​log(1−D(G(zi​))) （目標是讓 D(G(zi​)) 趨近於 0，這樣 1−D(G(zi​)) 趨近於 1，log(1−D(G(zi​))) 趨近於 0，−log(1−D(G(zi​))) 也趨近於 0）
- **d. 計算判別器的總損失：** LD​=Lossreal​+Lossfake​ （有些實現可能會將兩者分開計算，或者取平均，但核心思想是結合這兩部分損失。）
    
- **e. 更新判別器參數：**
    
    - 根據 LD​ 計算梯度，並通過反向傳播算法更新判別器 D 的網路權重。此步驟**只更新 D 的參數，G 的參數保持不變**。

**2. 生成器 (G) 的訓練階段**

生成器的目標是“欺騙”判別器，即讓判別器對其生成的圖像 G(z) 給出高分，使其輸出 D(G(z)) 盡可能接近 1。

**生成器的損失函數 LG​ (實踐中常用的形式)：** LG​=−Ez∼pz​(z)​[logD(G(z))] 生成器通過**最小化**這個 LG​ 來更新其參數。 (原始 GAN 論文中的生成器損失是最小化 Ez∼pz​(z)​[log(1−D(G(z)))]，但這個形式在訓練初期梯度較弱，所以上述 −logD(G(z)) 的形式更常用，被稱為 "non-saturating heuristic"。)

**一步步計算（假設處理一個批次 Batch 的數據）：**

- **a. 準備數據：**
    
    - 生成新的一批 `batch_size` 個隨機噪聲向量 {z1′​,z2′​,...,zbatch_size′​}。
    - 將這些新的噪聲向量輸入當前的生成器 G，得到一個批次的生成圖像 $\{G(z'_1), G(z'_2), ..., G(z'_{batch\_size}}\}$。
- **b. 判別器評估生成圖像（注意：此時判別器 D 的參數是固定的，不更新）：**
    
    - 將生成圖像批次 {G(zi′​)} 輸入判別器 D（判別器的參數是上一步訓練 D 後更新的參數，或者是訓練開始時的初始參數，總之在此步驟中 D 的參數不變），得到判別器對這些生成圖像的預測概率 $\{D(G(z'_1)), D(G(z'_2)), ..., D(G(z'_{batch\_size}})\}$。
- **c. 計算生成器的損失：** LG​=−batch_size1​i=1∑batch_size​log(D(G(zi′​))) （目標是讓 D(G(zi′​)) 趨近於 1，這樣 log(D(G(zi′​))) 趨近於 0，−log(D(G(zi′​))) 也趨近於 0）
    
- **d. 更新生成器參數：**
    
    - 根據 LG​ 計算梯度。注意，這個梯度需要通過判別器 D 反向傳播到生成器 G。
    - 通過反向傳播算法更新生成器 G 的網路權重。此步驟**只更新 G 的參數，D 的參數保持不變**。

**3. 交替訓練**

在實際訓練中，上述判別器的訓練步驟和生成器的訓練步驟會交替進行。例如：

- 訓練判別器 k 步 (例如 k=1 或 k=2)。
- 然後訓練生成器 1 步。
- 重複這個過程很多輪 (epochs)。

通過這種方式，生成器和判別器在相互的“博弈”中共同進步：生成器努力生成更逼真的圖像來欺騙判別器，而判別器則努力提高其分辨真偽的能力。最終理想的狀態是，生成器能夠生成與真實數據幾乎無法區分的圖像，而判別器對於任何輸入都只能給出接近 0.5 的概率（即無法分辨）。


### QA list

| Q                                                                                                                                       | Ans |
| --------------------------------------------------------------------------------------------------------------------------------------- | --- |
| [GAN](https://zhida.zhihu.com/search?content_id=244465215&content_type=Article&match_order=1&q=GAN&zhida_source=entity) 和 diffusion 的优势 |     |
| 为什么 GAN 不稳定                                                                                                                             |     |
| 图像生成的评估指标有哪些？                                                                                                                           |     |
|                                                                                                                                         |     |
|                                                                                                                                         |     |
|                                                                                                                                         |     |
