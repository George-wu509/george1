

2021.06.03 **Vision Transformer(ViT) (Google) 将Transformer架构应用到CV**
[Vision Transformer（ViT）github](https://github.com/google-research/vision_transformer)
[一文窥尽Vision Transformer (ViT)](https://zhuanlan.zhihu.com/p/686069271)
[逐步解析Vision Transformer各细节，附带源码与微调讲解](https://zhuanlan.zhihu.com/p/690406548)


2020.05.18 **DeepSpeed (Windows) 大模型分布式训练**
[Microsoft DeepSpeed](https://www.microsoft.com/en-us/research/project/deepspeed/)
[从啥也不会到DeepSpeed一篇大模型分布式训练的学习过程总结](https://zhuanlan.zhihu.com/p/688873027)
[大模型微调实践必看一文看懂Deepspeed：用ZeRO训练大模型原理解析及参数含义解释](https://zhuanlan.zhihu.com/p/674745061)


2021.06.23 **EfficientNetV2 (Google) 新的模型缩放方法+AutoML**
[EfficientNetV2：谷歌最小的模型最高的准确率最快的训练速度 | ICML 2021](https://zhuanlan.zhihu.com/p/690051728)
[Resnet VS. EfficientNet：主干网络发展速览](https://zhuanlan.zhihu.com/p/398657118)


2021.08.28 **CLIP (OpenAI) 用文本作为监督信号来训练可迁移的大视觉模型**
[CLIP: Connecting text and images](https://openai.com/index/clip/)
[神器CLIP：连接文本和图像，打造可迁移的视觉模型](https://zhuanlan.zhihu.com/p/493489688)


2022.08.28 **Stable Diffusion (Stable AI) 文本生成图像的算法模型**
[Stable Diffusion Online](https://stablediffusionweb.com/)
[Stable Diffusion Github](https://github.com/Stability-AI/stablediffusion)
[超全面的Stable Diffusion学习指南：初识篇](https://www.uisdc.com/stable-diffusion-guide)


2022.11.30 **ChatGPT (OpenAI)**
website: [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)
[一文读懂ChatGPT模型原理](https://zhuanlan.zhihu.com/p/589621442)
[ChatGPT 算法原理](https://zhuanlan.zhihu.com/p/605835778)

2023.0114 Stable diffusion + ControlNet 3D   影像生成
[Stable diffusion github ](https://github.com/lllyasviel/ControlNet)   [ControlNet Github ](https://github.com/lllyasviel/ControlNet)
[深入浅出完整解析Stable Diffusion（SD）核心基础知识](https://zhuanlan.zhihu.com/p/632809634)
[ICCV2023最佳论文——ControlNet](https://zhuanlan.zhihu.com/p/670498980)

2023.0313 **Visual-ChatGPT**
[Visual ChatGPT github](https://github.com/microsoft/visual-chatgpt)
[Visual ChatGPT（一）: 除了语言问答，还能看图问答、AI画图、AI改图的超实用系统](https://zhuanlan.zhihu.com/p/612627818)


2023.0315 **GPT-4 (OpenAI)**
[GPT-4 openAI website](https://openai.com/research/gpt-4)


2023.0407 **Segment Anything (Meta)**
[https://github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)


2023.0419 **DINOv2 (Meta)**
[https://zhuanlan.zhihu.com/p/622813627](https://zhuanlan.zhihu.com/p/622813627)
[https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)


2023.0510 **ImageBind (Meta)**
[https://imagebind.metademolab.com/](https://imagebind.metademolab.com/)


2023.0510 **CoTracker (Meta)**
[https://github.com/facebookresearch/co-tracker](https://github.com/facebookresearch/co-tracker)
[https://zhuanlan.zhihu.com/p/646156309](https://zhuanlan.zhihu.com/p/646156309)

2023.0808 **3D Gaussian splatting** (3DGS)  3D重建
[Paper ](https://arxiv.org/abs/2308.04079)   [Github ](https://github.com/graphdeco-inria/gaussian-splatting)
[3D 高斯Splatting：综述、技术、挑战和机遇](https://www.zhihu.com/question/1457540426/answer/51029769945)

2023.0910 **Llama2** (Meta)
[https://ai.meta.com/llama/](https://ai.meta.com/llama/)


2023.0925 ChatGPT can now see, hear and speak
[https://openai.com/blog/chatgpt-can-now-see-hear-and-speak](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak)


2023.0920 **DALLE3** - 文本轉換成圖片
similar: stable diffusion, [Midjourney](https://www.midjourney.com/)
[OpenAI dall-e-3 website](https://openai.com/dall-e-3)
[如何评价OpenAI最新发布的DALLE3？](https://www.zhihu.com/question/623068612/answer/3232766661)


2023.1218 **Mamba** - 新Backbone
[Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752)
[Mamba技术背景详解：从RNN到Mamba一文搞定！](https://zhuanlan.zhihu.com/p/689215356)
[一文读懂Mamba：具有选择状态空间的线性时间序列建模](https://zhuanlan.zhihu.com/p/680846351)
[Mamba原理最通俗介绍火了，一文看懂“Transformer挑战者”两大主要思想！](https://zhuanlan.zhihu.com/p/683978639)


2024.0215 **Sora** - 文本轉換成影片
previous: gemmo、pika和runway
[https://openai.com/sora](https://openai.com/sora)
[解密OpenAI超级视频模型Sora技术报告](https://zhuanlan.zhihu.com/p/682461345)
[OpenAI｜深入剖析Sora原理：细节解读与技术洞见](https://zhuanlan.zhihu.com/p/683169392)


2024.0216 **Gemini 1.5**
[Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)
[谷歌Gemini 1.5突然发布！100万token史上最强，仅靠提示词就能学会新语言](https://zhuanlan.zhihu.com/p/682394593)


2024.0216 **KAN** - Kolmogorov-Arnold Networks - 新Backbone
[KAN: Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756)
[关于 KAN(Kolmogorov-Arnold Networks) 的文章分析——一种全新的神经网络架构](https://zhuanlan.zhihu.com/p/697601102)


2024.0627 **Gemma 2**
[Gemma 2](https://blog.google/technology/developers/google-gemma-2/) is now available to researchers and developers

2024.0715 **Florence-2** 微软全新开源视觉语言模型
[post ](https://www.assemblyai.com/blog/florence-2-how-it-works-how-to-use/)
[微软全新开源视觉语言模型！能够执行超过10种不同的视觉任务，检测、分割、识别一切图片](https://zhuanlan.zhihu.com/p/8060780197)
[Florence-2 Demo](https://huggingface.co/spaces/gokaygokay/Florence-2)

2024.0802 **SAM 2** - Segment Anything特別是Video
[Meta Segment Anything Model for videos and images](https://ai.meta.com/SAM2/)
[论文阅读： SAM 2: Segment Anything in Images and Videos](https://zhuanlan.zhihu.com/p/711956148)


2024.0912 **OpenAI o1** - 通过复杂的任务进行推理
[Introducing OpenAI o1](https://openai.com/o1/)
[OpenAI o1 传说中的strawberry终于来了](https://quail.ink/op7418/p/openai-o1-strawberry-finally-arrived)


2024.1020 **CoTracker3 (Meta)**  Tracker
[CoTracker3 Gitub](https://cotracker3.github.io/)


2024.1024 Claude **computer use**
[Anthrop blog-computer use, Claude3.5](https://www.anthropic.com/news/3-5-models-and-computer-use)

2024.1120 **AlphaQubit**  Google DeepMind量子计算纠错
[Nature paper](https://www.nature.com/articles/s41586-024-08148-8)
[预定下一个诺奖级AI？谷歌量子纠错AlphaQubit登Nature，10万次模拟实验创新里程碑](https://zhuanlan.zhihu.com/p/8212057908)

2024.1205 DeepMind **Genie2**  Foundation world model
[DeepMind post](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/)
[DeepMind最强「基础世界模型」诞生](https://mp.weixin.qq.com/s/lUf5_0vnka7OM4jfeAZkeg)

2024.1204 **MIDI**: Single Image to 3D Scene Generation  李飛飛單圖生成3D場景
[Paper github](https://huanngzh.github.io/MIDI-Page/)
[李飞飞空间智能首秀：AI靠单图生成3D世界，可探索，遵循基本物理几何规则](https://zhuanlan.zhihu.com/p/10360911581)

2024.1211 **Gemini 2.0** (Google, Deepmind) 多模态基础模型，可以概括和理解不同类型的信息，包括文本、代码、音频、图像和视频
[Gemini 2.0 blog](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#ceo-message)   
[谷歌发布最新大模型 Gemini，包含多模态、三大版本，还有哪些特点？能力是否超越 GPT-4了？](https://www.zhihu.com/question/633684692/answer/53316813573)

2024.1209 **Willow**量子芯片 (Google Quantum AI)
[Nature paper](https://www.nature.com/articles/s41586-024-08449-y)
[谷歌Willow量子芯片逆天出世！5分钟颠覆10亿亿亿计算极限，马斯克奥特曼惊叹](https://zhuanlan.zhihu.com/p/11803295722)

2024.1209 **Genesis**生成式物理引擎
[Genesis github](https://github.com/Genesis-Embodied-AI/Genesis)
[刚刚，AI进化到一句话生成物理模拟，学术圈半壁江山联手耗时24个月研究成果](https://zhuanlan.zhihu.com/p/13499656158)

2025.0128  DeepSeek-R1
[DeepSeek-R1 github](https://github.com/deepseek-ai/DeepSeek-R1)
DeepSeek-R1 模型发布，性能对标 OpenAI o1 正式版，大家怎么看？ - 段小草的回答 - 知乎
https://www.zhihu.com/question/10152040622/answer/84383440957

2025.03.26  Introducing 4o Image Generation
https://openai.com/index/introducing-4o-image-generation/
如何看待 OpenAI 新推出的 4O Image Generation？ - 知乎
https://www.zhihu.com/question/1888134409091266476