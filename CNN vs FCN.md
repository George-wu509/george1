

### FCN 和 CNN 的介紹與比較

#### 什麼是 FCN？

FCN（Fully Convolutional Network，全卷積網絡）是一種專為圖像分割（Image Segmentation）任務設計的深度學習模型。與傳統的卷積神經網絡（CNN）不同，FCN 完全由卷積層組成，沒有全連接層（Fully Connected Layers），並且能夠處理任意大小的輸入圖像，輸出與輸入圖像空間尺寸相關的預測（如像素級分類）。

FCN 的核心思想是：

- 通過卷積和池化操作提取特徵。
- 使用上採樣（Upsampling，例如轉置卷積）將特徵圖恢復到原始輸入圖像的大小。
- 最終每個像素都會有一個類別預測，實現端到端的像素級分割。

#### FCN 與 CNN 的差別

|特性|CNN（卷積神經網絡）|FCN（全卷積網絡）|
|---|---|---|
|**輸出**|通常是單一向量（如類別概率）|空間映射（如像素級分類）|
|**結構**|包含卷積層 + 全連接層|僅包含卷積層（無全連接層）|
|**輸入大小**|通常固定（如 224×224）|可變（因無全連接層限制）|
|**應用**|圖像分類、目標檢測|圖像分割|
|**上採樣**|不需要|需要（如轉置卷積或插值）|

簡單來說，CNN 適合全局分類任務（如這張圖是貓還是狗），而 FCN 適合空間細粒度的任務（如分割出圖像中的貓的每個像素）。

---

### PyTorch 代碼示例

#### 1. CNN 示例（簡單圖像分類）

以下是一個簡單的 CNN，用於圖像分類任務：

```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # 輸入 3 通道 (RGB)
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 56 * 56, 128),  # 假設輸入圖像大小為 224×224
            nn.ReLU(),
            nn.Linear(128, num_classes),   # 輸出類別數
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# 初始化模型
cnn_model = SimpleCNN(num_classes=10)
print(cnn_model)

# 測試
input_tensor = torch.randn(1, 3, 224, 224)  # batch_size=1, 3通道, 224×224
output = cnn_model(input_tensor)
print("CNN Output Shape:", output.shape)  # torch.Size([1, 10])，10個類別的概率
```

#### 2. FCN 示例（簡單圖像分割）

以下是一個簡單的 FCN，用於圖像分割任務：

```python
import torch
import torch.nn as nn

class SimpleFCN(nn.Module):
    def __init__(self, num_classes=2):  # 假設分割成 2 類（如前景和背景）
        super(SimpleFCN, self).__init__()
        # 下採樣（特徵提取）
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣 2x
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 下採樣 2x
        )
        # 上採樣（恢復分辨率）
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # 上採樣 2x
            nn.ReLU(),
            nn.ConvTranspose2d(16, num_classes, kernel_size=2, stride=2),  # 上採樣 2x
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# 初始化模型
fcn_model = SimpleFCN(num_classes=2)
print(fcn_model)

# 測試
input_tensor = torch.randn(1, 3, 224, 224)  # batch_size=1, 3通道, 224×224
output = fcn_model(input_tensor)
print("FCN Output Shape:", output.shape)  # torch.Size([1, 2, 224, 224])，每個像素 2 類概率
```

---

### 代碼比較

1. **結構**：
    - **CNN**：有全連接層（nn.Linear），將特徵壓縮成單一向量輸出。
    - **FCN**：無全連接層，使用轉置卷積（nn.ConvTranspose2d）恢復空間維度。
2. **輸出**：
    - **CNN**：輸出為 [batch_size, num_classes]，表示圖像級別的類別概率。
    - **FCN**：輸出為 [batch_size, num_classes, height, width]，表示像素級別的類別概率。
3. **用途**：
    - **CNN**：用於分類，適合回答「這張圖是什麼？」。
    - **FCN**：用於分割，適合回答「圖中哪些像素屬於某類？」。
4. **輸入靈活性**：
    - **CNN**：由於全連接層的存在，輸入大小通常固定（這裡假設 224×224）。
    - **FCN**：全卷積結構允許任意大小的輸入，輸出尺寸與輸入成比例。

---

### 總結

- **CNN** 是傳統分類模型，通過卷積提取特徵後用全連接層輸出全局預測。
- **FCN** 是分割模型，通過全卷積結構保留空間信息並生成像素級預測。
- 在 PyTorch 實現中，FCN 的關鍵是去掉全連接層並加入上採樣層，這是它與 CNN 的根本區別。




以下以一個具體的例子，詳細展示在你的條件下（輸入為 4×4 圖像，卷積核大小為 3×3，通道數為 3）的 SimpleCNN 從輸入到輸出的每一步計算過程。我會基於你之前提供的 SimpleCNN 結構進行說明，並假設參數保持不變（即輸出通道數、池化層等）。我們逐步計算並解釋每個步驟。

---

### SimpleCNN 結構回顧

假設 SimpleCNN 的結構如下（根據你的要求調整輸入大小）：

```python
class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=0),  # 3 輸入通道，16 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
            nn.Conv2d(16, 32, kernel_size=3, padding=0),  # 16 輸入通道，32 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 1 * 1, 128),  # 調整全連接層輸入大小，後面會計算
            nn.ReLU(),
            nn.Linear(128, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
```

輸入條件：

- **輸入圖像**：4×4，3 通道（RGB），即形狀為 [1, 3, 4, 4]（batch_size=1）。
- **卷積核大小**：3×3。
- **無 padding**（padding=0）。

---

### 步驟-by-步驟計算與解釋

#### 步驟 1：第一次卷積 (Conv2d: 3 -> 16, 3×3)

- **輸入**：[1, 3, 4, 4]（batch_size=1, 通道=3, 高=4, 寬=4）。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：3。
    - 輸出通道：16。
    - Stride：1（預設）。
    - Padding：0。
- **輸出尺寸計算**：
    - 卷積輸出尺寸公式：output_size = (input_size - kernel_size + 2 * padding) / stride + 1
    - 高：(4 - 3 + 0) / 1 + 1 = 2
    - 寬：(4 - 3 + 0) / 1 + 1 = 2
    - 輸出形狀：[1, 16, 2, 2]（16 個特徵圖，每個 2×2）。
- **計算過程**：
    - 每個 3×3 卷積核在輸入圖像上滑動，對於每個位置，計算 3 個輸入通道與卷積核的點積，然後加偏置。
    - 假設輸入數據為：
```
    通道 1: [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]
	通道 2: [[...]]（類似隨機值）
	通道 3: [[...]]（類似隨機值）
```
        
    - 假設第一個卷積核權重（簡化為通道 1 的權重）：[[1, 0, -1], [2, 0, -2], [1, 0, -1]]，偏置為 0。
    - 第一個位置（左上角 3×3 區域）：
        - 輸入：[[1, 2, 3], [5, 6, 7], [9, 10, 11]]
        - 點積：1*1 + 2*0 + 3*-1 + 5*2 + 6*0 + 7*-2 + 9*1 + 10*0 + 11*-1 = 1 - 3 + 10 - 14 + 9 - 11 = -8
        - 同樣計算其他通道並加總（假設結果為 -10）。
    - 滑動到其他位置，重複計算，生成 2×2 的特徵圖。
- **輸出示例**（假設值）：

```
特徵圖 1: [[-10, 5], [3, -2]]
特徵圖 2: [[...]]（共 16 個特徵圖）
```
    

#### 步驟 2：ReLU 激活

- **輸入**：[1, 16, 2, 2]。
- **操作**：將所有負值設為 0。
- **輸出形狀**：不變，仍為 [1, 16, 2, 2]。
- **計算過程**：
    - 對每個元素應用 max(0, x)。
    - 示例：
```
特徵圖 1: [[-10, 5], [3, -2]]
特徵圖 2: [[...]]（共 16 個特徵圖）
```
        

#### 步驟 3：第一次池化 (MaxPool2d: 2×2)

- **輸入**：[1, 16, 2, 2]。
- **池化參數**：
    - 池化窗口：2×2。
    - Stride：2。
- **輸出尺寸計算**：
    - 高：(2 - 2) / 2 + 1 = 1
    - 寬：(2 - 2) / 2 + 1 = 1
    - 輸出形狀：[1, 16, 1, 1]（16 個 1×1 特徵圖）。
- **計算過程**：
    - 在每個 2×2 區域取最大值。
    - 示例：
```
輸入: [[0, 5], [3, 0]]
輸出: [5]（最大值）
```
        
- **輸出示例**：
```
    特徵圖 1: [[5]]
	特徵圖 2: [[...]]（共 16 個）
```

#### 步驟 4：第二次卷積 (Conv2d: 16 -> 32, 3×3)

- **輸入**：[1, 16, 1, 1]。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：16。
    - 輸出通道：32。
    - Padding：0。
- **輸出尺寸計算**：
    - 高：(1 - 3 + 0) / 1 + 1 = -1 + 1 = 0（無效，無法計算）。
    - **問題**：輸入尺寸 1×1 小於卷積核 3×3，無法進行卷積。
- **解釋**：
    - 在這個例子中，輸入尺寸過小，第二次卷積無法執行。現實中，輸入圖像通常更大（如 224×224），經過池化後仍能支持後續卷積。
    - 為繼續展示，我們假設輸入更大（例如跳過此步，或調整結構）。

#### 修改假設

假設我們調整第一次池化後的輸入為 [1, 16, 4, 4]（模擬更大的輸入），繼續計算：

- **第二次卷積**：
    - 輸入：[1, 16, 4, 4]。
    - 輸出：[1, 32, 2, 2]（計算同第一次卷積）。
- **第二次 ReLU**：[1, 32, 2, 2]。
- **第二次池化**：[1, 32, 1, 1]。

#### 步驟 5：展平 (Flatten)

- **輸入**：[1, 32, 1, 1]。
- **操作**：將張量展平為一維向量。
- **輸出形狀**：[1, 32]（32 = 32×1×1）。
- **示例**：

```
輸入: [[[5]], [[3]], ...]（32 個 1×1）
輸出: [5, 3, ...]（長度 32 的向量）
```
    

#### 步驟 6：第一次全連接層 (Linear: 32 -> 128)

- **輸入**：[1, 32]。
- **參數**：權重矩陣 [32, 128]，偏置 [128]。
- **輸出形狀**：[1, 128]。
- **計算過程**：
    - output = input @ weight + bias。
    - 示例（假設權重和偏置為隨機值）：
```
輸入: [5, 3, ...]
輸出: [x1, x2, ..., x128]
```
        

#### 步驟 7：ReLU 激活

- **輸入**：[1, 128]。
- **操作**：max(0, x)。
- **輸出形狀**：[1, 128]。

#### 步驟 8：第二次全連接層 (Linear: 128 -> 10)

- **輸入**：[1, 128]。
- **參數**：權重 [128, 10]，偏置 [10]。
- **輸出形狀**：[1, 10]（10 個類別的得分）。
- **計算過程**：
    - 同上，生成最終分類得分。

---

### 總結與數據流

|步驟|形狀|解釋|
|---|---|---|
|輸入|[1, 3, 4, 4]|4×4 RGB 圖像|
|Conv1|[1, 16, 2, 2]|3×3 卷積提取 16 個特徵圖|
|ReLU1|[1, 16, 2, 2]|非線性激活|
|MaxPool1|[1, 16, 1, 1]|2×2 池化縮減尺寸|
|Conv2（假設更大輸入）|[1, 32, 2, 2]|第二次卷積（需更大輸入）|
|ReLU2|[1, 32, 2, 2]|非線性激活|
|MaxPool2|[1, 32, 1, 1]|再次池化|
|Flatten|[1, 32]|展平為向量|
|Linear1|[1, 128]|全連接層|
|ReLU3|[1, 128]|非線性激活|
|Linear2|[1, 10]|最終分類輸出|

### 注意

- **輸入尺寸限制**：4×4 圖像過小，第二次 3×3 卷積無法執行。實際應用中，輸入應更大（如 32×32 或 224×224）。
- **假設數據**：這裡使用假設值展示計算，實際權重和偏置由訓練決定。





以下以一個具體的例子，詳細展示在你的條件下（輸入為 4×4 圖像，卷積核大小為 3×3，通道數為 3）的 SimpleFCN 從輸入到輸出的每一步計算過程。我會基於你之前提供的 SimpleFCN 結構進行說明，並針對 4×4 的輸入進行適當調整，逐步計算並解釋每個步驟。

---

### SimpleFCN 結構回顧

假設 SimpleFCN 的結構如下（根據你的要求調整）：

```python
import torch
import torch.nn as nn

class SimpleFCN(nn.Module):
    def __init__(self, num_classes=2):  # 分割成 2 類（如前景和背景）
        super(SimpleFCN, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=0),  # 3 輸入通道，16 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
            nn.Conv2d(16, 32, kernel_size=3, padding=0),  # 16 輸入通道，32 輸出通道，3×3 卷積
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2×2 池化
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # 上採樣 2x
            nn.ReLU(),
            nn.ConvTranspose2d(16, num_classes, kernel_size=2, stride=2),  # 上採樣 2x
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x
```

輸入條件：

- **輸入圖像**：4×4，3 通道（RGB），即形狀為 [1, 3, 4, 4]（batch_size=1）。
- **卷積核大小**：3×3。
- **無 padding**（padding=0）。
- **目標**：輸出為像素級分類（每個像素 2 個類別的得分）。

---

### 步驟-by-步驟計算與解釋

#### 步驟 1：第一次卷積 (Conv2d: 3 -> 16, 3×3)

- **輸入**：[1, 3, 4, 4]（batch_size=1, 通道=3, 高=4, 寬=4）。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：3。
    - 輸出通道：16。
    - Stride：1（預設）。
    - Padding：0。
- **輸出尺寸計算**：
    - 公式：output_size = (input_size - kernel_size + 2 * padding) / stride + 1
    - 高：(4 - 3 + 0) / 1 + 1 = 2
    - 寬：(4 - 3 + 0) / 1 + 1 = 2
    - 輸出形狀：[1, 16, 2, 2]（16 個 2×2 特徵圖）。
- **計算過程**：
    - 每個 3×3 卷積核在輸入圖像上滑動，計算 3 個通道的點積並加偏置。
    - 假設輸入數據（僅展示通道 1）：

        `通道 1: [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]`
        
    - 假設第一個卷積核權重（通道 1）：[[1, 0, -1], [2, 0, -2], [1, 0, -1]]，偏置為 0。
    - 左上角 3×3 區域：
        - 輸入：[[1, 2, 3], [5, 6, 7], [9, 10, 11]]
        - 點積：1*1 + 2*0 + 3*-1 + 5*2 + 6*0 + 7*-2 + 9*1 + 10*0 + 11*-1 = 1 - 3 + 10 - 14 + 9 - 11 = -8
        - 假設其他通道計算後總和為 -10。
    - 輸出特徵圖（假設值）：

        `特徵圖 1: [[-10, 5], [3, -2]]`

#### 步驟 2：ReLU 激活

- **輸入**：[1, 16, 2, 2]。
- **操作**：將負值設為 0。
- **輸出形狀**：[1, 16, 2, 2]。
- **計算過程**：
    - 示例：

        `輸入: [[-10, 5], [3, -2]] 輸出: [[0, 5], [3, 0]]`
        
#### 步驟 3：第一次池化 (MaxPool2d: 2×2)

- **輸入**：[1, 16, 2, 2]。
- **池化參數**：
    - 窗口：2×2。
    - Stride：2。
- **輸出尺寸計算**：
    - 高：(2 - 2) / 2 + 1 = 1
    - 寬：(2 - 2) / 2 + 1 = 1
    - 輸出形狀：[1, 16, 1, 1]。
- **計算過程**：
    - 取每個 2×2 區域的最大值。
    - 示例：

        `輸入: [[0, 5], [3, 0]] 輸出: [[5]]`
        

#### 步驟 4：第二次卷積 (Conv2d: 16 -> 32, 3×3)

- **輸入**：[1, 16, 1, 1]。
- **卷積參數**：
    - 卷積核大小：3×3。
    - 輸入通道：16。
    - 輸出通道：32。
    - Padding：0。
- **輸出尺寸計算**：
    - 高：(1 - 3 + 0) / 1 + 1 = -1 + 1 = 0（無效）。
- **問題**：
    - 輸入 1×1 小於 3×3 卷積核，無法進行卷積。
- **解決方法**：
    - 在此輸入尺寸下，第二次卷積無法執行。FCN 通常假設輸入更大（如 224×224）。為繼續展示，我們假設調整結構，跳過第二次卷積和池化，直接進入解碼器，或假設輸入更大。

#### 修改假設

假設我們調整結構，只保留一次卷積和池化：

```python
self.encoder = nn.Sequential(
    nn.Conv2d(3, 16, kernel_size=3, padding=0),
    nn.ReLU(),
    nn.MaxPool2d(2, 2),
)
```


- 編碼器輸出：[1, 16, 1, 1]。

#### 步驟 5：第一次轉置卷積 (ConvTranspose2d: 16 -> 16, 2×2, stride=2)

- **輸入**：[1, 16, 1, 1]。
- **參數**：
    - 輸入通道：16。
    - 輸出通道：16。
    - 卷積核：2×2。
    - Stride：2。
- **輸出尺寸計算**：
    - 公式：output_size = (input_size - 1) * stride + kernel_size
    - 高：(1 - 1) * 2 + 2 = 2
    - 寬：(1 - 1) * 2 + 2 = 2
    - 輸出形狀：[1, 16, 2, 2]。
- **計算過程**：
    - 轉置卷積將 1×1 擴展為 2×2。
    - 假設輸入：[[5]]，權重（簡化）：[[1, 0], [0, 1]]。
    - 輸出（假設值）：

        `[[5, 0], [0, 5]]`
        

#### 步驟 6：ReLU 激活

- **輸入**：[1, 16, 2, 2]。
- **操作**：max(0, x)。
- **輸出形狀**：[1, 16, 2, 2]。
- **示例**：

    `輸入: [[5, 0], [0, -2]] 輸出: [[5, 0], [0, 0]]`
    

#### 步驟 7：第二次轉置卷積 (ConvTranspose2d: 16 -> 2, 2×2, stride=2)

- **輸入**：[1, 16, 2, 2]。
- **參數**：
    - 輸入通道：16。
    - 輸出通道：2（類別數）。
    - 卷積核：2×2。
    - Stride：2。
- **輸出尺寸計算**：
    - 高：(2 - 1) * 2 + 2 = 4
    - 寬：(2 - 1) * 2 + 2 = 4
    - 輸出形狀：[1, 2, 4, 4]（每個像素 2 類得分）。
- **計算過程**：
    - 將 2×2 擴展為 4×4。
    - 假設輸出（簡化）：

        `通道 1: [[5, 0, 0, 0], [0, 5, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]] 通道 2: [[...]]`
        

---

### 總結與數據流

|步驟|形狀|解釋|
|---|---|---|
|輸入|[1, 3, 4, 4]|4×4 RGB 圖像|
|Conv1|[1, 16, 2, 2]|3×3 卷積提取特徵|
|ReLU1|[1, 16, 2, 2]|非線性激活|
|MaxPool1|[1, 16, 1, 1]|2×2 池化縮減尺寸|
|ConvTranspose1|[1, 16, 2, 2]|2×2 轉置卷積，上採樣|
|ReLU2|[1, 16, 2, 2]|非線性激活|
|ConvTranspose2|[1, 2, 4, 4]|2×2 轉置卷積，恢復到 4×4|

### 注意

- **尺寸問題**：原始結構中第二次卷積因輸入過小無法執行，我調整為單次卷積+池化，確保流程可行。
- **輸出**：最終輸出 [1, 2, 4, 4] 表示每個像素有 2 個類別的得分，符合 FCN 的分割目標。
- **假設數據**：這裡使用簡化值展示，實際權重由訓練決定。