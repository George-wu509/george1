
post: https://www.linkedin.com/posts/skalskip92_cvpr2025-computervision-deeplearning-activity-7338573145466925056-soqQ?utm_source=share&utm_medium=member_desktop&rcm=ACoAABMNj2MBAJSP3cWd4xpiz4wB7qdx43hvW18

![[Pasted image 20250807002153.png]]


```
Gaze-LLE: Gaze Target Estimation via Foundation Models ğŸ‘ï¸ ğŸ‘ï¸ ğŸ‘ï¸  
  
Gaze-LLE is easily one of my favorite CVPR 2025 papers. Developed by [Fiona Ryan]estimation by building on top of a frozen DINOv2 visual foundation model.  
  
Traditional gaze target estimation models rely on complex, multi-branch pipelines: separate encoders for head and scene, plus extra networks for pose or depth cues. These hand-crafted systems are often heavy and slow to train.  
  
Gaze-LLE simplifies the process by using a single feature representation from a frozen DINOv2 encoder, along with a simple head prompt that specifies whose gaze to estimate.  
  
â®‘ ğŸ”— top CVPR 2025 papers: [https://lnkd.in/dbNRXHW2](https://lnkd.in/dbNRXHW2)
```

  
- paper: [https://arxiv.org/pdf/2412.09586](https://arxiv.org/pdf/2412.09586)  
- code: [https://github.com/fkryan/gazelle](https://github.com/fkryan/gazelle)  
- demo: [https://huggingface.co/spaces/fffiloni/Gaze-LLE](https://huggingface.co/spaces/fffiloni/Gaze-LLE)